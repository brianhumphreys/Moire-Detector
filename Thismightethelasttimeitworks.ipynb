{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of Playground.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianhumphreys/Moire-Detector/blob/main/Thismightethelasttimeitworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDFp5O-Bqa_H"
      },
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To3GCs0JndZT",
        "outputId": "bae4fc15-d124-4486-d3b8-0df0527d8e55"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 26 23:17:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5iT4R4PnYT6",
        "outputId": "397df04b-3910-4cb0-ac75-d346f44f8c86"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "muinrEgNqa_J"
      },
      "source": [
        "## Test 2D Wavelet Decomposition function\n",
        "This function(fwdHaarDWT2D) computes the 2D Wavelet Transform in the image. All the input images are passed through a Haar Wavelet Decomposition module, to get the LL, LH, HL and HHH component of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWlOXh6fq3xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5524679d-aac5-470f-b20c-5feae6bfd1a9"
      },
      "source": [
        "from google.colab import drive                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsTZ_TLIv3TK",
        "outputId": "64f44b8a-adc8-46ca-eb95-26ad1a15f09d"
      },
      "source": [
        "# !ls /content/drive/MyDrive/Moire\n",
        "!pip install pyheif whatimage\n",
        "# !pip show wand"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyheif in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: whatimage in /usr/local/lib/python3.7/dist-packages (0.0.3)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pyheif) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->pyheif) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO9ckef9Wrs3"
      },
      "source": [
        "## Normalized Raw data to 1000x750 pixel images\n",
        "Images are cropped to fit a 3:4 aspect ratio and then resized to match a 1000x750 size. Moves photos **unnormalized** -> **preaugmented**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xaN5wepXCy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a425af8-e8d4-4239-bb4c-ee362ba9d634"
      },
      "source": [
        "# importing the module\n",
        "\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "import whatimage\n",
        "import pyheif\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def decodeImageMetadata(bytesIo):\n",
        "\n",
        "  with open(bytesIo, 'rb') as f:\n",
        "    data = f.read()\n",
        "    fmt = whatimage.identify_image(data)\n",
        "    print(fmt)\n",
        "    if fmt in ['heic', 'avif']:\n",
        "      i = pyheif.read_heif(bytesIo)\n",
        "\n",
        "      # Extract metadata etc\n",
        "      print(i.metadata)\n",
        "      for metadata in i.metadata or []:\n",
        "        if metadata['type']=='Exif':\n",
        "          print('exif:')\n",
        "        print(metadata)\n",
        "        \n",
        "      # Convert to other file format like jpeg\n",
        "      s = io.BytesIO()\n",
        "      pi = Image.frombytes(mode=i.mode, size=i.size, data=i.data)\n",
        "\n",
        "      pi.save(s, format=\"jpeg\")\n",
        "\n",
        "def decodeImage(bytesIo):\n",
        "  with open(bytesIo, 'rb') as f:\n",
        "    data = f.read()\n",
        "    fmt = whatimage.identify_image(data)\n",
        "    if fmt in ['heic', 'avif']:\n",
        "      i = pyheif.read_heif(data)\n",
        "      pi = Image.frombytes(mode=i.mode, size=i.size, data=i.data)\n",
        "      pi.save(\"heic.jpg\", format=\"jpeg\")\n",
        "\n",
        "def read_heic(path: str):\n",
        "    img = Wimage(path)\n",
        "    img.format = 'jpg'\n",
        "    img.save(filename=\"heic.jpg\")\n",
        "    img.close()\n",
        "\n",
        "def openImage(fileName):\n",
        "  # decodeImageMetadata(fileName)\n",
        "  decodeImage(fileName)\n",
        "  return Image.open(\"heic.jpg\")\n",
        "\n",
        "def cropAndSave(image, fileName):\n",
        "    width = image.size[0]\n",
        "    height = image.size[1]\n",
        "\n",
        "    aspect = width / float(height)\n",
        "\n",
        "    if (height > width):\n",
        "        image = image.rotate(90, Image.NEAREST, expand=1)\n",
        "        width = image.size[0]\n",
        "        height = image.size[1]\n",
        "\n",
        "    ideal_width = 1000\n",
        "    ideal_height = 750\n",
        "\n",
        "    ideal_aspect = ideal_width / float(ideal_height)\n",
        "\n",
        "    if aspect > ideal_aspect:\n",
        "        # Then crop the left and right edges:\n",
        "        new_width = int(ideal_aspect * height)\n",
        "        offset = (width - new_width) / 2\n",
        "        resize = (offset, 0, width - offset, height)\n",
        "    else:\n",
        "        # ... crop the top and bottom:\n",
        "        new_height = int(width / ideal_aspect)\n",
        "        offset = (height - new_height) / 2\n",
        "        resize = (0, offset, width, height - offset)\n",
        "\n",
        "    thumb = image.crop(resize).resize((ideal_width, ideal_height), Image.ANTIALIAS)\n",
        "    thumb.save(fileName)\n",
        "\n",
        "\n",
        "\n",
        "def normalizeRawImages(superpoch, dataSetNumber):\n",
        "\n",
        "  print('##### NORMALIZING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber)\n",
        "\n",
        "  negativeFromDir = '/content/drive/MyDrive/Moire/unnormalized/negative/' + dataSetNumber + '/'\n",
        "  positiveFromDir = '/content/drive/MyDrive/Moire/unnormalized/positive/' + dataSetNumber + '/'\n",
        "  negativeToDir = '/content/drive/MyDrive/Moire/preaugmented/negative/' + dataSetNumber + '/'\n",
        "  positiveToDir = '/content/drive/MyDrive/Moire/preaugmented/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  if not os.path.exists(positiveToDir):\n",
        "      os.makedirs(positiveToDir)\n",
        "  if not os.path.exists(negativeToDir):\n",
        "      os.makedirs(negativeToDir)\n",
        "\n",
        "  if len([name for name in os.listdir(positiveToDir)]) > 0:\n",
        "    print('Directory ' + positiveToDir + ' already has normalized photos in it.  Skipping normalization for negative photos.')\n",
        "  if len([name for name in os.listdir(negativeToDir)]) > 0:\n",
        "    print('Directory ' + negativeToDir + ' already has normalized photos in it.  Skipping normalization for positive photos.')\n",
        "\n",
        "  positiveImageFiles = [f for f in listdir(positiveFromDir) if (isfile(join(positiveFromDir, f)))]\n",
        "  negativeImageFiles = [f for f in listdir(negativeFromDir) if (isfile(join(negativeFromDir, f)))]\n",
        "\n",
        "  # LLList = [l for l in positiveImageFiles if 'LLL' in l]\n",
        "  # print(LLList)\n",
        "\n",
        "  if len([name for name in os.listdir(positiveToDir)]) <= 0:\n",
        "    for f in positiveImageFiles:\n",
        "        print(join(positiveFromDir, f))\n",
        "        img = openImage(join(positiveFromDir, f))\n",
        "\n",
        "        rgb_im = img.convert(\"RGB\")\n",
        "        components = f.split('.')\n",
        "        newComponents = components[:len(components) - 1]\n",
        "        newComponents.append('png')\n",
        "        newFileName = '.'.join(newComponents)\n",
        "\n",
        "        cropAndSave(rgb_im, join(positiveToDir, newFileName))\n",
        "\n",
        "  if len([name for name in os.listdir(negativeToDir)]) <= 0:\n",
        "    for f in negativeImageFiles:\n",
        "        print(join(negativeFromDir, f))\n",
        "        img = Image.open(join(negativeFromDir, f))\n",
        "\n",
        "        rgb_im = img.convert(\"RGB\")\n",
        "        components = f.split('.')\n",
        "        newComponents = components[:len(components) - 1]\n",
        "        newComponents.append('png')\n",
        "        newFileName = '.'.join(newComponents)\n",
        "\n",
        "        cropAndSave(rgb_im, join(negativeToDir, newFileName))\n",
        "\n",
        "# normalizeRawImages(\"001\", \"005\")\n",
        "# normalizeRawImages(\"001\", \"006\")  \n",
        "# normalizeRawImages(\"001\", \"007\")\n",
        "# normalizeRawImages(\"001\", \"008\") \n",
        "# normalizeRawImages(\"001\", \"009\")\n",
        "# normalizeRawImages(\"001\", \"010\")\n",
        "# normalizeRawImages(\"001\", \"011\") \n",
        "# normalizeRawImages(\"001\", \"012\") \n",
        "# normalizeRawImages(\"001\", \"013\") \n",
        "# normalizeRawImages(\"001\", \"014\") \n",
        "# normalizeRawImages(\"001\", \"015\") \n",
        "# normalizeRawImages(\"001\", \"016\") \n",
        "# normalizeRawImages(\"001\", \"017\") \n",
        "normalizeRawImages(\"001\", \"026\") \n",
        "# normalizeRawImages(\"001\", \"019\") \n",
        "# normalizeRawImages(\"001\", \"020\") \n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### NORMALIZING - superpoch: 001 - dataset: 026\n",
            "Directory /content/drive/MyDrive/Moire/preaugmented/positive/026/ already has normalized photos in it.  Skipping normalization for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/preaugmented/negative/026/ already has normalized photos in it.  Skipping normalization for positive photos.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNnfNmoEqa_M"
      },
      "source": [
        "## Augment normalized data\n",
        "The training images need to be put in two folders. positiveImages and negativeImages. positiveImages are the images which are captured from the display devices and has the presence of stron or weak Moiré patterms in it.\n",
        "negativeImages are the ones without Moiré Patterns (i.e. the images which are not captured from the display devices).  Moves photos **preaugmented** -> **train/test** based on a split ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9o2VLHoqyOo"
      },
      "source": [
        "#This function(fwdHaarDWT2D) computes the 2D Wavelet Transform in the image. All the input images are passed through a Haar Wavelet Decomposition module, to get the LL, LH, HL and HHH component of the image\n",
        "\n",
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "def splitFreqBands(img, levRows, levCols):\n",
        "    halfRow = int(levRows/2)\n",
        "    halfCol = int(levCols/2)\n",
        "    LL = img[0:halfRow, 0:halfCol]\n",
        "    LH = img[0:halfRow, halfCol:levCols]\n",
        "    HL = img[halfRow:levRows, 0:halfCol]\n",
        "    HH = img[halfRow:levRows, halfCol:levCols]\n",
        "    \n",
        "    return LL, LH, HL, HH\n",
        "    \n",
        "def haarDWT1D(data, length):\n",
        "    avg0 = 0.5;\n",
        "    avg1 = 0.5;\n",
        "    dif0 = 0.5;\n",
        "    dif1 = -0.5;\n",
        "    temp = np.empty_like(data)\n",
        "    temp = temp.astype(float)\n",
        "    h = int(length/2)\n",
        "    for i in range(h):\n",
        "        k = i*2\n",
        "        temp[i] = data[k] * avg0 + data[k + 1] * avg1;\n",
        "        temp[i + h] = data[k] * dif0 + data[k + 1] * dif1;\n",
        "    \n",
        "    data[:] = temp\n",
        "\n",
        "# computes the homography coefficients for PIL.Image.transform using point correspondences\n",
        "def fwdHaarDWT2D(img):\n",
        "    img = np.array(img)\n",
        "    levRows = img.shape[0];\n",
        "    levCols = img.shape[1];\n",
        "    img = img.astype(float)\n",
        "    for i in range(levRows):\n",
        "        row = img[i,:]\n",
        "        haarDWT1D(row, levCols)\n",
        "        img[i,:] = row\n",
        "    for j in range(levCols):\n",
        "        col = img[:,j]\n",
        "        haarDWT1D(col, levRows)\n",
        "        img[:,j] = col\n",
        "        \n",
        "    return splitFreqBands(img, levRows, levCols)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a63KHmZYqa_K"
      },
      "source": [
        "# from PIL import Image\n",
        "# from matplotlib import pyplot as plt\n",
        "# !ls /content/drive/MyDrive/Moire/\n",
        "# img = Image.open('/content/drive/MyDrive/Moire/preaugmented/positive/001/IMG_2906.jpg').convert('L')\n",
        "# img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "# img.save('chl.jpg')\n",
        "# LL, LH, HL, HH = fwdHaarDWT2D(img)\n",
        "# fig, axes = plt.subplots(2, 2)\n",
        "# fig.tight_layout()\n",
        "# axes[0, 0].imshow(LL)\n",
        "# axes[0, 1].imshow(LH)\n",
        "# axes[1, 0].imshow(HL)\n",
        "# axes[1, 1].imshow(HH)\n",
        "# axes[0, 0].set_title(\"LL\")\n",
        "# axes[0, 1].set_title(\"LH\")\n",
        "# axes[1, 0].set_title(\"HL\")\n",
        "# axes[1, 1].set_title(\"HH\")\n",
        "# plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO8AKkFsqm5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0693b36-7269-4182-9abf-c2af263426ce"
      },
      "source": [
        "import sys\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "\n",
        "#The training images need to be put in two folders. positiveImages and negativeImages. positiveImages are the images which are captured from the display devices and has the presence of stron or weak Moiré patterms in it. negativeImages are the ones without Moiré Patterns (i.e. the images which are not captured from the display devices)\n",
        "\n",
        "\n",
        "def augmentNormalizedData(superpoch, dataSetNumber):\n",
        "\n",
        "  print('##### AUGMENTING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber)\n",
        "\n",
        "  negativeFromDir = '/content/drive/MyDrive/Moire/preaugmented/negative/' + dataSetNumber + '/'\n",
        "  positiveFromDir = '/content/drive/MyDrive/Moire/preaugmented/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  negativeToTrainDir = '/content/drive/MyDrive/Moire/train/negative/' + dataSetNumber + '/'\n",
        "  positiveToTrainDir = '/content/drive/MyDrive/Moire/train/positive/' + dataSetNumber + '/'\n",
        "  negativeToTestDir = '/content/drive/MyDrive/Moire/test/negative/' + dataSetNumber + '/'\n",
        "  positiveToTestDir = '/content/drive/MyDrive/Moire/test/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  if not os.path.exists(negativeToTrainDir):\n",
        "      os.makedirs(negativeToTrainDir)\n",
        "  if not os.path.exists(positiveToTrainDir):\n",
        "      os.makedirs(positiveToTrainDir)\n",
        "  if not os.path.exists(negativeToTestDir):\n",
        "      os.makedirs(negativeToTestDir)\n",
        "  if not os.path.exists(positiveToTestDir):\n",
        "      os.makedirs(positiveToTestDir)\n",
        "\n",
        "  if len([name for name in os.listdir(negativeToTrainDir)]) > 0:\n",
        "    print('Directory ' + negativeToTrainDir + ' already has normalized photos in it.  Skipping augmentation for negative photos.')\n",
        "  if len([name for name in os.listdir(positiveToTrainDir)]) > 0:\n",
        "    print('Directory ' + positiveToTrainDir + ' already has normalized photos in it.  Skipping augmentation for positive photos.')\n",
        "  if len([name for name in os.listdir(negativeToTestDir)]) > 0:\n",
        "    print('Directory ' + negativeToTestDir + ' already has normalized photos in it.  Skipping augmentation for negative photos.')\n",
        "  if len([name for name in os.listdir(positiveToTestDir)]) > 0:\n",
        "    print('Directory ' + positiveToTestDir + ' already has normalized photos in it.  Skipping augmentation for positive photos.')\n",
        "        \n",
        "  createTrainingData(positiveFromDir, negativeFromDir, positiveToTrainDir, negativeToTrainDir, positiveToTestDir, negativeToTestDir)\n",
        "\n",
        "    \n",
        "#The wavelet decomposed images are the transformed images representing the spatial and the frequency information of the image. These images are stored as 'tiff' in the disk, to preserve that information. Each image is transformed with 180 degrees rotation and as well flipped, as part of data augmentation.\n",
        "\n",
        "def transformImageAndSave(image, f, customStr, path):\n",
        "    cA, cH, cV, cD  = fwdHaarDWT2D(image);\n",
        "    \n",
        "    fileName = (os.path.splitext(f)[0])\n",
        "    fLL = (f.replace(fileName, fileName+'_' + customStr + 'LL')).replace('.png','.tiff')\n",
        "    fLH = (f.replace(fileName, fileName+'_' + customStr + 'LH')).replace('.png','.tiff')\n",
        "    fHL = (f.replace(fileName, fileName+'_' + customStr + 'HL')).replace('.png','.tiff')\n",
        "    fHH = (f.replace(fileName, fileName+'_' + customStr + 'HH')).replace('.png','.tiff')\n",
        "\n",
        "    cA = Image.fromarray(cA)\n",
        "    cH = Image.fromarray(cH)\n",
        "    cV = Image.fromarray(cV)\n",
        "    cD = Image.fromarray(cD)\n",
        "\n",
        "    cA.save(join(path, fLL))\n",
        "    cH.save(join(path, fLH))\n",
        "    cV.save(join(path, fHL))\n",
        "    cD.save(join(path, fHH))\n",
        "    \n",
        "    \n",
        "def augmentAndTrasformImage(f, mainFolder, trainFolder):\n",
        "    try:\n",
        "        print(join(mainFolder, f))\n",
        "        img = Image.open(join(mainFolder, f)) \n",
        "    except:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(f))\n",
        "        return None\n",
        "\n",
        "    imgGray = img.convert('L')\n",
        "    wdChk, htChk = imgGray.size\n",
        "    if htChk > wdChk:\n",
        "        imgGray = imgGray.rotate(-90, expand=1)\n",
        "        print('training image rotated')\n",
        "    transformImageAndSave(imgGray, f, '', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.ROTATE_180)\n",
        "    transformImageAndSave(imgGray, f, '180_', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    transformImageAndSave(imgGray, f, '180_FLIP_', trainFolder)\n",
        "    \n",
        "    return True\n",
        "    \n",
        "    \n",
        "def createTrainingData(positiveFromDir, negativeFromDir, positiveToTrainDir, negativeToTrainDir, positiveToTestDir, negativeToTestDir):\n",
        "\n",
        "    print('positive image path: ' + positiveFromDir)\n",
        "    print('negative image path: ' + negativeFromDir)\n",
        "    splitRatio = 0.8\n",
        "\n",
        "    # get image files by classes\n",
        "    positiveImageFiles = [f for f in listdir(positiveFromDir) if (isfile(join(positiveFromDir, f)))]\n",
        "    negativeImageFiles = [f for f in listdir(negativeFromDir) if (isfile(join(negativeFromDir, f)))]\n",
        "\n",
        "    positiveDataBorder = round(len(positiveImageFiles) * splitRatio)\n",
        "    negativeDataBorder = round(len(negativeImageFiles) * splitRatio)\n",
        "\n",
        "    positiveTrainFiles = positiveImageFiles[:positiveDataBorder]\n",
        "    positiveTestFiles = positiveImageFiles[positiveDataBorder:]\n",
        "    negativeTrainFiles = negativeImageFiles[:negativeDataBorder]\n",
        "    negativeTestFiles = negativeImageFiles[negativeDataBorder:]\n",
        "\n",
        "    print('positive train samples: ' + str(len(positiveTrainFiles)))\n",
        "    print('negative train samples: ' + str(len(negativeTrainFiles)))\n",
        "    print('positive test samples: ' + str(len(positiveTestFiles)))\n",
        "    print('negative test samples: ' + str(len(negativeTestFiles)))\n",
        "\n",
        "    Knegative = 0\n",
        "    Kpositive = 0\n",
        "\n",
        "    # create positive training images\n",
        "    if len([name for name in os.listdir(positiveToTrainDir)]) <= 0:\n",
        "      for f in positiveTrainFiles:\n",
        "          ret = augmentAndTrasformImage(f, positiveFromDir, positiveToTrainDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Kpositive += 3\n",
        "\n",
        "    if len([name for name in os.listdir(negativeToTrainDir)]) <= 0:\n",
        "      # create positive test images\n",
        "      for f in negativeTrainFiles:\n",
        "          ret = augmentAndTrasformImage(f, negativeFromDir, negativeToTrainDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Kpositive += 3\n",
        "\n",
        "    if len([name for name in os.listdir(positiveToTestDir)]) <= 0:\n",
        "      # create negative training images\n",
        "      for f in positiveTestFiles:\n",
        "          ret = augmentAndTrasformImage(f, positiveFromDir, positiveToTestDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Knegative += 3;\n",
        "\n",
        "    if len([name for name in os.listdir(negativeToTestDir)]) <= 0:\n",
        "      # create negative training images\n",
        "      for f in negativeTestFiles:\n",
        "          ret = augmentAndTrasformImage(f, negativeFromDir, negativeToTestDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Knegative += 3;\n",
        "    #\n",
        "    # print('Total positive files after augmentation: ', Kpositive)\n",
        "    # print('Total negative files after augmentation: ', Knegative)\n",
        "    \n",
        "\n",
        "\n",
        "# mainAugment('/content/drive/MyDrive/Moire/preaugmentedPositiveImages', '/content/drive/MyDrive/Moire/preaugmentedNegativeImages')\n",
        "\n",
        "# augmentNormalizedData('001', '005')\n",
        "# augmentNormalizedData('001', '006')\n",
        "# augmentNormalizedData('001', '007')\n",
        "# augmentNormalizedData('001', '008')\n",
        "# augmentNormalizedData('001', '009')\n",
        "# augmentNormalizedData('001', '010')\n",
        "# augmentNormalizedData('001', '011')\n",
        "# augmentNormalizedData('001', '012')\n",
        "# augmentNormalizedData('001', '013')\n",
        "# augmentNormalizedData('001', '014')\n",
        "# augmentNormalizedData('001', '015')\n",
        "\n",
        "# augmentNormalizedData('001', '016')\n",
        "# augmentNormalizedData('001', '017')\n",
        "augmentNormalizedData('001', '026')\n",
        "# augmentNormalizedData('001', '019')\n",
        "# augmentNormalizedData('001', '020')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### AUGMENTING - superpoch: 001 - dataset: 026\n",
            "Directory /content/drive/MyDrive/Moire/train/negative/026/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/train/positive/026/ already has normalized photos in it.  Skipping augmentation for positive photos.\n",
            "Directory /content/drive/MyDrive/Moire/test/negative/026/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/test/positive/026/ already has normalized photos in it.  Skipping augmentation for positive photos.\n",
            "positive image path: /content/drive/MyDrive/Moire/preaugmented/positive/026/\n",
            "negative image path: /content/drive/MyDrive/Moire/preaugmented/negative/026/\n",
            "positive train samples: 24\n",
            "negative train samples: 24\n",
            "positive test samples: 6\n",
            "negative test samples: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INPlfs7QQXYJ"
      },
      "source": [
        "## Load Data into Memory\n",
        "Get your big boy pants on because it's going to be a lot of data.  Increase runtime memory.  This section will load data from an **augmented** directory and loads it into a tensor for training or evaluation.  Recommended to make sure that there is no accelerator used so that it can be used when training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOTnUFotxJJJ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#constants\n",
        "WIDTH = 500#384\n",
        "HEIGHT = 375#512\n",
        "\n",
        "#Here, we perform index based splitting and use those indices to split the our multi-input datasets. This is done because the CNN model is multi-input network\n",
        "def splitTrainTestDataForBands(inputData, X_train_ind, X_test_ind):\n",
        "    X_train = np.zeros((len(X_train_ind), WIDTH*HEIGHT))\n",
        "    for i in range(len(X_train_ind)):\n",
        "        X_train[i,:] = inputData[int(X_train_ind[i,0]),:]\n",
        "        \n",
        "    X_test = np.zeros((len(X_test_ind), WIDTH*HEIGHT))\n",
        "    for i in range(len(X_test_ind)):\n",
        "        X_test[i,:] = inputData[int(X_test_ind[i,0]),:]\n",
        "        \n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def countPositiveSamplesAfterSplit(trainData):\n",
        "    count = 0;\n",
        "    for i in range(len(trainData)):\n",
        "        if(trainData[i,0] == 0):\n",
        "            count = count + 1\n",
        "    return count\n",
        "\n",
        "def scaleData(inp, minimum, maximum):\n",
        "    minMaxScaler = preprocessing.MinMaxScaler(copy=True, feature_range=(minimum,maximum))\n",
        "    inp = inp.reshape(-1, 1)\n",
        "    inp = minMaxScaler.fit_transform(inp)\n",
        "    \n",
        "    return inp\n",
        "\n",
        "def readAndScaleImage(f, customStr, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, sampleVal):\n",
        "    fileName = (os.path.splitext(f)[0])\n",
        "    # print(fileName)\n",
        "    # print(customStr)\n",
        "\n",
        "    fLL = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fLH = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fHL = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fHH = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    \n",
        "    print('Filenames')\n",
        "    print(trainImagePath)\n",
        "    print(fLL)\n",
        "    print(fLH)\n",
        "    print(fHL)\n",
        "    print(fHH)\n",
        "\n",
        "\n",
        "    try:\n",
        "        imgLL = Image.open(join(trainImagePath, fLL))\n",
        "        imgLH = Image.open(join(trainImagePath, fLH))\n",
        "        imgHL = Image.open(join(trainImagePath, fHL))\n",
        "        imgHH = Image.open(join(trainImagePath, fHH))\n",
        "    except Exception as e:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(fileName))\n",
        "        print('Exception:', e)\n",
        "        return None\n",
        "        \n",
        "    imgLL = np.array(imgLL)\n",
        "    imgLH = np.array(imgLH)\n",
        "    imgHL = np.array(imgHL)\n",
        "    imgHH = np.array(imgHH)\n",
        "\n",
        "    # print(imgLL)\n",
        "    # print(imgLH)\n",
        "    # print(imgHL)\n",
        "    # print(imgHH)\n",
        "\n",
        "\n",
        "    imgLL = scaleData(imgLL, 0, 1)\n",
        "    imgLH = scaleData(imgLH, -1, 1)\n",
        "    imgHL = scaleData(imgHL, -1, 1)\n",
        "    imgHH = scaleData(imgHH, -1, 1)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    imgVector = imgLL.reshape(1, WIDTH*HEIGHT)\n",
        "    X_LL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgLH.reshape(1, WIDTH*HEIGHT)\n",
        "    X_LH[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHL.reshape(1, WIDTH*HEIGHT)\n",
        "    X_HL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHH.reshape(1, WIDTH*HEIGHT)\n",
        "    X_HH[sampleIndex, :] = imgVector\n",
        "    \n",
        "    Y[sampleIndex, 0] = sampleVal;\n",
        "    X_index[sampleIndex, 0] = sampleIndex;\n",
        "\n",
        "    imgVector = None\n",
        "    imgLL = None\n",
        "    imgLH = None\n",
        "    imgHL = None\n",
        "    imgHH = None\n",
        "    \n",
        "    return True\n",
        "\n",
        "def reshapeData(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount):\n",
        "\n",
        "    print('Dataset length: ' + str(len(X_LL)))\n",
        "    \n",
        "    print('num_train_samples', len(X_LL))\n",
        "    X_LL = np.array(X_LL)\n",
        "    X_LL = X_LL.reshape((len(X_LL), HEIGHT, WIDTH, 1))\n",
        "\n",
        "    X_LH = np.array(X_LH)\n",
        "    X_LH = X_LH.reshape((len(X_LH), HEIGHT, WIDTH, 1))\n",
        "\n",
        "    X_HL = np.array(X_HL)\n",
        "    X_HL = X_HL.reshape((len(X_HL), HEIGHT, WIDTH, 1))\n",
        "    \n",
        "    X_HH = np.array(X_HH)\n",
        "    X_HH = X_HH.reshape((len(X_HH), HEIGHT, WIDTH, 1))\n",
        "\n",
        "    Y = np.array(Y)\n",
        "    \n",
        "    return X_LL, X_LH, X_HL, X_HH, Y\n",
        "\n",
        "def readImageSet(imageFiles, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass):\n",
        "\n",
        "    for f in imageFiles:\n",
        "        ret = readAndScaleImage(f, '', trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass)\n",
        "        if ret == True:\n",
        "            sampleIndex = sampleIndex + 1\n",
        "\n",
        "    return sampleIndex\n",
        "\n",
        "def readWaveletData(positiveImagePath, negativeImagePath):\n",
        "    \n",
        "    # get augmented, balanced training data image files by class\n",
        "    positiveImageFiles = [f for f in listdir(positiveImagePath) if (isfile(join(positiveImagePath, f)))]\n",
        "    negativeImageFiles = [f for f in listdir(negativeImagePath) if (isfile(join(negativeImagePath, f)))]\n",
        "\n",
        "    positiveCount = len(positiveImageFiles)\n",
        "    negativeCount = len(negativeImageFiles)\n",
        "\n",
        "    print('positive samples: ' + str(positiveCount))\n",
        "    print('negative samples: ' + str(negativeCount))\n",
        "    imageCount = positiveCount + negativeCount\n",
        "    #intialization\n",
        "    X_LL = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_LH = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_HL = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_HH = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_index = np.zeros((positiveCount + negativeCount, 1))\n",
        "    Y = np.zeros((positiveCount + negativeCount, 1))\n",
        "    \n",
        "    sampleIndex = 0\n",
        "    # read all images, convert to float, divide by 255 (leads to gray range 0..1), reshape into a row vector\n",
        "    # write class 0 for positive and 1 for negative samples\n",
        "\n",
        "    sampleIndex = readImageSet(positiveImageFiles, positiveImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, 0)\n",
        "    print('positive data loaded.')\n",
        "    \n",
        "    sampleIndex += readImageSet(negativeImageFiles, negativeImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, 1)\n",
        "    print('negative data loaded.')\n",
        "\n",
        "    print('Total Samples Loaded: ', sampleIndex)\n",
        "    \n",
        "    X_LL, X_LH, X_HL, X_HH, Y = shuffle(X_LL, X_LH, X_HL, X_HH, Y, random_state=0)\n",
        "    \n",
        "    return X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount\n",
        "\n",
        "def mainReadDatafromDrive(dataSetNumber, dataType):\n",
        "\n",
        "    # dataType can be 'train' or 'test'\n",
        "\n",
        "    positiveFromTrainDir = '/content/drive/MyDrive/Moire/' + dataType + '/positive/' + dataSetNumber + '/'\n",
        "    negativeFromTrainDir = '/content/drive/MyDrive/Moire/' + dataType + '/negative/' + dataSetNumber + '/'\n",
        "    print(positiveFromTrainDir)\n",
        "    print(negativeFromTrainDir)\n",
        "\n",
        "    if not os.path.exists(positiveFromTrainDir):\n",
        "      print(\"ERROR: \" + positiveFromTrainDir + ' does not exist.  Exiting.')\n",
        "      raise ValueError('Directory does not exist')\n",
        "    if not os.path.exists(negativeFromTrainDir):\n",
        "      print(\"ERROR: \" + negativeFromTrainDir + ' does not exist.  Exiting.')\n",
        "      raise ValueError('Directory does not exist')\n",
        "    \n",
        "    X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount = readWaveletData(positiveFromTrainDir, negativeFromTrainDir)\n",
        "\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = reshapeData(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount)\n",
        "\n",
        "    return X_LL, X_LH, X_HL, X_HH, Y\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azf3IN-SRudm"
      },
      "source": [
        "## Train CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ASB86jIRxvK"
      },
      "source": [
        "import os\n",
        "\n",
        "from keras.models import Model # basic class for specifying and training a neural network\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Add, Multiply, Maximum\n",
        "\n",
        "def createModel(height, width, depth, num_classes):\n",
        "#     num_epochs = 20 # 50 26 200 # we iterate 200 times over the entire training set\n",
        "    kernel_size_1 = 7 # we will use 7x7 kernels \n",
        "    kernel_size_2 = 3 # we will use 3x3 kernels \n",
        "    pool_size = 2 # we will use 2x2 pooling throughout\n",
        "    conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
        "    conv_depth_2 = 16 # ...switching to 16 after the first pooling layer\n",
        "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
        "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
        "    hidden_size = 32 # 128 512 the FC layer will have 512 neurons\n",
        "\n",
        "\n",
        "    inpLL = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpLH = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHL = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHH = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    \n",
        "    conv_1_LL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLL)\n",
        "    conv_1_LH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLH)\n",
        "    conv_1_HL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHL)\n",
        "    conv_1_HH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHH)\n",
        "\n",
        "    pool_1_LL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LL)\n",
        "    pool_1_LH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LH)\n",
        "    pool_1_HL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HL)\n",
        "    pool_1_HH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HH)\n",
        "\n",
        "    avg_LH_HL_HH = Maximum()([pool_1_LH, pool_1_HL, pool_1_HH])\n",
        "    inp_merged = Multiply()([pool_1_LL, avg_LH_HL_HH])\n",
        "    print(inp_merged)\n",
        "    C4 = Convolution2D(conv_depth_2, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(inp_merged)\n",
        "    S2 = MaxPooling2D(pool_size=(4, 4))(C4)\n",
        "    drop_1 = Dropout(drop_prob_1)(S2)\n",
        "    C5 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(drop_1)\n",
        "    S3 = MaxPooling2D(pool_size=(pool_size, pool_size))(C5)\n",
        "    C6 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(S3)\n",
        "    S4 = MaxPooling2D(pool_size=(pool_size, pool_size))(C6)\n",
        "    drop_2 = Dropout(drop_prob_1)(S4)\n",
        "    # Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
        "    flat = Flatten()(drop_2)\n",
        "    hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "    drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "    out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "    \n",
        "    model = Model(inputs=[inpLL, inpLH, inpHL, inpHH], outputs=out) # To define a model, just specify its input and output layers\n",
        "    intermediate_model = Model(inputs=[inpLL, inpLH, inpHL, inpHH], outputs=inp_merged)\n",
        "    \n",
        "    return model, intermediate_model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTX2vudptIaO"
      },
      "source": [
        "#To detect Moire ́ patternzs, images are first decomposed using Wavelet decomposition (refer to file '') and trained using multi-input Convolutional neural network. The strength of the proposed CNN model is, it uses the LL intensity image (from the Wavelet decomposition) as a weight parameter for the Moire ́ pattern, thereby approximating the spatial spread of the Moire ́ pattern in the image. Usage of CNN model performs better than frequency thresholding approach as the model is trained considering diverse scenarios and it is able to distinguish between the high frequency of background texture and the Moire ́ pattern.\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import time\n",
        "from tensorflow import keras\n",
        "\n",
        "# - read positive and negative training data\n",
        "# - create X and Y from training data\n",
        "\n",
        "\n",
        "def trainMoire(superpoch, dataSetNumber, numEpochs, weights_file = None):\n",
        "\n",
        "    print('##### TRAINING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber[0] + ', ', dataSetNumber[1])\n",
        "\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(dataSetNumber[0], 'train')\n",
        "\n",
        "    print(\"X_LL\")\n",
        "    print(X_LL)\n",
        "\n",
        "    print(\"X_LH\")\n",
        "    print(X_LH)\n",
        "\n",
        "    print(\"X_HL\")\n",
        "    print(X_HL)\n",
        "\n",
        "    print(\"X_HH\")\n",
        "    print(X_HH)\n",
        "\n",
        "    X_LL_2, X_LH_2, X_HL_2, X_HH_2, Y_2 = mainReadDatafromDrive(dataSetNumber[1], 'train')\n",
        "\n",
        "\n",
        "    print('Concatenating 2 datasets.')\n",
        "    print(X_LL.shape)\n",
        "    print(X_LL_2.shape)\n",
        "    X_LL = np.concatenate((X_LL, X_LL_2), axis=0)\n",
        "    X_LH = np.concatenate((X_LH, X_LH_2), axis=0)\n",
        "    X_HL = np.concatenate((X_HL, X_HL_2), axis=0)\n",
        "    X_HH = np.concatenate((X_HH, X_HH_2), axis=0)\n",
        "    Y = np.concatenate((Y, Y_2), axis=0)\n",
        "    X_LL_2 = None\n",
        "    X_LH_2 = None\n",
        "    X_HL_2 = None\n",
        "    X_HH_2 = None\n",
        "    Y_2 = None\n",
        "\n",
        "    modelName = trainCNNModel(superpoch, dataSetNumber, X_LL, X_LH, X_HL, X_HH, Y, numEpochs, weights_file)\n",
        "    \n",
        "    X_LL = None\n",
        "    X_LH = None\n",
        "    X_HL = None \n",
        "    X_HH = None\n",
        "    Y = None\n",
        "\n",
        "    return modelName\n",
        "    # evaluate(model, X_LL_test,X_LH_test,X_HL_test,X_HH_test,Y_test)\n",
        "    \n",
        "\n",
        "def trainCNNModel(superpoch, dataSetNumber, X_LL_train, X_LH_train, X_HL_train, X_HH_train, y_train, num_epochs, weights_file):\n",
        "\n",
        "    batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "    print(\"SHAPE\")\n",
        "    print(X_LL_train.shape);\n",
        "    num_train, height, width, depth = X_LL_train.shape\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "    # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "\n",
        "    checkPointFolder = '/content/drive/MyDrive/Moire/checkPoint'\n",
        "    checkpoint_name = checkPointFolder + '/mid-sp' + superpoch + '-ds' + dataSetNumber[0] + '_' + dataSetNumber[1] + '-ep{epoch:03d}-ls{val_loss:.5f}-ac{val_accuracy:.2f}-weights' \n",
        "    checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "    callbacks_list = [checkpoint]\n",
        "    \n",
        "    if not os.path.exists(checkPointFolder):\n",
        "        os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "    model = None\n",
        "    # if preloaded_model == None:\n",
        "    #   print('A preloaded model was not provided.  Creating a new one')\n",
        "    #   model, _ = createModel(height, width, depth, num_classes)\n",
        "\n",
        "    if weights_file != None:\n",
        "      print('--- Loading weights file: ' + weights_file)\n",
        "      model = keras.models.load_model(weights_file)\n",
        "    else:\n",
        "      print('--- No weights file provided.  Compiling a new one.')\n",
        "      \n",
        "      model, _ = createModel(height, width, depth, num_classes)\n",
        "      model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "                    optimizer='adam', # using the Adam optimiser\n",
        "                    metrics=['accuracy']) # reporting the accuracy\n",
        "      # if preloaded_model == None:\n",
        "        \n",
        "      # else:\n",
        "      #   print('--- Model already loaded with weights.  Skipping compilation')\n",
        "\n",
        "    model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "              batch_size=batch_size, epochs=num_epochs,\n",
        "              verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "    # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "    # print('------ weights ------')\n",
        "    # for i in range(len(model.layers)):\n",
        "    #   print(len(model.layers[i].get_weights()))\n",
        "\n",
        "    modelName = '/content/drive/MyDrive/Moire/checkPoint/final-tm' + str(time.time()).split('.')[0] + '-sp' + superpoch + '-ds' + dataSetNumber[0] + '_' + dataSetNumber[1] + '-weights'\n",
        "    model.save(modelName)\n",
        "    \n",
        "    return modelName\n",
        "\n",
        "\n",
        "def evaluate(model, X_LL_test,X_LH_test,X_HL_test,X_HH_test,y_test):\n",
        "\n",
        "    model_out = model.predict([X_LL_test,X_LH_test,X_HL_test,X_HH_test])\n",
        "    passCnt = 0\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "    positive_confidence_threshold = 0.5\n",
        "    incorrect_threshold_count = 0\n",
        "    largest_fp = 0\n",
        "    smallest_tp = 2\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "            str_label='Pass'\n",
        "            passCnt = passCnt + 1\n",
        "        else:\n",
        "            str_label='Fail'\n",
        "\n",
        "        if y_test[i] ==0:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                if model_out[i, 0] < smallest_tp:\n",
        "                  smallest_tp = model_out[i, 0]\n",
        "                # print('TP' + str(model_out[i, :]))\n",
        "                TP = TP + 1;\n",
        "            else:\n",
        "                # print('FN' + str(model_out[i, :]))\n",
        "                FN = FN + 1\n",
        "        else:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                # print('TN' + str(model_out[i, :]))\n",
        "                TN = TN + 1;\n",
        "            else:\n",
        "                if model_out[i, 1] > largest_fp:\n",
        "                  largest_fp = model_out[i, 1]\n",
        "                # print('FP' + str(model_out[i, :]))\n",
        "                FP = FP + 1\n",
        "\n",
        "        if model_out[i, 0] > positive_confidence_threshold and y_test[i] == 1:\n",
        "          incorrect_threshold_count = incorrect_threshold_count + 1\n",
        "\n",
        "    start = \"\\033[1m\"\n",
        "    end = \"\\033[0;0m\"\n",
        "\n",
        "    print(start + 'incorrect positives with threshold: ' + end + str(incorrect_threshold_count))\n",
        "    print(start + 'largest false positive confidence: ' + end + str(largest_fp))\n",
        "    print(start + 'smalles true positive confidence: ' + end + str(smallest_tp))\n",
        "    print(start + 'confusion matrix (test / validation)' + end)\n",
        "    print(start + 'true positive:  '+ end + str(TP))\n",
        "    print(start + 'false positive: '+ end + str(FP))\n",
        "    print(start + 'true negative:  '+ end + str(TN))\n",
        "    print(start + 'false negative: '+ end + str(FN))\n",
        "    print('\\n')\n",
        "\n",
        "    if TP+FP+FN+TN != 0:\n",
        "      print(start + 'accuracy:  ' + end + \"{:.4f} %\".format(100*(TP+TN)/(TP+FP+FN+TN)))\n",
        "    else:\n",
        "      print(start + 'accuracy:  ' + end + \"{:.4f} %\".format(100))\n",
        "\n",
        "    if TP + FP != 0:\n",
        "      print(start + 'precision: ' + end + \"{:.4f} %\".format(100*TP/(TP + FP)))\n",
        "    else:\n",
        "      print(start + 'precision: ' + end + \"{:.4f} %\".format(100))\n",
        "\n",
        "    if TP + FN != 0:\n",
        "      print(start + 'recall:  ' + end + \"{:.4f} %\".format(100*TP/(TP + FN)))\n",
        "    else:\n",
        "      print(start + 'recall:  ' + end + \"{:.4f} %\".format(100))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWnNYpcTqa_O"
      },
      "source": [
        "## Test CNN Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV0rGdyIueOf"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "#constants\n",
        "width = 500#384 #change dimensions according to the input image in the training\n",
        "height = 375#512 #change dimensions according to the input image in the training\n",
        "depth = 1\n",
        "num_classes = 2\n",
        "\n",
        "def testMoire(weightsFile, superpoch, dataSetNumber):\n",
        "\n",
        "    print('##### TESTING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber[0] + ', ' + dataSetNumber[1])\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(dataSetNumber[0], 'test')\n",
        "    X_LL_2, X_LH_2, X_HL_2, X_HH_2, Y_2 = mainReadDatafromDrive(dataSetNumber[1], 'test')\n",
        "\n",
        "    print('Concatenating 2 datasets.')\n",
        "    X_LL = np.concatenate((X_LL, X_LL_2), axis=0)\n",
        "    X_LH = np.concatenate((X_LH, X_LH_2), axis=0)\n",
        "    X_HL = np.concatenate((X_HL, X_HL_2), axis=0)\n",
        "    X_HH = np.concatenate((X_HH, X_HH_2), axis=0)\n",
        "    Y = np.concatenate((Y, Y_2), axis=0)\n",
        "    X_LL_2 = None\n",
        "    X_LH_2 = None\n",
        "    X_HL_2 = None\n",
        "    X_HH_2 = None\n",
        "    Y_2 = None\n",
        "    \n",
        "    CNN_model = keras.models.load_model(weightsFile)\n",
        "    evaluate(CNN_model,X_LL,X_LH,X_HL,X_HH, Y)\n",
        "    X_LL = None\n",
        "    X_LH = None\n",
        "    X_HL = None \n",
        "    X_HH = None\n",
        "    Y = None\n",
        "\n",
        "def run(model, X_LL_test,X_LH_test,X_HL_test,y_test):\n",
        "    return\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmyNG_XqMzIb"
      },
      "source": [
        "## Synthesize Data\n",
        "Synthesize random data wooo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELZtp0_bM3rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a800fc-24dd-474e-cc7d-8178d4e5016d"
      },
      "source": [
        "import os\n",
        "from os.path import isfile, join\n",
        "from PIL import Image, ImageDraw, ImageFilter\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "colors = ['orange', 'blue', 'yellow', 'red', 'green', 'purple']\n",
        "\n",
        "def randomColor():\n",
        "  return colors[random.randint(0, 5)]\n",
        "\n",
        "def getBoundingBox(minWidth, maxWidth, minHeight, maxHeight):\n",
        "  length = random.randint(minWidth, maxWidth)\n",
        "  length1 = random.randint(minHeight, maxHeight)\n",
        "  w, h = length, length1\n",
        "  x = random.randint(0, 1000 - length)\n",
        "  y = random.randint(0, 750 - length1)\n",
        "  return [(x, y), (w + x, h + y)]\n",
        "\n",
        "def getBoundingSquare(minWidth, maxWidth):\n",
        "  length = random.randint(minWidth, maxWidth)\n",
        "  w, h = length, length\n",
        "  x = random.randint(0, 1000 - length)\n",
        "  y = random.randint(0, 750 - length)\n",
        "  return [(x, y), (w + x, h + y)]\n",
        "\n",
        "def getBoxFromSize(widthSize, heightSize, square = False):\n",
        "\n",
        "  minHeight = 0\n",
        "  maxHeight = 0\n",
        "  minWidth = 0\n",
        "  maxWidth = 0\n",
        "\n",
        "  if widthSize == 'small':\n",
        "    minWidth = 25\n",
        "    maxWidth = 100\n",
        "  elif widthSize == 'medium':\n",
        "    minWidth = 120\n",
        "    maxWidth = 280\n",
        "  elif widthSize == 'large':\n",
        "    minWidth = 280\n",
        "    maxWidth = 450\n",
        "  elif widthSize == 'x-large':\n",
        "    minWidth = 450\n",
        "    maxWidth = 620\n",
        "  elif widthSize == 'xx-large':\n",
        "    minWidth = 620\n",
        "    maxWidth = 900\n",
        "  else:\n",
        "    raise ValueError('width was not the proper value')\n",
        "\n",
        "  if heightSize == 'small':\n",
        "    minHeight = 25\n",
        "    maxHeight = 100\n",
        "  elif heightSize == 'medium':\n",
        "    minHeight = 120\n",
        "    maxHeight = 280\n",
        "  elif heightSize == 'large':\n",
        "    minHeight = 280\n",
        "    maxHeight = 450\n",
        "  elif heightSize == 'x-large':\n",
        "    minHeight = 450\n",
        "    maxHeight = 620\n",
        "  else:\n",
        "    raise ValueError('height was not the proper value')\n",
        "\n",
        "  if square == True:\n",
        "    return getBoundingSquare(minWidth, maxWidth)\n",
        "  else:\n",
        "    return getBoundingBox(minWidth, maxWidth, minHeight, maxHeight)\n",
        "\n",
        "def getRandomPointInRegion(shape):\n",
        "  return (random.randint(shape[0][0], shape[1][0]), random.randint(shape[0][1], shape[1][1]))\n",
        "\n",
        "def circle(image, imageConfig):\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make a circle')\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, True)\n",
        "    draw.chord(shape, start=0, end=360, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def ellipse(image, imageConfig):\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make an ellipse')\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    draw.chord(shape, start=0, end=360, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def chord(image, imageConfig):\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make a chord')\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    start = random.randint(30, 145)\n",
        "    end = random.randint(225, 340)\n",
        "    draw.chord(shape, start=start, end=end, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def rectangle(image, imageConfig):\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make a rectangle')\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    draw.rectangle(shape, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def square(image, imageConfig):\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make a square')\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, True)\n",
        "    draw.rectangle(shape, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def pieslice(image, imageConfig):\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make a pieslice')\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, True)\n",
        "    start = random.randint(30, 145)\n",
        "    end = random.randint(225, 340)\n",
        "    draw.pieslice(shape, start=start, end=end, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def line(image, imageConfig):\n",
        "\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make a pieslice')\n",
        "    if imageConfig.sides == None:\n",
        "      raise ValueError('number of sides (lines) need to be specified to make a line group')\n",
        "    if imageConfig.noiseLow == None or imageConfig.noiseHigh == None:\n",
        "      raise ValueError('noise-low (low-line-width) and noise-high (high-line-width) need to be specified to create line groups in image')\n",
        "\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    pointRegion1 = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    pointRegion2 = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "\n",
        "    width=random.randint(imageConfig.noiseLow,imageConfig.noiseHigh)\n",
        "\n",
        "    for i in range(random.randint(max(round(imageConfig.sides / 3), 1), imageConfig.sides)):\n",
        "      points = [getRandomPointInRegion(pointRegion1), getRandomPointInRegion(pointRegion2)]\n",
        "      draw.line(points, width=width, fill=randomColor(), joint=\"curve\")\n",
        "\n",
        "\n",
        "def polygon(image, imageConfig):\n",
        "    if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to make a polygon')\n",
        "    if imageConfig.sides == None:\n",
        "      raise ValueError('The number of sides was not specified')\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    point = None\n",
        "\n",
        "    sides = random.randint(max(round(imageConfig.sides / 2), 3), imageConfig.sides)\n",
        "\n",
        "    if sides < 3:\n",
        "      raise ValueError('There needs to be three or more sides')\n",
        "    elif sides > 10:\n",
        "      raise ValueError('There needs to be ten or less sides')\n",
        "    elif sides == 3:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif sides == 4:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif sides == 5:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif sides == 6:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif sides == 7:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif sides == 8:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif sides == 9:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif sides == 10:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "\n",
        "    draw.polygon(points, fill=randomColor())\n",
        "    \n",
        "def noise(image, imageConfig):\n",
        "  if imageConfig.noiseLow == None or imageConfig.noiseHigh == None:\n",
        "      raise ValueError('noise-low and noise-high need to be specified to create noise in image')\n",
        "  \n",
        "  imageData = image.getdata()\n",
        "  threshold = random.randint(imageConfig.noiseLow, imageConfig.noiseHigh)\n",
        "  newImageData = []\n",
        "\n",
        "  for pixel in imageData:\n",
        "    if random.randint(0, 100) < threshold:\n",
        "      newImageData.append((random.randint(25, 255), random.randint(25, 255), random.randint(25, 255)))\n",
        "    else:\n",
        "      newImageData.append(pixel)\n",
        "\n",
        "  noisy = Image.new(image.mode, image.size)\n",
        "  noisy.putdata(newImageData)\n",
        "  return noisy\n",
        "\n",
        "def localNoise(image, imageConfig):\n",
        "  if imageConfig.noiseLow == None or imageConfig.noiseHigh == None:\n",
        "      raise ValueError('noise-low and noise-high need to be specified to create noise in image')\n",
        "  if imageConfig.widthClass == None or imageConfig.heightClass == None:\n",
        "      raise ValueError('width and height class need to be specified to create localized noise in image')\n",
        "\n",
        "  shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "\n",
        "  lowWidth = shape[0][0]\n",
        "  highWidth = shape[1][0]\n",
        "  lowHeight = shape[0][1]\n",
        "  highHeight = shape[1][1]\n",
        "\n",
        "  imageData = image.getdata()\n",
        "  threshold = random.randint(imageConfig.noiseLow, imageConfig.noiseHigh)\n",
        "  newImageData = []\n",
        "\n",
        "  for i in range(len(imageData)):\n",
        "    x = i % 1000\n",
        "    y = i / 1000\n",
        "\n",
        "    inRegion = x > lowWidth and x < highWidth and y > lowHeight and y < highHeight\n",
        "\n",
        "    if random.randint(0, 100) < threshold and inRegion:\n",
        "      newImageData.append((random.randint(25, 255), random.randint(25, 255), random.randint(25, 255)))\n",
        "    else:\n",
        "      newImageData.append(imageData[i])\n",
        "\n",
        "  noisy = Image.new(image.mode, image.size)\n",
        "  noisy.putdata(newImageData)\n",
        "  return noisy\n",
        "\n",
        "def cropShape(cropContour, imageConfig):\n",
        "  files = [name for name in os.listdir(imageConfig.inputImageDirPath)]\n",
        "  cropFile = files[random.randint(0, len(files) - 1)]\n",
        "  img = Image.open(join(imageConfig.inputImageDirPath, cropFile))\n",
        "\n",
        "  # blankImageData = np.full((750, 1000), 255, np.uint8)\n",
        "  # image = Image.fromarray(blankImageData)\n",
        "\n",
        "  # if image.mode != 'RGB':\n",
        "  #   image = image.convert('RGB')\n",
        "\n",
        "  cropContourImageData = cropContour.getdata()\n",
        "  croppedImageData = img.getdata()\n",
        "\n",
        "  newImageData = []\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  print(cropContourImageData)\n",
        "  print(len(cropContourImageData))\n",
        "  for i in range(len(cropContourImageData)):\n",
        "    # print(cropContourImageData[i])\n",
        "    if cropContourImageData[i][0] < 255 or cropContourImageData[i][1] < 255 or cropContourImageData[i][2] < 255:\n",
        "      \n",
        "      count = count + 1\n",
        "      newImageData.append(croppedImageData[i])\n",
        "    else:\n",
        "      newImageData.append((255,255,255))\n",
        "\n",
        "  print(count)\n",
        "  cropped = Image.new(cropContour.mode, cropContour.size)\n",
        "  cropped.putdata(newImageData)\n",
        "  return cropped\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "class ImageConfig(object):\n",
        "    def __init__(self, process, widthClass = None, heightClass = None, amount = None, sides = None, noiseLow = 0, noiseHigh = 0):\n",
        "        self.process = process\n",
        "        self.widthClass = widthClass\n",
        "        self.heightClass = heightClass\n",
        "        self.amount = amount\n",
        "        self.sides = sides\n",
        "        self.noiseLow = noiseLow\n",
        "        self.noiseHigh = noiseHigh\n",
        "\n",
        "class ShapeCropConfig(object):\n",
        "  def __init__(self, process, inputImageDirPath):\n",
        "    self.process = process\n",
        "    self.inputImageDirPath = inputImageDirPath\n",
        "\n",
        "def generateFakeImages(imageConfigList, dataset, i):\n",
        "  imageData = np.full((750, 1000), 255, np.uint8)\n",
        "  image = Image.fromarray(imageData)\n",
        "\n",
        "  if image.mode != 'RGB':\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "  for config in imageConfigList:\n",
        "    \n",
        "\n",
        "    if isinstance(config, ImageConfig):\n",
        "      if config.amount == None:\n",
        "        config.amount = 1\n",
        "\n",
        "      if config.process == 'circle':\n",
        "        for number in range(config.amount):\n",
        "          circle(image, config)\n",
        "      if config.process == 'chord':\n",
        "        for number in range(config.amount):\n",
        "          chord(image, config)\n",
        "      if config.process == 'pieslice':\n",
        "        for number in range(config.amount):\n",
        "          pieslice(image, config)\n",
        "      if config.process == 'square':\n",
        "        for number in range(config.amount):\n",
        "          square(image, config)\n",
        "      if config.process == 'ellipse':\n",
        "        for number in range(config.amount):\n",
        "          ellipse(image, config)\n",
        "      if config.process == 'rectangle':\n",
        "        for number in range(config.amount):\n",
        "          rectangle(image, config)\n",
        "      if config.process == 'polygon':\n",
        "        for number in range(config.amount):\n",
        "          polygon(image, config)\n",
        "      if config.process == 'line':\n",
        "        for number in range(config.amount):\n",
        "          line(image, config)\n",
        "      if config.process == 'noise':\n",
        "        for number in range(config.amount):\n",
        "          image = noise(image, config)\n",
        "      if config.process == 'local-noise':\n",
        "        for number in range(config.amount):\n",
        "          image = localNoise(image, config)\n",
        "    if isinstance(config, ShapeCropConfig):\n",
        "      if config.process == 'crop-shape':\n",
        "        image = cropShape(image, config)\n",
        "\n",
        "  # image.filter(ImageFilter.SMOOTH)\n",
        "  image.save('/content/drive/MyDrive/Moire/unnormalized/negative/' + dataset + '/' + str(i) + '.png')\n",
        "      \n",
        "      \n",
        "\n",
        "imageConfigList18 = []\n",
        "\n",
        "# 018\n",
        "# imageConfigList18.append(ImageConfig('circle', 'large', 'large', 4))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'small', 'medium', 5))\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'small', 'large', 8, 8))\n",
        "# imageConfigList18.append(ImageConfig('line', 'small', 'small', amount = 4, sides = 5, noiseLow = 2, noiseHigh = 5))\n",
        "\n",
        "# 019\n",
        "# imageConfigList18.append(ImageConfig('circle', 'small', 'small', 4))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'small', 'medium', 5))\n",
        "# imageConfigList18.append(ImageConfig('square', 'medium', 'medium', 5))\n",
        "# imageConfigList18.append(ImageConfig('noise', 'small', 'small', amount = 1, noiseLow = 10, noiseHigh = 50))\n",
        "# imageConfigList18.append(ImageConfig('line', 'small', 'small', amount = 4, sides = 5, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'large', 'small', 12, 9))\n",
        "\n",
        "# 020\n",
        "# imageConfigList18.append(ImageConfig('local-noise', 'small', 'small', amount = 10, noiseLow = 10, noiseHigh = 40))\n",
        "# imageConfigList18.append(ImageConfig('local-noise', 'medium', 'small', amount = 7, noiseLow = 10, noiseHigh = 40))\n",
        "# imageConfigList18.append(ImageConfig('local-noise', 'medium', 'large', amount = 5, noiseLow = 10, noiseHigh = 40))\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'large', 'small', 12, 3))\n",
        "# imageConfigList18.append(ImageConfig('local-noise', 'small', 'medium', amount = 7, noiseLow = 10, noiseHigh = 40))\n",
        "\n",
        "# 021\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'medium', 'small', amount = 10))\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'large', 'small', 20, 6))\n",
        "# imageConfigList18.append(ImageConfig('local-noise', 'medium', 'large', amount = 5, noiseLow = 10, noiseHigh = 40))\n",
        "# imageConfigList18.append(ImageConfig('circle', 'small', 'small', amount = 20))\n",
        "\n",
        "# 022\n",
        "# imageConfigList18.append(ImageConfig('line', 'small', 'small', amount = 8, sides = 6, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('line', 'medium', 'medium', amount = 8, sides = 5, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('line', 'large', 'large', amount = 8, sides = 4, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('line', 'x-large', 'x-large', amount = 8, sides = 3, noiseLow = 2, noiseHigh = 5))\n",
        "\n",
        "# 023\n",
        "# imageConfigList18.append(ImageConfig('line', 'small', 'small', amount = 5, sides = 6, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('line', 'medium', 'medium', amount = 5, sides = 5, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('line', 'large', 'large', amount = 5, sides = 4, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('line', 'x-large', 'x-large', amount = 5, sides = 3, noiseLow = 2, noiseHigh = 5))\n",
        "# imageConfigList18.append(ImageConfig('noise', 'small', 'small', amount = 1, noiseLow = 10, noiseHigh = 50))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'medium', 'small', amount = 10))\n",
        "# imageConfigList18.append(ImageConfig('square', 'medium', 'medium', 5))\n",
        "# imageConfigList18.append(ImageConfig('local-noise', 'medium', 'large', amount = 6, noiseLow = 10, noiseHigh = 40))\n",
        "\n",
        "# 024\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'large', 'small', 12, 3))\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'medium', 'medium', 12, 6))\n",
        "# imageConfigList18.append(ShapeCropConfig('crop-shape', '/content/drive/MyDrive/Moire/preaugmented/negative/006'))\n",
        "\n",
        "# 025\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'large', 'small', 12, 3))\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'medium', 'medium', 12, 6))\n",
        "# imageConfigList18.append(ImageConfig('square', 'medium', 'medium', 5))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'medium', 'medium', amount = 10))\n",
        "# imageConfigList18.append(ShapeCropConfig('crop-shape', '/content/drive/MyDrive/Moire/preaugmented/negative/007'))\n",
        "\n",
        "# 026\n",
        "imageConfigList18.append(ImageConfig('circle', 'large', 'large', amount = 10))\n",
        "imageConfigList18.append(ImageConfig('polygon', 'large', 'small', 12, 3))\n",
        "imageConfigList18.append(ImageConfig('polygon', 'medium', 'medium', 12, 6))\n",
        "imageConfigList18.append(ImageConfig('square', 'medium', 'medium', 5))\n",
        "imageConfigList18.append(ImageConfig('pieslice', 'medium', 'medium', amount = 10))\n",
        "imageConfigList18.append(ShapeCropConfig('crop-shape', '/content/drive/MyDrive/Moire/preaugmented/negative/008'))\n",
        "\n",
        "# imageConfigList18.append(ImageConfig('polygon', 'large', 'small', 12, 3))\n",
        "# imageConfigList18.append(ImageConfig('local-noise', 'small', 'medium', amount = 7, noiseLow = 10, noiseHigh = 40))\n",
        "# imageConfigList18.append(ImageConfig('circle', 'large', 'x-large', 3))\n",
        "# imageConfigList18.append(ImageConfig('circle', 'small', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('circle', 'large', 'x-large', 3))\n",
        "# imageConfigList18.append(ImageConfig('chord', 'large', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('chord', 'x-large', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('chord', 'small', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('square', 'medium', 'medium', 5))\n",
        "# imageConfigList18.append(ImageConfig('ellipse', 'small', 'small', 5))\n",
        "# imageConfigList18.append(ImageConfig('rectangle', 'small', 'small', 5))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'large', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'medium', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'large', 'large', 5))\n",
        "\n",
        "dataset = '026'\n",
        "dir = '/content/drive/MyDrive/Moire/unnormalized/negative/' + dataset\n",
        "\n",
        "if len([name for name in os.listdir(dir)]) > 0:\n",
        "  print('Directory ' + dir + ' already has normalized photos in it.  Skipping normalization for negative photos.')\n",
        "else:\n",
        "  for i in range(30):\n",
        "    print(i)\n",
        "    generateFakeImages(imageConfigList18, dataset, i)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory /content/drive/MyDrive/Moire/unnormalized/negative/026 already has normalized photos in it.  Skipping normalization for negative photos.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agjwCacSQyN0",
        "outputId": "5732ead6-6cea-4065-f619-293b8405438c"
      },
      "source": [
        "isinstance(ImageConfig('line', 'small', 'small', amount = 5, sides = 6, noiseLow = 2, noiseHigh = 5), int)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPksVriW1E8W"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "my_img = np.full((750, 1000, 3), 255, np.uint8)\n",
        "# my_img = np.zeros((400, 400, 3), dtype = \"uint8\")\n",
        "pts = np.array([[80,261],[110,296],[260,306],[150,276]], np.int32)\n",
        "\n",
        "pts = pts.reshape((-1,1,2))\n",
        "\n",
        "cv2.ellipse(my_img,(256,256),(200,100),0,0,180,255,-1)\n",
        "cv2.polylines(my_img,[pts],True,(0,255,255))\n",
        "\n",
        "image = Image.fromarray(my_img)\n",
        "image.save(\"opencv.jpeg\")\n",
        "# cv2.imshow('Window', my_img)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91EoQyF2543f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c40faf5-7a5a-4e7c-dba7-31c8d0f269b3"
      },
      "source": [
        "from IPython.display import Image as ImageDisplay\n",
        "# Image('/content/drive/MyDrive/Moire/unnormalized/negative/018/28.jpeg')\n",
        "ImageDisplay('/content/drive/MyDrive/Moire/unnormalized/negative/020/29.jpeg')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "/content/drive/MyDrive/Moire/unnormalized/negative/020/29.jpeg",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTxUTR6Yv2LG"
      },
      "source": [
        "## Extended Training\n",
        "Take the trained model and continue training with additional data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_fb9-mhtcBbo",
        "outputId": "499aad71-5d2c-4b9d-a333-ae2147a2fad1"
      },
      "source": [
        "# normalizeRawImages(\"001\", \"001\")\n",
        "# augmentNormalizedData(\"001\", \"001\")\n",
        "# normalizeRawImages(\"001\", \"002\")\n",
        "# augmentNormalizedData(\"001\", \"002\")\n",
        "# normalizeRawImages(\"001\", \"003\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"003\")\n",
        "# normalizeRawImages(\"001\", \"004\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"004\")\n",
        "# normalizeRawImages(\"001\", \"005\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"005\")\n",
        "# normalizeRawImages(\"001\", \"006\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"006\")\n",
        "\n",
        "# weights_file = '/content/drive/MyDrive/Moire/checkPoint/final-tm1626925731-sp001-ds020_013-weights'\n",
        "weights_file = None\n",
        "\n",
        "superpoch_count = 3\n",
        "scramblepoch_count = 3\n",
        "epochs = 20\n",
        "datasets = ['024', '025', '026']\n",
        "\n",
        "for sp in range(superpoch_count):\n",
        "  superpoch = '00' + str(sp + 1)\n",
        "  print('---------------------------------------------------------')\n",
        "  print('BEGINNING TRAINING OF SUPERPOCH: ' + superpoch)\n",
        "  print('---------------------------------------------------------')\n",
        "  for ds in range(len(datasets)):\n",
        "    dsIndex = ds\n",
        "    otherDsIndex = ((ds + 1) % len(datasets))\n",
        "    # datasets = ['00' + str(dsNumber), '00' + str(otherDsNumber)]\n",
        "    print([datasets[dsIndex], datasets[otherDsIndex]])\n",
        "\n",
        "    # print(ds)\n",
        "    # print(i)\n",
        "\n",
        "    # print(datasets)\n",
        "    # normalizeRawImages(superpoch, dataset)\n",
        "    # augmentNormalizedData(superpoch, dataset)\n",
        "\n",
        "    weights_file = trainMoire(superpoch, [datasets[dsIndex], datasets[otherDsIndex]], epochs, weights_file)\n",
        "    testMoire(weights_file, superpoch, [datasets[dsIndex], datasets[otherDsIndex]])\n",
        "    print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "# for scp in range(scramblepoch_count):\n",
        "#   '/content/drive/MyDrive/Moire/'\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------\n",
            "BEGINNING TRAINING OF SUPERPOCH: 001\n",
            "---------------------------------------------------------\n",
            "['024', '025']\n",
            "##### TRAINING - superpoch: 001 - dataset: 024,  025\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "/content/drive/MyDrive/Moire/train/negative/024/\n",
            "positive samples: 288\n",
            "negative samples: 288\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_LL.tiff\n",
            "IMG_3886_LL.tiff\n",
            "IMG_3886_LL.tiff\n",
            "IMG_3886_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_LH.tiff\n",
            "IMG_3886_LH.tiff\n",
            "IMG_3886_LH.tiff\n",
            "IMG_3886_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_HL.tiff\n",
            "IMG_3886_HL.tiff\n",
            "IMG_3886_HL.tiff\n",
            "IMG_3886_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_HH.tiff\n",
            "IMG_3886_HH.tiff\n",
            "IMG_3886_HH.tiff\n",
            "IMG_3886_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_LL.tiff\n",
            "IMG_3886_180_LL.tiff\n",
            "IMG_3886_180_LL.tiff\n",
            "IMG_3886_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_LH.tiff\n",
            "IMG_3886_180_LH.tiff\n",
            "IMG_3886_180_LH.tiff\n",
            "IMG_3886_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_HL.tiff\n",
            "IMG_3886_180_HL.tiff\n",
            "IMG_3886_180_HL.tiff\n",
            "IMG_3886_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_HH.tiff\n",
            "IMG_3886_180_HH.tiff\n",
            "IMG_3886_180_HH.tiff\n",
            "IMG_3886_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_FLIP_LL.tiff\n",
            "IMG_3886_180_FLIP_LL.tiff\n",
            "IMG_3886_180_FLIP_LL.tiff\n",
            "IMG_3886_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_FLIP_LH.tiff\n",
            "IMG_3886_180_FLIP_LH.tiff\n",
            "IMG_3886_180_FLIP_LH.tiff\n",
            "IMG_3886_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_FLIP_HL.tiff\n",
            "IMG_3886_180_FLIP_HL.tiff\n",
            "IMG_3886_180_FLIP_HL.tiff\n",
            "IMG_3886_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3886_180_FLIP_HH.tiff\n",
            "IMG_3886_180_FLIP_HH.tiff\n",
            "IMG_3886_180_FLIP_HH.tiff\n",
            "IMG_3886_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_LL.tiff\n",
            "IMG_3865_LL.tiff\n",
            "IMG_3865_LL.tiff\n",
            "IMG_3865_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_LH.tiff\n",
            "IMG_3865_LH.tiff\n",
            "IMG_3865_LH.tiff\n",
            "IMG_3865_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_HL.tiff\n",
            "IMG_3865_HL.tiff\n",
            "IMG_3865_HL.tiff\n",
            "IMG_3865_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_HH.tiff\n",
            "IMG_3865_HH.tiff\n",
            "IMG_3865_HH.tiff\n",
            "IMG_3865_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_LL.tiff\n",
            "IMG_3865_180_LL.tiff\n",
            "IMG_3865_180_LL.tiff\n",
            "IMG_3865_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_LH.tiff\n",
            "IMG_3865_180_LH.tiff\n",
            "IMG_3865_180_LH.tiff\n",
            "IMG_3865_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_HL.tiff\n",
            "IMG_3865_180_HL.tiff\n",
            "IMG_3865_180_HL.tiff\n",
            "IMG_3865_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_HH.tiff\n",
            "IMG_3865_180_HH.tiff\n",
            "IMG_3865_180_HH.tiff\n",
            "IMG_3865_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_FLIP_LL.tiff\n",
            "IMG_3865_180_FLIP_LL.tiff\n",
            "IMG_3865_180_FLIP_LL.tiff\n",
            "IMG_3865_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_FLIP_LH.tiff\n",
            "IMG_3865_180_FLIP_LH.tiff\n",
            "IMG_3865_180_FLIP_LH.tiff\n",
            "IMG_3865_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_FLIP_HL.tiff\n",
            "IMG_3865_180_FLIP_HL.tiff\n",
            "IMG_3865_180_FLIP_HL.tiff\n",
            "IMG_3865_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3865_180_FLIP_HH.tiff\n",
            "IMG_3865_180_FLIP_HH.tiff\n",
            "IMG_3865_180_FLIP_HH.tiff\n",
            "IMG_3865_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_LL.tiff\n",
            "IMG_3872_LL.tiff\n",
            "IMG_3872_LL.tiff\n",
            "IMG_3872_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_LH.tiff\n",
            "IMG_3872_LH.tiff\n",
            "IMG_3872_LH.tiff\n",
            "IMG_3872_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_HL.tiff\n",
            "IMG_3872_HL.tiff\n",
            "IMG_3872_HL.tiff\n",
            "IMG_3872_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_HH.tiff\n",
            "IMG_3872_HH.tiff\n",
            "IMG_3872_HH.tiff\n",
            "IMG_3872_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_LL.tiff\n",
            "IMG_3872_180_LL.tiff\n",
            "IMG_3872_180_LL.tiff\n",
            "IMG_3872_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_LH.tiff\n",
            "IMG_3872_180_LH.tiff\n",
            "IMG_3872_180_LH.tiff\n",
            "IMG_3872_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_HL.tiff\n",
            "IMG_3872_180_HL.tiff\n",
            "IMG_3872_180_HL.tiff\n",
            "IMG_3872_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_HH.tiff\n",
            "IMG_3872_180_HH.tiff\n",
            "IMG_3872_180_HH.tiff\n",
            "IMG_3872_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_FLIP_LL.tiff\n",
            "IMG_3872_180_FLIP_LL.tiff\n",
            "IMG_3872_180_FLIP_LL.tiff\n",
            "IMG_3872_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_FLIP_LH.tiff\n",
            "IMG_3872_180_FLIP_LH.tiff\n",
            "IMG_3872_180_FLIP_LH.tiff\n",
            "IMG_3872_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_FLIP_HL.tiff\n",
            "IMG_3872_180_FLIP_HL.tiff\n",
            "IMG_3872_180_FLIP_HL.tiff\n",
            "IMG_3872_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3872_180_FLIP_HH.tiff\n",
            "IMG_3872_180_FLIP_HH.tiff\n",
            "IMG_3872_180_FLIP_HH.tiff\n",
            "IMG_3872_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_LL.tiff\n",
            "IMG_3880_LL.tiff\n",
            "IMG_3880_LL.tiff\n",
            "IMG_3880_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_LH.tiff\n",
            "IMG_3880_LH.tiff\n",
            "IMG_3880_LH.tiff\n",
            "IMG_3880_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_HL.tiff\n",
            "IMG_3880_HL.tiff\n",
            "IMG_3880_HL.tiff\n",
            "IMG_3880_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_HH.tiff\n",
            "IMG_3880_HH.tiff\n",
            "IMG_3880_HH.tiff\n",
            "IMG_3880_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_LL.tiff\n",
            "IMG_3880_180_LL.tiff\n",
            "IMG_3880_180_LL.tiff\n",
            "IMG_3880_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_LH.tiff\n",
            "IMG_3880_180_LH.tiff\n",
            "IMG_3880_180_LH.tiff\n",
            "IMG_3880_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_HL.tiff\n",
            "IMG_3880_180_HL.tiff\n",
            "IMG_3880_180_HL.tiff\n",
            "IMG_3880_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_HH.tiff\n",
            "IMG_3880_180_HH.tiff\n",
            "IMG_3880_180_HH.tiff\n",
            "IMG_3880_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_FLIP_LL.tiff\n",
            "IMG_3880_180_FLIP_LL.tiff\n",
            "IMG_3880_180_FLIP_LL.tiff\n",
            "IMG_3880_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_FLIP_LH.tiff\n",
            "IMG_3880_180_FLIP_LH.tiff\n",
            "IMG_3880_180_FLIP_LH.tiff\n",
            "IMG_3880_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_FLIP_HL.tiff\n",
            "IMG_3880_180_FLIP_HL.tiff\n",
            "IMG_3880_180_FLIP_HL.tiff\n",
            "IMG_3880_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3880_180_FLIP_HH.tiff\n",
            "IMG_3880_180_FLIP_HH.tiff\n",
            "IMG_3880_180_FLIP_HH.tiff\n",
            "IMG_3880_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_LL.tiff\n",
            "IMG_3879_LL.tiff\n",
            "IMG_3879_LL.tiff\n",
            "IMG_3879_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_LH.tiff\n",
            "IMG_3879_LH.tiff\n",
            "IMG_3879_LH.tiff\n",
            "IMG_3879_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_HL.tiff\n",
            "IMG_3879_HL.tiff\n",
            "IMG_3879_HL.tiff\n",
            "IMG_3879_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_HH.tiff\n",
            "IMG_3879_HH.tiff\n",
            "IMG_3879_HH.tiff\n",
            "IMG_3879_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_LL.tiff\n",
            "IMG_3879_180_LL.tiff\n",
            "IMG_3879_180_LL.tiff\n",
            "IMG_3879_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_LH.tiff\n",
            "IMG_3879_180_LH.tiff\n",
            "IMG_3879_180_LH.tiff\n",
            "IMG_3879_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_HL.tiff\n",
            "IMG_3879_180_HL.tiff\n",
            "IMG_3879_180_HL.tiff\n",
            "IMG_3879_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_HH.tiff\n",
            "IMG_3879_180_HH.tiff\n",
            "IMG_3879_180_HH.tiff\n",
            "IMG_3879_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_FLIP_LL.tiff\n",
            "IMG_3879_180_FLIP_LL.tiff\n",
            "IMG_3879_180_FLIP_LL.tiff\n",
            "IMG_3879_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_FLIP_LH.tiff\n",
            "IMG_3879_180_FLIP_LH.tiff\n",
            "IMG_3879_180_FLIP_LH.tiff\n",
            "IMG_3879_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_FLIP_HL.tiff\n",
            "IMG_3879_180_FLIP_HL.tiff\n",
            "IMG_3879_180_FLIP_HL.tiff\n",
            "IMG_3879_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3879_180_FLIP_HH.tiff\n",
            "IMG_3879_180_FLIP_HH.tiff\n",
            "IMG_3879_180_FLIP_HH.tiff\n",
            "IMG_3879_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_LL.tiff\n",
            "IMG_3883_LL.tiff\n",
            "IMG_3883_LL.tiff\n",
            "IMG_3883_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_LH.tiff\n",
            "IMG_3883_LH.tiff\n",
            "IMG_3883_LH.tiff\n",
            "IMG_3883_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_HL.tiff\n",
            "IMG_3883_HL.tiff\n",
            "IMG_3883_HL.tiff\n",
            "IMG_3883_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_HH.tiff\n",
            "IMG_3883_HH.tiff\n",
            "IMG_3883_HH.tiff\n",
            "IMG_3883_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_LL.tiff\n",
            "IMG_3883_180_LL.tiff\n",
            "IMG_3883_180_LL.tiff\n",
            "IMG_3883_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_LH.tiff\n",
            "IMG_3883_180_LH.tiff\n",
            "IMG_3883_180_LH.tiff\n",
            "IMG_3883_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_HL.tiff\n",
            "IMG_3883_180_HL.tiff\n",
            "IMG_3883_180_HL.tiff\n",
            "IMG_3883_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_HH.tiff\n",
            "IMG_3883_180_HH.tiff\n",
            "IMG_3883_180_HH.tiff\n",
            "IMG_3883_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_FLIP_LL.tiff\n",
            "IMG_3883_180_FLIP_LL.tiff\n",
            "IMG_3883_180_FLIP_LL.tiff\n",
            "IMG_3883_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_FLIP_LH.tiff\n",
            "IMG_3883_180_FLIP_LH.tiff\n",
            "IMG_3883_180_FLIP_LH.tiff\n",
            "IMG_3883_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_FLIP_HL.tiff\n",
            "IMG_3883_180_FLIP_HL.tiff\n",
            "IMG_3883_180_FLIP_HL.tiff\n",
            "IMG_3883_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3883_180_FLIP_HH.tiff\n",
            "IMG_3883_180_FLIP_HH.tiff\n",
            "IMG_3883_180_FLIP_HH.tiff\n",
            "IMG_3883_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_LL.tiff\n",
            "IMG_3867_LL.tiff\n",
            "IMG_3867_LL.tiff\n",
            "IMG_3867_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_LH.tiff\n",
            "IMG_3867_LH.tiff\n",
            "IMG_3867_LH.tiff\n",
            "IMG_3867_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_HL.tiff\n",
            "IMG_3867_HL.tiff\n",
            "IMG_3867_HL.tiff\n",
            "IMG_3867_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_HH.tiff\n",
            "IMG_3867_HH.tiff\n",
            "IMG_3867_HH.tiff\n",
            "IMG_3867_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_LL.tiff\n",
            "IMG_3867_180_LL.tiff\n",
            "IMG_3867_180_LL.tiff\n",
            "IMG_3867_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_LH.tiff\n",
            "IMG_3867_180_LH.tiff\n",
            "IMG_3867_180_LH.tiff\n",
            "IMG_3867_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_HL.tiff\n",
            "IMG_3867_180_HL.tiff\n",
            "IMG_3867_180_HL.tiff\n",
            "IMG_3867_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_HH.tiff\n",
            "IMG_3867_180_HH.tiff\n",
            "IMG_3867_180_HH.tiff\n",
            "IMG_3867_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_FLIP_LL.tiff\n",
            "IMG_3867_180_FLIP_LL.tiff\n",
            "IMG_3867_180_FLIP_LL.tiff\n",
            "IMG_3867_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_FLIP_LH.tiff\n",
            "IMG_3867_180_FLIP_LH.tiff\n",
            "IMG_3867_180_FLIP_LH.tiff\n",
            "IMG_3867_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_FLIP_HL.tiff\n",
            "IMG_3867_180_FLIP_HL.tiff\n",
            "IMG_3867_180_FLIP_HL.tiff\n",
            "IMG_3867_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3867_180_FLIP_HH.tiff\n",
            "IMG_3867_180_FLIP_HH.tiff\n",
            "IMG_3867_180_FLIP_HH.tiff\n",
            "IMG_3867_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_LL.tiff\n",
            "IMG_3866_LL.tiff\n",
            "IMG_3866_LL.tiff\n",
            "IMG_3866_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_LH.tiff\n",
            "IMG_3866_LH.tiff\n",
            "IMG_3866_LH.tiff\n",
            "IMG_3866_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_HL.tiff\n",
            "IMG_3866_HL.tiff\n",
            "IMG_3866_HL.tiff\n",
            "IMG_3866_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_HH.tiff\n",
            "IMG_3866_HH.tiff\n",
            "IMG_3866_HH.tiff\n",
            "IMG_3866_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_LL.tiff\n",
            "IMG_3866_180_LL.tiff\n",
            "IMG_3866_180_LL.tiff\n",
            "IMG_3866_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_LH.tiff\n",
            "IMG_3866_180_LH.tiff\n",
            "IMG_3866_180_LH.tiff\n",
            "IMG_3866_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_HL.tiff\n",
            "IMG_3866_180_HL.tiff\n",
            "IMG_3866_180_HL.tiff\n",
            "IMG_3866_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_HH.tiff\n",
            "IMG_3866_180_HH.tiff\n",
            "IMG_3866_180_HH.tiff\n",
            "IMG_3866_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_FLIP_LL.tiff\n",
            "IMG_3866_180_FLIP_LL.tiff\n",
            "IMG_3866_180_FLIP_LL.tiff\n",
            "IMG_3866_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_FLIP_LH.tiff\n",
            "IMG_3866_180_FLIP_LH.tiff\n",
            "IMG_3866_180_FLIP_LH.tiff\n",
            "IMG_3866_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_FLIP_HL.tiff\n",
            "IMG_3866_180_FLIP_HL.tiff\n",
            "IMG_3866_180_FLIP_HL.tiff\n",
            "IMG_3866_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3866_180_FLIP_HH.tiff\n",
            "IMG_3866_180_FLIP_HH.tiff\n",
            "IMG_3866_180_FLIP_HH.tiff\n",
            "IMG_3866_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_LL.tiff\n",
            "IMG_3873_LL.tiff\n",
            "IMG_3873_LL.tiff\n",
            "IMG_3873_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_LH.tiff\n",
            "IMG_3873_LH.tiff\n",
            "IMG_3873_LH.tiff\n",
            "IMG_3873_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_HL.tiff\n",
            "IMG_3873_HL.tiff\n",
            "IMG_3873_HL.tiff\n",
            "IMG_3873_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_HH.tiff\n",
            "IMG_3873_HH.tiff\n",
            "IMG_3873_HH.tiff\n",
            "IMG_3873_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_LL.tiff\n",
            "IMG_3873_180_LL.tiff\n",
            "IMG_3873_180_LL.tiff\n",
            "IMG_3873_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_LH.tiff\n",
            "IMG_3873_180_LH.tiff\n",
            "IMG_3873_180_LH.tiff\n",
            "IMG_3873_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_HL.tiff\n",
            "IMG_3873_180_HL.tiff\n",
            "IMG_3873_180_HL.tiff\n",
            "IMG_3873_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_HH.tiff\n",
            "IMG_3873_180_HH.tiff\n",
            "IMG_3873_180_HH.tiff\n",
            "IMG_3873_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_FLIP_LL.tiff\n",
            "IMG_3873_180_FLIP_LL.tiff\n",
            "IMG_3873_180_FLIP_LL.tiff\n",
            "IMG_3873_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_FLIP_LH.tiff\n",
            "IMG_3873_180_FLIP_LH.tiff\n",
            "IMG_3873_180_FLIP_LH.tiff\n",
            "IMG_3873_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_FLIP_HL.tiff\n",
            "IMG_3873_180_FLIP_HL.tiff\n",
            "IMG_3873_180_FLIP_HL.tiff\n",
            "IMG_3873_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3873_180_FLIP_HH.tiff\n",
            "IMG_3873_180_FLIP_HH.tiff\n",
            "IMG_3873_180_FLIP_HH.tiff\n",
            "IMG_3873_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_LL.tiff\n",
            "IMG_3860_LL.tiff\n",
            "IMG_3860_LL.tiff\n",
            "IMG_3860_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_LH.tiff\n",
            "IMG_3860_LH.tiff\n",
            "IMG_3860_LH.tiff\n",
            "IMG_3860_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_HL.tiff\n",
            "IMG_3860_HL.tiff\n",
            "IMG_3860_HL.tiff\n",
            "IMG_3860_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_HH.tiff\n",
            "IMG_3860_HH.tiff\n",
            "IMG_3860_HH.tiff\n",
            "IMG_3860_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_LL.tiff\n",
            "IMG_3860_180_LL.tiff\n",
            "IMG_3860_180_LL.tiff\n",
            "IMG_3860_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_LH.tiff\n",
            "IMG_3860_180_LH.tiff\n",
            "IMG_3860_180_LH.tiff\n",
            "IMG_3860_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_HL.tiff\n",
            "IMG_3860_180_HL.tiff\n",
            "IMG_3860_180_HL.tiff\n",
            "IMG_3860_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_HH.tiff\n",
            "IMG_3860_180_HH.tiff\n",
            "IMG_3860_180_HH.tiff\n",
            "IMG_3860_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_FLIP_LL.tiff\n",
            "IMG_3860_180_FLIP_LL.tiff\n",
            "IMG_3860_180_FLIP_LL.tiff\n",
            "IMG_3860_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_FLIP_LH.tiff\n",
            "IMG_3860_180_FLIP_LH.tiff\n",
            "IMG_3860_180_FLIP_LH.tiff\n",
            "IMG_3860_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_FLIP_HL.tiff\n",
            "IMG_3860_180_FLIP_HL.tiff\n",
            "IMG_3860_180_FLIP_HL.tiff\n",
            "IMG_3860_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3860_180_FLIP_HH.tiff\n",
            "IMG_3860_180_FLIP_HH.tiff\n",
            "IMG_3860_180_FLIP_HH.tiff\n",
            "IMG_3860_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_LL.tiff\n",
            "IMG_3878_LL.tiff\n",
            "IMG_3878_LL.tiff\n",
            "IMG_3878_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_LH.tiff\n",
            "IMG_3878_LH.tiff\n",
            "IMG_3878_LH.tiff\n",
            "IMG_3878_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_HL.tiff\n",
            "IMG_3878_HL.tiff\n",
            "IMG_3878_HL.tiff\n",
            "IMG_3878_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_HH.tiff\n",
            "IMG_3878_HH.tiff\n",
            "IMG_3878_HH.tiff\n",
            "IMG_3878_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_LL.tiff\n",
            "IMG_3878_180_LL.tiff\n",
            "IMG_3878_180_LL.tiff\n",
            "IMG_3878_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_LH.tiff\n",
            "IMG_3878_180_LH.tiff\n",
            "IMG_3878_180_LH.tiff\n",
            "IMG_3878_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_HL.tiff\n",
            "IMG_3878_180_HL.tiff\n",
            "IMG_3878_180_HL.tiff\n",
            "IMG_3878_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_HH.tiff\n",
            "IMG_3878_180_HH.tiff\n",
            "IMG_3878_180_HH.tiff\n",
            "IMG_3878_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_FLIP_LL.tiff\n",
            "IMG_3878_180_FLIP_LL.tiff\n",
            "IMG_3878_180_FLIP_LL.tiff\n",
            "IMG_3878_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_FLIP_LH.tiff\n",
            "IMG_3878_180_FLIP_LH.tiff\n",
            "IMG_3878_180_FLIP_LH.tiff\n",
            "IMG_3878_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_FLIP_HL.tiff\n",
            "IMG_3878_180_FLIP_HL.tiff\n",
            "IMG_3878_180_FLIP_HL.tiff\n",
            "IMG_3878_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3878_180_FLIP_HH.tiff\n",
            "IMG_3878_180_FLIP_HH.tiff\n",
            "IMG_3878_180_FLIP_HH.tiff\n",
            "IMG_3878_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_LL.tiff\n",
            "IMG_3885_LL.tiff\n",
            "IMG_3885_LL.tiff\n",
            "IMG_3885_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_LH.tiff\n",
            "IMG_3885_LH.tiff\n",
            "IMG_3885_LH.tiff\n",
            "IMG_3885_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_HL.tiff\n",
            "IMG_3885_HL.tiff\n",
            "IMG_3885_HL.tiff\n",
            "IMG_3885_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_HH.tiff\n",
            "IMG_3885_HH.tiff\n",
            "IMG_3885_HH.tiff\n",
            "IMG_3885_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_LL.tiff\n",
            "IMG_3885_180_LL.tiff\n",
            "IMG_3885_180_LL.tiff\n",
            "IMG_3885_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_LH.tiff\n",
            "IMG_3885_180_LH.tiff\n",
            "IMG_3885_180_LH.tiff\n",
            "IMG_3885_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_HL.tiff\n",
            "IMG_3885_180_HL.tiff\n",
            "IMG_3885_180_HL.tiff\n",
            "IMG_3885_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_HH.tiff\n",
            "IMG_3885_180_HH.tiff\n",
            "IMG_3885_180_HH.tiff\n",
            "IMG_3885_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_FLIP_LL.tiff\n",
            "IMG_3885_180_FLIP_LL.tiff\n",
            "IMG_3885_180_FLIP_LL.tiff\n",
            "IMG_3885_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_FLIP_LH.tiff\n",
            "IMG_3885_180_FLIP_LH.tiff\n",
            "IMG_3885_180_FLIP_LH.tiff\n",
            "IMG_3885_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_FLIP_HL.tiff\n",
            "IMG_3885_180_FLIP_HL.tiff\n",
            "IMG_3885_180_FLIP_HL.tiff\n",
            "IMG_3885_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3885_180_FLIP_HH.tiff\n",
            "IMG_3885_180_FLIP_HH.tiff\n",
            "IMG_3885_180_FLIP_HH.tiff\n",
            "IMG_3885_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_LL.tiff\n",
            "IMG_3875_LL.tiff\n",
            "IMG_3875_LL.tiff\n",
            "IMG_3875_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_LH.tiff\n",
            "IMG_3875_LH.tiff\n",
            "IMG_3875_LH.tiff\n",
            "IMG_3875_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_HL.tiff\n",
            "IMG_3875_HL.tiff\n",
            "IMG_3875_HL.tiff\n",
            "IMG_3875_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_HH.tiff\n",
            "IMG_3875_HH.tiff\n",
            "IMG_3875_HH.tiff\n",
            "IMG_3875_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_LL.tiff\n",
            "IMG_3875_180_LL.tiff\n",
            "IMG_3875_180_LL.tiff\n",
            "IMG_3875_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_LH.tiff\n",
            "IMG_3875_180_LH.tiff\n",
            "IMG_3875_180_LH.tiff\n",
            "IMG_3875_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_HL.tiff\n",
            "IMG_3875_180_HL.tiff\n",
            "IMG_3875_180_HL.tiff\n",
            "IMG_3875_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_HH.tiff\n",
            "IMG_3875_180_HH.tiff\n",
            "IMG_3875_180_HH.tiff\n",
            "IMG_3875_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_FLIP_LL.tiff\n",
            "IMG_3875_180_FLIP_LL.tiff\n",
            "IMG_3875_180_FLIP_LL.tiff\n",
            "IMG_3875_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_FLIP_LH.tiff\n",
            "IMG_3875_180_FLIP_LH.tiff\n",
            "IMG_3875_180_FLIP_LH.tiff\n",
            "IMG_3875_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_FLIP_HL.tiff\n",
            "IMG_3875_180_FLIP_HL.tiff\n",
            "IMG_3875_180_FLIP_HL.tiff\n",
            "IMG_3875_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3875_180_FLIP_HH.tiff\n",
            "IMG_3875_180_FLIP_HH.tiff\n",
            "IMG_3875_180_FLIP_HH.tiff\n",
            "IMG_3875_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_LL.tiff\n",
            "IMG_3884_LL.tiff\n",
            "IMG_3884_LL.tiff\n",
            "IMG_3884_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_LH.tiff\n",
            "IMG_3884_LH.tiff\n",
            "IMG_3884_LH.tiff\n",
            "IMG_3884_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_HL.tiff\n",
            "IMG_3884_HL.tiff\n",
            "IMG_3884_HL.tiff\n",
            "IMG_3884_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_HH.tiff\n",
            "IMG_3884_HH.tiff\n",
            "IMG_3884_HH.tiff\n",
            "IMG_3884_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_LL.tiff\n",
            "IMG_3884_180_LL.tiff\n",
            "IMG_3884_180_LL.tiff\n",
            "IMG_3884_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_LH.tiff\n",
            "IMG_3884_180_LH.tiff\n",
            "IMG_3884_180_LH.tiff\n",
            "IMG_3884_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_HL.tiff\n",
            "IMG_3884_180_HL.tiff\n",
            "IMG_3884_180_HL.tiff\n",
            "IMG_3884_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_HH.tiff\n",
            "IMG_3884_180_HH.tiff\n",
            "IMG_3884_180_HH.tiff\n",
            "IMG_3884_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_FLIP_LL.tiff\n",
            "IMG_3884_180_FLIP_LL.tiff\n",
            "IMG_3884_180_FLIP_LL.tiff\n",
            "IMG_3884_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_FLIP_LH.tiff\n",
            "IMG_3884_180_FLIP_LH.tiff\n",
            "IMG_3884_180_FLIP_LH.tiff\n",
            "IMG_3884_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_FLIP_HL.tiff\n",
            "IMG_3884_180_FLIP_HL.tiff\n",
            "IMG_3884_180_FLIP_HL.tiff\n",
            "IMG_3884_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3884_180_FLIP_HH.tiff\n",
            "IMG_3884_180_FLIP_HH.tiff\n",
            "IMG_3884_180_FLIP_HH.tiff\n",
            "IMG_3884_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_LL.tiff\n",
            "IMG_3859_LL.tiff\n",
            "IMG_3859_LL.tiff\n",
            "IMG_3859_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_LH.tiff\n",
            "IMG_3859_LH.tiff\n",
            "IMG_3859_LH.tiff\n",
            "IMG_3859_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_HL.tiff\n",
            "IMG_3859_HL.tiff\n",
            "IMG_3859_HL.tiff\n",
            "IMG_3859_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_HH.tiff\n",
            "IMG_3859_HH.tiff\n",
            "IMG_3859_HH.tiff\n",
            "IMG_3859_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_LL.tiff\n",
            "IMG_3859_180_LL.tiff\n",
            "IMG_3859_180_LL.tiff\n",
            "IMG_3859_180_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_LH.tiff\n",
            "IMG_3859_180_LH.tiff\n",
            "IMG_3859_180_LH.tiff\n",
            "IMG_3859_180_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_HL.tiff\n",
            "IMG_3859_180_HL.tiff\n",
            "IMG_3859_180_HL.tiff\n",
            "IMG_3859_180_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_HH.tiff\n",
            "IMG_3859_180_HH.tiff\n",
            "IMG_3859_180_HH.tiff\n",
            "IMG_3859_180_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_FLIP_LL.tiff\n",
            "IMG_3859_180_FLIP_LL.tiff\n",
            "IMG_3859_180_FLIP_LL.tiff\n",
            "IMG_3859_180_FLIP_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_FLIP_LH.tiff\n",
            "IMG_3859_180_FLIP_LH.tiff\n",
            "IMG_3859_180_FLIP_LH.tiff\n",
            "IMG_3859_180_FLIP_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_FLIP_HL.tiff\n",
            "IMG_3859_180_FLIP_HL.tiff\n",
            "IMG_3859_180_FLIP_HL.tiff\n",
            "IMG_3859_180_FLIP_HL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3859_180_FLIP_HH.tiff\n",
            "IMG_3859_180_FLIP_HH.tiff\n",
            "IMG_3859_180_FLIP_HH.tiff\n",
            "IMG_3859_180_FLIP_HH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3882_LL.tiff\n",
            "IMG_3882_LL.tiff\n",
            "IMG_3882_LL.tiff\n",
            "IMG_3882_LL.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3882_LH.tiff\n",
            "IMG_3882_LH.tiff\n",
            "IMG_3882_LH.tiff\n",
            "IMG_3882_LH.tiff\n",
            "Filenames\n",
            "/content/drive/MyDrive/Moire/train/positive/024/\n",
            "IMG_3882_HL.tiff\n",
            "IMG_3882_HL.tiff\n",
            "IMG_3882_HL.tiff\n",
            "IMG_3882_HL.tiff\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8c927a47efeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# augmentNormalizedData(superpoch, dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainMoire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motherDsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mtestMoire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuperpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motherDsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-1e789d9a0b93>\u001b[0m in \u001b[0;36mtrainMoire\u001b[0;34m(superpoch, dataSetNumber, numEpochs, weights_file)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'##### TRAINING - superpoch: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuperpoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' - dataset: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataSetNumber\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataSetNumber\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mX_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainReadDatafromDrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataSetNumber\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_LL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cd5caf157045>\u001b[0m in \u001b[0;36mmainReadDatafromDrive\u001b[0;34m(dataSetNumber, dataType)\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Directory does not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mX_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadWaveletData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositiveFromTrainDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegativeFromTrainDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mX_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshapeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cd5caf157045>\u001b[0m in \u001b[0;36mreadWaveletData\u001b[0;34m(positiveImagePath, negativeImagePath)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# write class 0 for positive and 1 for negative samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0msampleIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadImageSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositiveImageFiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositiveImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive data loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cd5caf157045>\u001b[0m in \u001b[0;36mreadImageSet\u001b[0;34m(imageFiles, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimageFiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadAndScaleImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msampleIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampleIndex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cd5caf157045>\u001b[0m in \u001b[0;36mreadAndScaleImage\u001b[0;34m(f, customStr, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, sampleVal)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mimgLL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaleData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgLL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mimgLH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaleData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgLH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mimgHL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaleData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgHL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cd5caf157045>\u001b[0m in \u001b[0;36mscaleData\u001b[0;34m(inp, minimum, maximum)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mminMaxScaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminMaxScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0;32m--> 412\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;34m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_subclasscheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyiISSNr2ZAr"
      },
      "source": [
        "# X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train = mainReadDatafromDrive('/content/drive/MyDrive/Moire/trainDataPositive', '/content/drive/MyDrive/Moire/trainDataNegative')\n",
        "# !ls /content/drive/MyDrive/Moire/preaugmented/positive/003\n",
        "print('negative unnormalized 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/negative/001')])))\n",
        "print('positive unnormalized 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/positive/001')])))\n",
        "print('negative unnormalized 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/negative/002')])))\n",
        "print('positive unnormalized 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/positive/002')])))\n",
        "print('negative unnormalized 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/negative/003')])))\n",
        "print('positive unnormalized 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/positive/003')])))\n",
        "# print('negative train 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/negative/001')])))\n",
        "# print('negative train 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/negative/002')])))\n",
        "# print('negative train 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/negative/003')])))\n",
        "# print('positive train 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/positive/001')])))\n",
        "# print('positive train 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/positive/002')])))\n",
        "# print('positive train 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/positive/003')])))\n",
        "# print('negative test 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/negative/001')])))\n",
        "# print('negative test 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/negative/002')])))\n",
        "# print('negative test 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/negative/003')])))\n",
        "# print('positive test 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/positive/001')])))\n",
        "# print('positive test 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/positive/002')])))\n",
        "# print('positive test 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/positive/003')])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9RFVMxIroLI"
      },
      "source": [
        "# testMoire('/content/drive/MyDrive/Moire/checkPoint/mid-sp005-ds002-ep016-ls0.00455-ac1.00-weights.h5', \"001\", \"001\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDO0lSriFOJt"
      },
      "source": [
        "def intermediateMoire(dataSetNumber, weights_file = None):\n",
        "\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(dataSetNumber, 'test')\n",
        "    return createIntermediateModel(dataSetNumber, X_LL, X_LH, X_HL, X_HH, Y, weights_file)\n",
        "    \n",
        "\n",
        "def createIntermediateModel(dataSetNumber, X_LL_train, X_LH_train, X_HL_train, X_HH_train, y_train, weights_file):\n",
        "\n",
        "    batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "    print(\"SHAPE\")\n",
        "    print(X_LL_train.shape);\n",
        "    num_train, height, width, depth = X_LL_train.shape\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "    # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "    \n",
        "    # if not os.path.exists(checkPointFolder):\n",
        "    #     os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "    model, intermediate_model = createModel(height, width, depth, num_classes)\n",
        "\n",
        "    if weights_file != None:\n",
        "      print('--- Loading weights file: ' + weights_file)\n",
        "      model.load_weights(weights_file)\n",
        "    else:\n",
        "      print('--- No weights file provided.  Creating new model.')\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "                  optimizer='adam', # using the Adam optimiser\n",
        "                  metrics=['accuracy']) # reporting the accuracy\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # weights_list = model.get_weights()\n",
        "    # for i in range(len(model.layers)):\n",
        "    #   print(model.layers[i].get_weights())\n",
        "      # print(model.layers[i].get_weights()[1])\n",
        "    \n",
        "    model_index = 0;\n",
        "    print('----------------')\n",
        "    for layer in intermediate_model.layers:\n",
        "      for weights in layer.get_weights():\n",
        "        weights = model.get_weights()[model_index]\n",
        "        model_index = model_index + 1\n",
        "\n",
        "    # print('----------------')\n",
        "\n",
        "    # for layer in model.layers:\n",
        "    #   for weights in layer.get_weights():\n",
        "    #     print(len(weights))\n",
        "    # print('----------------')\n",
        "    \n",
        "    # intermediate_model.layers[5].set_weights(weights_list[0])\n",
        "    # print(len(model.layers))\n",
        "    # intermediate_model.layers[i].set_weights(weights)\n",
        "\n",
        "    # intermediate_model.summary()\n",
        "\n",
        "    # model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "    #           batch_size=batch_size, epochs=num_epochs,\n",
        "    #           verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "    # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "    # modelName = '/content/drive/MyDrive/Moire/checkPoint/final-tm' + str(time.time()).split('.')[0] + '-sp' + superpoch + '-ds' + dataSetNumber + '-weights.h5'\n",
        "    # model.save(modelName)\n",
        "    \n",
        "    return intermediate_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27zETVwPEMCf"
      },
      "source": [
        "# from keras.models import Model\n",
        "\n",
        "# model = intermediateMoire(\"001\", '/content/drive/MyDrive/Moire/checkPoint/mid-sp005-ds002-ep016-ls0.00455-ac1.00-weights.h5')\n",
        "\n",
        "# model.summary()\n",
        "# X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(\"001\", 'test')\n",
        "# model_out = model.predict([X_LL, X_LH, X_HL, X_HH])\n",
        "\n",
        "\n",
        "# print(model_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ESg5hvZl3u_"
      },
      "source": [
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "# model_shape = model_out.shape\n",
        "\n",
        "# reshaped_output = np.reshape(model_out, (model_shape[0], model_shape[3], model_shape[1], model_shape[2]))\n",
        "\n",
        "# print(reshaped_output.shape)\n",
        "# index = 0\n",
        "# # for image_batch in reshaped_output:\n",
        "# for image in reshaped_output[0]:\n",
        "#   # image_batch = np.reshape(reshaped_output, (model_shape[0], model_shape[3], model_shape[1], model_shape[2]))\n",
        "#   print(image.shape)\n",
        "\n",
        "#   largest = 0\n",
        "#   smallest = 100000\n",
        "\n",
        "#   for row in image:\n",
        "#     for i in row:\n",
        "#       if i > largest:\n",
        "#         largest = i\n",
        "#       if i < smallest:\n",
        "#         smallest = i\n",
        "\n",
        "#   value_range = largest - smallest\n",
        "#   scale_value = 255 / value_range\n",
        "\n",
        "#   for i in range(len(image)):\n",
        "#     for j in range(len(image[i])):\n",
        "#       image[i][j] = scale_value * image[i][j]\n",
        "#   print('largest: ' + str(largest))\n",
        "#   print('smallest: ' + str(smallest))\n",
        "#   im = Image.fromarray(image)\n",
        "#   index = index + 1\n",
        "\n",
        "#   if im.mode != 'RGB':\n",
        "#     im = im.convert('RGB')\n",
        "\n",
        "#   im.save('/content/drive/MyDrive/Moire/intermediate/test/negative/001/' + str(index) + \".jpg\")\n",
        "\n",
        "# print(index)\n",
        "# print(np.reshape(model_out, (model_shape[0], model_shape[3], model_shape[1], model_shape[2])).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnwQH5eYqa_O"
      },
      "source": [
        "# #constants\n",
        "# # width = 500#384 #change dimensions according to the input image in the training\n",
        "# # height = 375#512 #change dimensions according to the input image in the training\n",
        "# # depth = 1\n",
        "# # num_classes = 2\n",
        "\n",
        "# def continueTraining(weightsFile, X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, num_epochs):\n",
        "#     weights_file = (weightsFile)\n",
        "\n",
        "#     # X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(positiveImagePath, negativeImagePath)\n",
        "    \n",
        "    \n",
        "\n",
        "#     batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "#     print(\"SHAPE\")\n",
        "#     print(X_LL_train.shape);\n",
        "#     num_train, height, width, depth = X_LL_train.shape\n",
        "#     num_classes = len(np.unique(Y_train))\n",
        "#     Y_train = np_utils.to_categorical(Y_train, num_classes) # One-hot encode the labels\n",
        "#     print(Y_train);\n",
        "#     # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "\n",
        "#     CNN_model = createModel(height, width, depth, num_classes)\n",
        "#     CNN_model.load_weights(weights_file)\n",
        "\n",
        "#     checkPointFolder = 'content/drive/MyDrive/Moire/checkPoint'\n",
        "#     checkpoint_name = checkPointFolder + '/Weights-retrained-002--{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "#     checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "#     callbacks_list = [checkpoint]\n",
        "    \n",
        "#     if not os.path.exists(checkPointFolder):\n",
        "#         os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "#     # model = createModel(height, width, depth, num_classes)\n",
        "    \n",
        "#     CNN_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "#                   optimizer='adam', # using the Adam optimiser\n",
        "#                   metrics=['accuracy']) # reporting the accuracy\n",
        "\n",
        "#     CNN_model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "#               batch_size=batch_size, epochs=num_epochs,\n",
        "#               verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "#     # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "#     CNN_model.save('content/drive/MyDrive/Moire/checkPoint/retrained-002-moirePattern3CNN_.h5')\n",
        "    \n",
        "#     return model\n",
        "#     # evaluate(CNN_model,X_LL,X_LH,X_HL,X_HH, Y)\n",
        "# import time\n",
        "# str(time.time()).split('.')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fyxBfYY4i7U"
      },
      "source": [
        "# continueTraining('content/drive/MyDrive/Moire/checkPoint/Weights-028--0.06866.hdf5', X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlSUPMxf6tFa"
      },
      "source": [
        "# !ls content/drive/MyDrive/Moire/checkPoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYl1Npdb623a"
      },
      "source": [
        "# mainTest('content/drive/MyDrive/Moire/checkPoint/retrained-002-moirePattern3CNN_.h5', '/content/drive/MyDrive/Moire/testDataPositive', '/content/drive/MyDrive/Moire/testDataNegative')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}