{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of Playground.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianhumphreys/Moire-Detector/blob/main/Copy_of_Playground_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDFp5O-Bqa_H"
      },
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To3GCs0JndZT",
        "outputId": "d603a938-8fd2-4bfd-a7fa-0b867a0d36dd"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 18 16:25:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5iT4R4PnYT6",
        "outputId": "5729abe3-d956-4cf1-90c3-1a118886843b"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "muinrEgNqa_J"
      },
      "source": [
        "## Test 2D Wavelet Decomposition function\n",
        "This function(fwdHaarDWT2D) computes the 2D Wavelet Transform in the image. All the input images are passed through a Haar Wavelet Decomposition module, to get the LL, LH, HL and HHH component of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWlOXh6fq3xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879c5a95-df3b-43e7-8895-01889c905607"
      },
      "source": [
        "from google.colab import drive                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r96WGlWEqjL1"
      },
      "source": [
        "# !ls /content/drive/MyDrive/Moire/train/negative/001/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDw39lK9kAe0"
      },
      "source": [
        "# !ls /content/drive/MyDrive/Moire/trainDataNegative\n",
        "# !ls /content/drive/MyDrive/Moire/train/negative/001\n",
        "# !mv -v /content/drive/MyDrive/Moire/trainDataNegative/ '/content/drive/MyDrive/Moire/train/negative/001'\n",
        "# !ls '/content/drive/MyDrive/Moire/train/negative/001/trainDataNegative'\n",
        "# !mv -v '/content/drive/MyDrive/Moire/train/negative/001/trainDataNegative/*.tiff' '/content/drive/MyDrive/Moire/train/negative/001'\n",
        "# import os\n",
        "\n",
        "# fromDir = '/content/drive/MyDrive/Moire/notNormalizedPositiveImages/'\n",
        "# toDir = \"/content/drive/MyDrive/Moire/unnormalized/positive/002/\"\n",
        "\n",
        "# # !ls /content/drive/MyDrive/Moire/testDataNegative/\n",
        "\n",
        "# for filename in os.listdir(fromDir):\n",
        "#   os.rename(fromDir + filename, toDir + filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA7CMKEhro9d"
      },
      "source": [
        "# import os\n",
        "# os.chdir(\"/content/drive/\")\n",
        "# !ls\n",
        "\n",
        "# os.chdir(\"../..\")\n",
        "# !ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsTZ_TLIv3TK",
        "outputId": "e8bd5fb7-df20-44b1-a5dc-899d89356b93"
      },
      "source": [
        "!ls /content/drive/MyDrive/Moire\n",
        "!pip install pyheif whatimage\n",
        "# !pip show wand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkPoint  intermediate  preaugmented\ttest  train  unnormalized\n",
            "Collecting pyheif\n",
            "  Downloading pyheif-0.5.1-cp37-cp37m-manylinux2014_x86_64.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting whatimage\n",
            "  Downloading whatimage-0.0.3-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pyheif) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->pyheif) (2.20)\n",
            "Installing collected packages: whatimage, pyheif\n",
            "Successfully installed pyheif-0.5.1 whatimage-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmgaiBmhtDHX"
      },
      "source": [
        "# !ls /content/drive/MyDrive/Moire/notNormalizedPositiveImages/\n",
        "# !ls /content/drive/MyDrive/Moire/notNormalizedNegativeImages/\n",
        "# !uname -m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO9ckef9Wrs3"
      },
      "source": [
        "## Normalized Raw data to 1000x750 pixel images\n",
        "Images are cropped to fit a 3:4 aspect ratio and then resized to match a 1000x750 size. Moves photos **unnormalized** -> **preaugmented**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xaN5wepXCy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "06d69145-c8ec-44d5-db5f-c7e9efcd4f6f"
      },
      "source": [
        "# importing the module\n",
        "\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "\n",
        "import whatimage\n",
        "import pyheif\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def decodeImage(bytesIo):\n",
        "    with open(bytesIo, 'rb') as f:\n",
        "      data = f.read()\n",
        "      fmt = whatimage.identify_image(data)\n",
        "      if fmt in ['heic', 'avif']:\n",
        "        i = pyheif.read_heif(data)\n",
        "        pi = Image.frombytes(mode=i.mode, size=i.size, data=i.data)\n",
        "        pi.save(\"heic.jpg\", format=\"jpeg\")\n",
        "\n",
        "def read_heic(path: str):\n",
        "    img = Wimage(path)\n",
        "    img.format = 'jpg'\n",
        "    img.save(filename=\"heic.jpg\")\n",
        "    img.close()\n",
        "\n",
        "def openImage(fileName):\n",
        "  decodeImage(fileName)\n",
        "  return Image.open(\"heic.jpg\")\n",
        "\n",
        "def cropAndSave(image, fileName):\n",
        "    width = image.size[0]\n",
        "    height = image.size[1]\n",
        "\n",
        "    aspect = width / float(height)\n",
        "\n",
        "    if (height > width):\n",
        "        image = image.rotate(90, Image.NEAREST, expand=1)\n",
        "        width = image.size[0]\n",
        "        height = image.size[1]\n",
        "\n",
        "    ideal_width = 1000\n",
        "    ideal_height = 750\n",
        "\n",
        "    ideal_aspect = ideal_width / float(ideal_height)\n",
        "\n",
        "    if aspect > ideal_aspect:\n",
        "        # Then crop the left and right edges:\n",
        "        new_width = int(ideal_aspect * height)\n",
        "        offset = (width - new_width) / 2\n",
        "        resize = (offset, 0, width - offset, height)\n",
        "    else:\n",
        "        # ... crop the top and bottom:\n",
        "        new_height = int(width / ideal_aspect)\n",
        "        offset = (height - new_height) / 2\n",
        "        resize = (0, offset, width, height - offset)\n",
        "\n",
        "    thumb = image.crop(resize).resize((ideal_width, ideal_height), Image.ANTIALIAS)\n",
        "    thumb.save(fileName)\n",
        "\n",
        "\n",
        "\n",
        "def normalizeRawImages(superpoch, dataSetNumber):\n",
        "\n",
        "  print('##### NORMALIZING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber)\n",
        "\n",
        "  negativeFromDir = '/content/drive/MyDrive/Moire/unnormalized/negative/' + dataSetNumber + '/'\n",
        "  positiveFromDir = '/content/drive/MyDrive/Moire/unnormalized/positive/' + dataSetNumber + '/'\n",
        "  negativeToDir = '/content/drive/MyDrive/Moire/preaugmented/negative/' + dataSetNumber + '/'\n",
        "  positiveToDir = '/content/drive/MyDrive/Moire/preaugmented/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  if not os.path.exists(positiveToDir):\n",
        "      os.makedirs(positiveToDir)\n",
        "  if not os.path.exists(negativeToDir):\n",
        "      os.makedirs(negativeToDir)\n",
        "\n",
        "  if len([name for name in os.listdir(positiveToDir)]) > 0:\n",
        "    print('Directory ' + positiveToDir + ' already has normalized photos in it.  Skipping normalization for negative photos.')\n",
        "  if len([name for name in os.listdir(negativeToDir)]) > 0:\n",
        "    print('Directory ' + negativeToDir + ' already has normalized photos in it.  Skipping normalization for positive photos.')\n",
        "\n",
        "  positiveImageFiles = [f for f in listdir(positiveFromDir) if (isfile(join(positiveFromDir, f)))]\n",
        "  negativeImageFiles = [f for f in listdir(negativeFromDir) if (isfile(join(negativeFromDir, f)))]\n",
        "\n",
        "  # LLList = [l for l in positiveImageFiles if 'LLL' in l]\n",
        "  # print(LLList)\n",
        "\n",
        "  if len([name for name in os.listdir(positiveToDir)]) <= 0:\n",
        "    for f in positiveImageFiles:\n",
        "        print(join(positiveFromDir, f))\n",
        "        img = openImage(join(positiveFromDir, f))\n",
        "\n",
        "        rgb_im = img.convert(\"RGB\")\n",
        "        components = f.split('.')\n",
        "        newComponents = components[:len(components) - 1]\n",
        "        newComponents.append('jpg')\n",
        "        newFileName = '.'.join(newComponents)\n",
        "\n",
        "        cropAndSave(rgb_im, join(positiveToDir, newFileName))\n",
        "\n",
        "  if len([name for name in os.listdir(negativeToDir)]) <= 0:\n",
        "    for f in negativeImageFiles:\n",
        "        print(join(negativeFromDir, f))\n",
        "        img = Image.open(join(negativeFromDir, f))\n",
        "\n",
        "        rgb_im = img.convert(\"RGB\")\n",
        "        components = f.split('.')\n",
        "        newComponents = components[:len(components) - 1]\n",
        "        newComponents.append('jpg')\n",
        "        newFileName = '.'.join(newComponents)\n",
        "\n",
        "        cropAndSave(rgb_im, join(negativeToDir, newFileName))\n",
        "\n",
        "# normalizeRawImages(\"001\", \"005\")\n",
        "# normalizeRawImages(\"001\", \"006\")  \n",
        "# normalizeRawImages(\"001\", \"007\")\n",
        "# normalizeRawImages(\"001\", \"008\") \n",
        "# normalizeRawImages(\"001\", \"009\")\n",
        "# normalizeRawImages(\"001\", \"010\")\n",
        "# normalizeRawImages(\"001\", \"011\") \n",
        "# normalizeRawImages(\"001\", \"012\") \n",
        "normalizeRawImages(\"001\", \"013\") \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### NORMALIZING - superpoch: 001 - dataset: 013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d0c9215df86c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# normalizeRawImages(\"001\", \"011\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# normalizeRawImages(\"001\", \"012\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mnormalizeRawImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"001\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"013\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-d0c9215df86c>\u001b[0m in \u001b[0;36mnormalizeRawImages\u001b[0;34m(superpoch, dataSetNumber)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Directory '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnegativeToDir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' already has normalized photos in it.  Skipping normalization for positive photos.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m   \u001b[0mpositiveImageFiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositiveFromDir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositiveFromDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m   \u001b[0mnegativeImageFiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegativeFromDir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegativeFromDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Moire/unnormalized/positive/013/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9o2VLHoqyOo"
      },
      "source": [
        "#This function(fwdHaarDWT2D) computes the 2D Wavelet Transform in the image. All the input images are passed through a Haar Wavelet Decomposition module, to get the LL, LH, HL and HHH component of the image\n",
        "\n",
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "def splitFreqBands(img, levRows, levCols):\n",
        "    halfRow = int(levRows/2)\n",
        "    halfCol = int(levCols/2)\n",
        "    LL = img[0:halfRow, 0:halfCol]\n",
        "    LH = img[0:halfRow, halfCol:levCols]\n",
        "    HL = img[halfRow:levRows, 0:halfCol]\n",
        "    HH = img[halfRow:levRows, halfCol:levCols]\n",
        "    \n",
        "    return LL, LH, HL, HH\n",
        "    \n",
        "def haarDWT1D(data, length):\n",
        "    avg0 = 0.5;\n",
        "    avg1 = 0.5;\n",
        "    dif0 = 0.5;\n",
        "    dif1 = -0.5;\n",
        "    temp = np.empty_like(data)\n",
        "    temp = temp.astype(float)\n",
        "    h = int(length/2)\n",
        "    for i in range(h):\n",
        "        k = i*2\n",
        "        temp[i] = data[k] * avg0 + data[k + 1] * avg1;\n",
        "        temp[i + h] = data[k] * dif0 + data[k + 1] * dif1;\n",
        "    \n",
        "    data[:] = temp\n",
        "\n",
        "# computes the homography coefficients for PIL.Image.transform using point correspondences\n",
        "def fwdHaarDWT2D(img):\n",
        "    img = np.array(img)\n",
        "    levRows = img.shape[0];\n",
        "    levCols = img.shape[1];\n",
        "    img = img.astype(float)\n",
        "    for i in range(levRows):\n",
        "        row = img[i,:]\n",
        "        haarDWT1D(row, levCols)\n",
        "        img[i,:] = row\n",
        "    for j in range(levCols):\n",
        "        col = img[:,j]\n",
        "        haarDWT1D(col, levRows)\n",
        "        img[:,j] = col\n",
        "        \n",
        "    return splitFreqBands(img, levRows, levCols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a63KHmZYqa_K"
      },
      "source": [
        "# from PIL import Image\n",
        "# from matplotlib import pyplot as plt\n",
        "# !ls /content/drive/MyDrive/Moire/\n",
        "# img = Image.open('/content/drive/MyDrive/Moire/preaugmented/positive/001/IMG_2906.jpg').convert('L')\n",
        "# img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "# img.save('chl.jpg')\n",
        "# LL, LH, HL, HH = fwdHaarDWT2D(img)\n",
        "# fig, axes = plt.subplots(2, 2)\n",
        "# fig.tight_layout()\n",
        "# axes[0, 0].imshow(LL)\n",
        "# axes[0, 1].imshow(LH)\n",
        "# axes[1, 0].imshow(HL)\n",
        "# axes[1, 1].imshow(HH)\n",
        "# axes[0, 0].set_title(\"LL\")\n",
        "# axes[0, 1].set_title(\"LH\")\n",
        "# axes[1, 0].set_title(\"HL\")\n",
        "# axes[1, 1].set_title(\"HH\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNnfNmoEqa_M"
      },
      "source": [
        "## Augment normalized data\n",
        "The training images need to be put in two folders. positiveImages and negativeImages. positiveImages are the images which are captured from the display devices and has the presence of stron or weak Moiré patterms in it.\n",
        "negativeImages are the ones without Moiré Patterns (i.e. the images which are not captured from the display devices).  Moves photos **preaugmented** -> **train/test** based on a split ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO8AKkFsqm5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0867eba-c981-486d-ee37-5bb44bcdbac3"
      },
      "source": [
        "import sys\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "\n",
        "#The training images need to be put in two folders. positiveImages and negativeImages. positiveImages are the images which are captured from the display devices and has the presence of stron or weak Moiré patterms in it. negativeImages are the ones without Moiré Patterns (i.e. the images which are not captured from the display devices)\n",
        "\n",
        "\n",
        "def augmentNormalizedData(superpoch, dataSetNumber):\n",
        "\n",
        "  print('##### AUGMENTING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber)\n",
        "\n",
        "  negativeFromDir = '/content/drive/MyDrive/Moire/preaugmented/negative/' + dataSetNumber + '/'\n",
        "  positiveFromDir = '/content/drive/MyDrive/Moire/preaugmented/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  negativeToTrainDir = '/content/drive/MyDrive/Moire/train/negative/' + dataSetNumber + '/'\n",
        "  positiveToTrainDir = '/content/drive/MyDrive/Moire/train/positive/' + dataSetNumber + '/'\n",
        "  negativeToTestDir = '/content/drive/MyDrive/Moire/test/negative/' + dataSetNumber + '/'\n",
        "  positiveToTestDir = '/content/drive/MyDrive/Moire/test/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  if not os.path.exists(negativeToTrainDir):\n",
        "      os.makedirs(negativeToTrainDir)\n",
        "  if not os.path.exists(positiveToTrainDir):\n",
        "      os.makedirs(positiveToTrainDir)\n",
        "  if not os.path.exists(negativeToTestDir):\n",
        "      os.makedirs(negativeToTestDir)\n",
        "  if not os.path.exists(positiveToTestDir):\n",
        "      os.makedirs(positiveToTestDir)\n",
        "\n",
        "  if len([name for name in os.listdir(negativeToTrainDir)]) > 0:\n",
        "    print('Directory ' + negativeToTrainDir + ' already has normalized photos in it.  Skipping augmentation for negative photos.')\n",
        "  if len([name for name in os.listdir(positiveToTrainDir)]) > 0:\n",
        "    print('Directory ' + positiveToTrainDir + ' already has normalized photos in it.  Skipping augmentation for positive photos.')\n",
        "  if len([name for name in os.listdir(negativeToTestDir)]) > 0:\n",
        "    print('Directory ' + negativeToTestDir + ' already has normalized photos in it.  Skipping augmentation for negative photos.')\n",
        "  if len([name for name in os.listdir(positiveToTestDir)]) > 0:\n",
        "    print('Directory ' + positiveToTestDir + ' already has normalized photos in it.  Skipping augmentation for positive photos.')\n",
        "        \n",
        "  createTrainingData(positiveFromDir, negativeFromDir, positiveToTrainDir, negativeToTrainDir, positiveToTestDir, negativeToTestDir)\n",
        "\n",
        "    \n",
        "#The wavelet decomposed images are the transformed images representing the spatial and the frequency information of the image. These images are stored as 'tiff' in the disk, to preserve that information. Each image is transformed with 180 degrees rotation and as well flipped, as part of data augmentation.\n",
        "\n",
        "def transformImageAndSave(image, f, customStr, path):\n",
        "    cA, cH, cV, cD  = fwdHaarDWT2D(image);\n",
        "    \n",
        "    fileName = (os.path.splitext(f)[0])\n",
        "    fLL = (f.replace(fileName, fileName+'_' + customStr + 'LL')).replace('.jpg','.tiff')\n",
        "    fLH = (f.replace(fileName, fileName+'_' + customStr + 'LH')).replace('.jpg','.tiff')\n",
        "    fHL = (f.replace(fileName, fileName+'_' + customStr + 'HL')).replace('.jpg','.tiff')\n",
        "    fHH = (f.replace(fileName, fileName+'_' + customStr + 'HH')).replace('.jpg','.tiff')\n",
        "\n",
        "    cA = Image.fromarray(cA)\n",
        "    cH = Image.fromarray(cH)\n",
        "    cV = Image.fromarray(cV)\n",
        "    cD = Image.fromarray(cD)\n",
        "\n",
        "    cA.save(join(path, fLL))\n",
        "    cH.save(join(path, fLH))\n",
        "    cV.save(join(path, fHL))\n",
        "    cD.save(join(path, fHH))\n",
        "    \n",
        "    \n",
        "def augmentAndTrasformImage(f, mainFolder, trainFolder):\n",
        "    try:\n",
        "        print(join(mainFolder, f))\n",
        "        img = Image.open(join(mainFolder, f)) \n",
        "    except:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(f))\n",
        "        return None\n",
        "\n",
        "    imgGray = img.convert('L')\n",
        "    wdChk, htChk = imgGray.size\n",
        "    if htChk > wdChk:\n",
        "        imgGray = imgGray.rotate(-90, expand=1)\n",
        "        print('training image rotated')\n",
        "    transformImageAndSave(imgGray, f, '', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.ROTATE_180)\n",
        "    transformImageAndSave(imgGray, f, '180_', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    transformImageAndSave(imgGray, f, '180_FLIP_', trainFolder)\n",
        "    \n",
        "    return True\n",
        "    \n",
        "    \n",
        "def createTrainingData(positiveFromDir, negativeFromDir, positiveToTrainDir, negativeToTrainDir, positiveToTestDir, negativeToTestDir):\n",
        "\n",
        "    print('positive image path: ' + positiveFromDir)\n",
        "    print('negative image path: ' + negativeFromDir)\n",
        "    splitRatio = 0.8\n",
        "\n",
        "    # get image files by classes\n",
        "    positiveImageFiles = [f for f in listdir(positiveFromDir) if (isfile(join(positiveFromDir, f)))]\n",
        "    negativeImageFiles = [f for f in listdir(negativeFromDir) if (isfile(join(negativeFromDir, f)))]\n",
        "\n",
        "    positiveDataBorder = round(len(positiveImageFiles) * splitRatio)\n",
        "    negativeDataBorder = round(len(negativeImageFiles) * splitRatio)\n",
        "\n",
        "    positiveTrainFiles = positiveImageFiles[:positiveDataBorder]\n",
        "    positiveTestFiles = positiveImageFiles[positiveDataBorder:]\n",
        "    negativeTrainFiles = negativeImageFiles[:negativeDataBorder]\n",
        "    negativeTestFiles = negativeImageFiles[negativeDataBorder:]\n",
        "\n",
        "    print('positive train samples: ' + str(len(positiveTrainFiles)))\n",
        "    print('negative train samples: ' + str(len(negativeTrainFiles)))\n",
        "    print('positive test samples: ' + str(len(positiveTestFiles)))\n",
        "    print('negative test samples: ' + str(len(negativeTestFiles)))\n",
        "\n",
        "    Knegative = 0\n",
        "    Kpositive = 0\n",
        "\n",
        "    # create positive training images\n",
        "    if len([name for name in os.listdir(positiveToTrainDir)]) <= 0:\n",
        "      for f in positiveTrainFiles:\n",
        "          ret = augmentAndTrasformImage(f, positiveFromDir, positiveToTrainDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Kpositive += 3\n",
        "\n",
        "    if len([name for name in os.listdir(negativeToTrainDir)]) <= 0:\n",
        "      # create positive test images\n",
        "      for f in negativeTrainFiles:\n",
        "          ret = augmentAndTrasformImage(f, negativeFromDir, negativeToTrainDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Kpositive += 3\n",
        "\n",
        "    if len([name for name in os.listdir(positiveToTestDir)]) <= 0:\n",
        "      # create negative training images\n",
        "      for f in positiveTestFiles:\n",
        "          ret = augmentAndTrasformImage(f, positiveFromDir, positiveToTestDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Knegative += 3;\n",
        "\n",
        "    if len([name for name in os.listdir(negativeToTestDir)]) <= 0:\n",
        "      # create negative training images\n",
        "      for f in negativeTestFiles:\n",
        "          ret = augmentAndTrasformImage(f, negativeFromDir, negativeToTestDir)\n",
        "          if ret == None:\n",
        "              continue\n",
        "          Knegative += 3;\n",
        "    #\n",
        "    # print('Total positive files after augmentation: ', Kpositive)\n",
        "    # print('Total negative files after augmentation: ', Knegative)\n",
        "    \n",
        "\n",
        "\n",
        "# mainAugment('/content/drive/MyDrive/Moire/preaugmentedPositiveImages', '/content/drive/MyDrive/Moire/preaugmentedNegativeImages')\n",
        "\n",
        "# augmentNormalizedData('001', '005')\n",
        "# augmentNormalizedData('001', '006')\n",
        "# augmentNormalizedData('001', '007')\n",
        "# augmentNormalizedData('001', '008')\n",
        "# augmentNormalizedData('001', '009')\n",
        "# augmentNormalizedData('001', '010')\n",
        "# augmentNormalizedData('001', '011')\n",
        "# augmentNormalizedData('001', '012')\n",
        "augmentNormalizedData('001', '013')"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### AUGMENTING - superpoch: 001 - dataset: 013\n",
            "Directory /content/drive/MyDrive/Moire/train/negative/013/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/test/negative/013/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "positive image path: /content/drive/MyDrive/Moire/preaugmented/positive/013/\n",
            "negative image path: /content/drive/MyDrive/Moire/preaugmented/negative/013/\n",
            "positive train samples: 24\n",
            "negative train samples: 24\n",
            "positive test samples: 6\n",
            "negative test samples: 6\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3296.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3356.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3345.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3355.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3305.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3351.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3313.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3316.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3343.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3324.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3303.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3342.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3307.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3337.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3318.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3348.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3352.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3354.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3327.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3319.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3304.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3301.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3317.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3335.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3328.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3333.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3300.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3297.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3306.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/013/IMG_3340.jpg\n",
            "##### AUGMENTING - superpoch: 001 - dataset: 014\n",
            "Directory /content/drive/MyDrive/Moire/train/negative/014/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/test/negative/014/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "positive image path: /content/drive/MyDrive/Moire/preaugmented/positive/014/\n",
            "negative image path: /content/drive/MyDrive/Moire/preaugmented/negative/014/\n",
            "positive train samples: 24\n",
            "negative train samples: 24\n",
            "positive test samples: 6\n",
            "negative test samples: 6\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3540.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3537.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3523.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3530.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3513.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3511.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3516.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3514.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3512.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3526.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3517.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3519.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3522.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3524.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3520.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3529.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3515.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3534.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3527.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3535.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3536.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3528.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3538.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3531.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3518.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3521.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3539.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3533.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3525.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/014/IMG_3532.jpg\n",
            "##### AUGMENTING - superpoch: 001 - dataset: 015\n",
            "Directory /content/drive/MyDrive/Moire/train/negative/015/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/test/negative/015/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "positive image path: /content/drive/MyDrive/Moire/preaugmented/positive/015/\n",
            "negative image path: /content/drive/MyDrive/Moire/preaugmented/negative/015/\n",
            "positive train samples: 24\n",
            "negative train samples: 24\n",
            "positive test samples: 6\n",
            "negative test samples: 6\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3572.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3567.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3544.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3566.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3555.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3560.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3559.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3549.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3543.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3552.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3553.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3564.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3550.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3547.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3561.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3545.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3541.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3542.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3558.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3565.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3551.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3569.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3546.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3570.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3563.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3568.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3562.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3556.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3554.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/015/IMG_3548.jpg\n",
            "##### AUGMENTING - superpoch: 001 - dataset: 016\n",
            "Directory /content/drive/MyDrive/Moire/train/negative/016/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/test/negative/016/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "positive image path: /content/drive/MyDrive/Moire/preaugmented/positive/016/\n",
            "negative image path: /content/drive/MyDrive/Moire/preaugmented/negative/016/\n",
            "positive train samples: 24\n",
            "negative train samples: 24\n",
            "positive test samples: 6\n",
            "negative test samples: 6\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3598.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3591.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3587.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3576.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3578.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3581.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3594.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3599.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3600.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3582.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3580.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3579.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3583.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3596.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3593.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3592.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3588.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3602.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3575.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3589.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3574.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3601.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3590.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3585.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3573.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3595.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3577.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3597.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3584.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/016/IMG_3586.jpg\n",
            "##### AUGMENTING - superpoch: 001 - dataset: 017\n",
            "Directory /content/drive/MyDrive/Moire/train/negative/017/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "Directory /content/drive/MyDrive/Moire/test/negative/017/ already has normalized photos in it.  Skipping augmentation for negative photos.\n",
            "positive image path: /content/drive/MyDrive/Moire/preaugmented/positive/017/\n",
            "negative image path: /content/drive/MyDrive/Moire/preaugmented/negative/017/\n",
            "positive train samples: 24\n",
            "negative train samples: 24\n",
            "positive test samples: 6\n",
            "negative test samples: 6\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3613.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3604.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3633.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3615.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3630.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3632.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3608.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3621.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3609.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3631.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3614.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3624.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3628.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3611.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3619.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3610.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3606.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3620.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3629.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3612.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3617.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3623.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3605.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3622.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3618.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3616.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3626.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3625.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3607.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmented/positive/017/IMG_3627.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzpWIkVNqa_M"
      },
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "# positiveImagePath = '/content/drive/MyDrive/Moire/preaugmentedPositiveImages'\n",
        "# negativeImagePath = '/content/drive/MyDrive/Moire/preaugmentedNegativeImages'\n",
        "\n",
        "# mainAugment(positiveImagePath, negativeImagePath, 0)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNTveLG9tEf6"
      },
      "source": [
        "# !cd ../\n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INPlfs7QQXYJ"
      },
      "source": [
        "## Load Data into Memory\n",
        "Get your big boy pants on because it's going to be a lot of data.  Increase runtime memory.  This section will load data from an **augmented** directory and loads it into a tensor for training or evaluation.  Recommended to make sure that there is no accelerator used so that it can be used when training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOTnUFotxJJJ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#constants\n",
        "WIDTH = 500#384\n",
        "HEIGHT = 375#512\n",
        "\n",
        "#Here, we perform index based splitting and use those indices to split the our multi-input datasets. This is done because the CNN model is multi-input network\n",
        "def splitTrainTestDataForBands(inputData, X_train_ind, X_test_ind):\n",
        "    X_train = np.zeros((len(X_train_ind), WIDTH*HEIGHT))\n",
        "    for i in range(len(X_train_ind)):\n",
        "        X_train[i,:] = inputData[int(X_train_ind[i,0]),:]\n",
        "        \n",
        "    X_test = np.zeros((len(X_test_ind), WIDTH*HEIGHT))\n",
        "    for i in range(len(X_test_ind)):\n",
        "        X_test[i,:] = inputData[int(X_test_ind[i,0]),:]\n",
        "        \n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def countPositiveSamplesAfterSplit(trainData):\n",
        "    count = 0;\n",
        "    for i in range(len(trainData)):\n",
        "        if(trainData[i,0] == 0):\n",
        "            count = count + 1\n",
        "    return count\n",
        "\n",
        "def scaleData(inp, minimum, maximum):\n",
        "    minMaxScaler = preprocessing.MinMaxScaler(copy=True, feature_range=(minimum,maximum))\n",
        "    inp = inp.reshape(-1, 1)\n",
        "    inp = minMaxScaler.fit_transform(inp)\n",
        "    \n",
        "    return inp\n",
        "\n",
        "def readAndScaleImage(f, customStr, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, sampleVal):\n",
        "    fileName = (os.path.splitext(f)[0])\n",
        "    # print(fileName)\n",
        "    # print(customStr)\n",
        "\n",
        "    fLL = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fLH = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fHL = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fHH = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    \n",
        "    try:\n",
        "        imgLL = Image.open(join(trainImagePath, fLL))\n",
        "        imgLH = Image.open(join(trainImagePath, fLH))\n",
        "        imgHL = Image.open(join(trainImagePath, fHL))\n",
        "        imgHH = Image.open(join(trainImagePath, fHH))\n",
        "    except Exception as e:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(fileName))\n",
        "        print('Exception:', e)\n",
        "        return None\n",
        "        \n",
        "    imgLL = np.array(imgLL)\n",
        "    imgLH = np.array(imgLH)\n",
        "    imgHL = np.array(imgHL)\n",
        "    imgHH = np.array(imgHH)\n",
        "    imgLL = scaleData(imgLL, 0, 1)\n",
        "    imgLH = scaleData(imgLH, -1, 1)\n",
        "    imgHL = scaleData(imgHL, -1, 1)\n",
        "    imgHH = scaleData(imgHH, -1, 1)\n",
        "    \n",
        "    imgVector = imgLL.reshape(1, WIDTH*HEIGHT)\n",
        "    X_LL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgLH.reshape(1, WIDTH*HEIGHT)\n",
        "    X_LH[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHL.reshape(1, WIDTH*HEIGHT)\n",
        "    X_HL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHH.reshape(1, WIDTH*HEIGHT)\n",
        "    X_HH[sampleIndex, :] = imgVector\n",
        "    \n",
        "    Y[sampleIndex, 0] = sampleVal;\n",
        "    X_index[sampleIndex, 0] = sampleIndex;\n",
        "\n",
        "    imgVector = None\n",
        "    imgLL = None\n",
        "    imgLH = None\n",
        "    imgHL = None\n",
        "    imgHH = None\n",
        "    \n",
        "    return True\n",
        "\n",
        "def reshapeData(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount):\n",
        "\n",
        "    print('Dataset length: ' + str(len(X_LL)))\n",
        "    \n",
        "    print('num_train_samples', len(X_LL))\n",
        "    X_LL = np.array(X_LL)\n",
        "    X_LL = X_LL.reshape((len(X_LL), HEIGHT, WIDTH, 1))\n",
        "\n",
        "    X_LH = np.array(X_LH)\n",
        "    X_LH = X_LH.reshape((len(X_LH), HEIGHT, WIDTH, 1))\n",
        "\n",
        "    X_HL = np.array(X_HL)\n",
        "    X_HL = X_HL.reshape((len(X_HL), HEIGHT, WIDTH, 1))\n",
        "    \n",
        "    X_HH = np.array(X_HH)\n",
        "    X_HH = X_HH.reshape((len(X_HH), HEIGHT, WIDTH, 1))\n",
        "\n",
        "    Y = np.array(Y)\n",
        "    \n",
        "    return X_LL, X_LH, X_HL, X_HH, Y\n",
        "\n",
        "def readImageSet(imageFiles, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass):\n",
        "\n",
        "    for f in imageFiles:\n",
        "        ret = readAndScaleImage(f, '', trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass)\n",
        "        if ret == True:\n",
        "            sampleIndex = sampleIndex + 1\n",
        "\n",
        "    return sampleIndex\n",
        "\n",
        "def readWaveletData(positiveImagePath, negativeImagePath):\n",
        "    \n",
        "    # get augmented, balanced training data image files by class\n",
        "    positiveImageFiles = [f for f in listdir(positiveImagePath) if (isfile(join(positiveImagePath, f)))]\n",
        "    negativeImageFiles = [f for f in listdir(negativeImagePath) if (isfile(join(negativeImagePath, f)))]\n",
        "\n",
        "    positiveCount = len(positiveImageFiles)\n",
        "    negativeCount = len(negativeImageFiles)\n",
        "\n",
        "    print('positive samples: ' + str(positiveCount))\n",
        "    print('negative samples: ' + str(negativeCount))\n",
        "    imageCount = positiveCount + negativeCount\n",
        "    #intialization\n",
        "    X_LL = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_LH = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_HL = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_HH = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_index = np.zeros((positiveCount + negativeCount, 1))\n",
        "    Y = np.zeros((positiveCount + negativeCount, 1))\n",
        "    \n",
        "    sampleIndex = 0\n",
        "    # read all images, convert to float, divide by 255 (leads to gray range 0..1), reshape into a row vector\n",
        "    # write class 0 for positive and 1 for negative samples\n",
        "\n",
        "    sampleIndex = readImageSet(positiveImageFiles, positiveImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, 0)\n",
        "    print('positive data loaded.')\n",
        "    \n",
        "    sampleIndex += readImageSet(negativeImageFiles, negativeImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, 1)\n",
        "    print('negative data loaded.')\n",
        "\n",
        "    print('Total Samples Loaded: ', sampleIndex)\n",
        "    \n",
        "    X_LL, X_LH, X_HL, X_HH, Y = shuffle(X_LL, X_LH, X_HL, X_HH, Y, random_state=0)\n",
        "    \n",
        "    return X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount\n",
        "\n",
        "def mainReadDatafromDrive(dataSetNumber, dataType):\n",
        "\n",
        "    # dataType can be 'train' or 'test'\n",
        "\n",
        "    positiveFromTrainDir = '/content/drive/MyDrive/Moire/' + dataType + '/positive/' + dataSetNumber + '/'\n",
        "    negativeFromTrainDir = '/content/drive/MyDrive/Moire/' + dataType + '/negative/' + dataSetNumber + '/'\n",
        "    print(positiveFromTrainDir)\n",
        "    print(negativeFromTrainDir)\n",
        "\n",
        "    if not os.path.exists(positiveFromTrainDir):\n",
        "      print(\"ERROR: \" + positiveFromTrainDir + ' does not exist.  Exiting.')\n",
        "      raise ValueError('Directory does not exist')\n",
        "    if not os.path.exists(negativeFromTrainDir):\n",
        "      print(\"ERROR: \" + negativeFromTrainDir + ' does not exist.  Exiting.')\n",
        "      raise ValueError('Directory does not exist')\n",
        "    \n",
        "    X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount = readWaveletData(positiveFromTrainDir, negativeFromTrainDir)\n",
        "\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = reshapeData(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount)\n",
        "\n",
        "    return X_LL, X_LH, X_HL, X_HH, Y\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azf3IN-SRudm"
      },
      "source": [
        "## Train CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ASB86jIRxvK"
      },
      "source": [
        "import os\n",
        "\n",
        "from keras.models import Model # basic class for specifying and training a neural network\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Add, Multiply, Maximum\n",
        "\n",
        "def createModel(height, width, depth, num_classes):\n",
        "#     num_epochs = 20 # 50 26 200 # we iterate 200 times over the entire training set\n",
        "    kernel_size_1 = 7 # we will use 7x7 kernels \n",
        "    kernel_size_2 = 3 # we will use 3x3 kernels \n",
        "    pool_size = 2 # we will use 2x2 pooling throughout\n",
        "    conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
        "    conv_depth_2 = 16 # ...switching to 16 after the first pooling layer\n",
        "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
        "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
        "    hidden_size = 32 # 128 512 the FC layer will have 512 neurons\n",
        "\n",
        "\n",
        "    inpLL = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpLH = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHL = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHH = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    \n",
        "    conv_1_LL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLL)\n",
        "    conv_1_LH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLH)\n",
        "    conv_1_HL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHL)\n",
        "    conv_1_HH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHH)\n",
        "\n",
        "    pool_1_LL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LL)\n",
        "    pool_1_LH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LH)\n",
        "    pool_1_HL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HL)\n",
        "    pool_1_HH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HH)\n",
        "\n",
        "    avg_LH_HL_HH = Maximum()([pool_1_LH, pool_1_HL, pool_1_HH])\n",
        "    inp_merged = Multiply()([pool_1_LL, avg_LH_HL_HH])\n",
        "    print(inp_merged)\n",
        "    C4 = Convolution2D(conv_depth_2, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(inp_merged)\n",
        "    S2 = MaxPooling2D(pool_size=(4, 4))(C4)\n",
        "    drop_1 = Dropout(drop_prob_1)(S2)\n",
        "    C5 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(drop_1)\n",
        "    S3 = MaxPooling2D(pool_size=(pool_size, pool_size))(C5)\n",
        "    C6 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(S3)\n",
        "    S4 = MaxPooling2D(pool_size=(pool_size, pool_size))(C6)\n",
        "    drop_2 = Dropout(drop_prob_1)(S4)\n",
        "    # Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
        "    flat = Flatten()(drop_2)\n",
        "    hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "    drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "    out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "    \n",
        "    model = Model(inputs=[inpLL, inpLH, inpHL, inpHH], outputs=out) # To define a model, just specify its input and output layers\n",
        "    intermediate_model = Model(inputs=[inpLL, inpLH, inpHL, inpHH], outputs=inp_merged)\n",
        "    \n",
        "    return model, intermediate_model"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTX2vudptIaO"
      },
      "source": [
        "#To detect Moire ́ patternzs, images are first decomposed using Wavelet decomposition (refer to file '') and trained using multi-input Convolutional neural network. The strength of the proposed CNN model is, it uses the LL intensity image (from the Wavelet decomposition) as a weight parameter for the Moire ́ pattern, thereby approximating the spatial spread of the Moire ́ pattern in the image. Usage of CNN model performs better than frequency thresholding approach as the model is trained considering diverse scenarios and it is able to distinguish between the high frequency of background texture and the Moire ́ pattern.\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import time\n",
        "from tensorflow import keras\n",
        "\n",
        "# - read positive and negative training data\n",
        "# - create X and Y from training data\n",
        "\n",
        "\n",
        "def trainMoire(superpoch, dataSetNumber, numEpochs, weights_file = None):\n",
        "\n",
        "    print('##### TRAINING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber[0] + ', ', dataSetNumber[1])\n",
        "\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(dataSetNumber[0], 'train')\n",
        "    X_LL_2, X_LH_2, X_HL_2, X_HH_2, Y_2 = mainReadDatafromDrive(dataSetNumber[1], 'train')\n",
        "\n",
        "\n",
        "    print('Concatenating 2 datasets.')\n",
        "    print(X_LL.shape)\n",
        "    print(X_LL_2.shape)\n",
        "    X_LL = np.concatenate((X_LL, X_LL_2), axis=0)\n",
        "    X_LH = np.concatenate((X_LH, X_LH_2), axis=0)\n",
        "    X_HL = np.concatenate((X_HL, X_HL_2), axis=0)\n",
        "    X_HH = np.concatenate((X_HH, X_HH_2), axis=0)\n",
        "    Y = np.concatenate((Y, Y_2), axis=0)\n",
        "    X_LL_2 = None\n",
        "    X_LH_2 = None\n",
        "    X_HL_2 = None\n",
        "    X_HH_2 = None\n",
        "    Y_2 = None\n",
        "\n",
        "    modelName = trainCNNModel(superpoch, dataSetNumber, X_LL, X_LH, X_HL, X_HH, Y, numEpochs, weights_file)\n",
        "    \n",
        "    X_LL = None\n",
        "    X_LH = None\n",
        "    X_HL = None \n",
        "    X_HH = None\n",
        "    Y = None\n",
        "\n",
        "    return modelName\n",
        "    # evaluate(model, X_LL_test,X_LH_test,X_HL_test,X_HH_test,Y_test)\n",
        "    \n",
        "\n",
        "def trainCNNModel(superpoch, dataSetNumber, X_LL_train, X_LH_train, X_HL_train, X_HH_train, y_train, num_epochs, weights_file):\n",
        "\n",
        "    batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "    print(\"SHAPE\")\n",
        "    print(X_LL_train.shape);\n",
        "    num_train, height, width, depth = X_LL_train.shape\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "    # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "\n",
        "    checkPointFolder = '/content/drive/MyDrive/Moire/checkPoint'\n",
        "    checkpoint_name = checkPointFolder + '/mid-sp' + superpoch + '-ds' + dataSetNumber[0] + '_' + dataSetNumber[1] + '-ep{epoch:03d}-ls{val_loss:.5f}-ac{val_accuracy:.2f}-weights' \n",
        "    checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "    callbacks_list = [checkpoint]\n",
        "    \n",
        "    if not os.path.exists(checkPointFolder):\n",
        "        os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "    model = None\n",
        "    # if preloaded_model == None:\n",
        "    #   print('A preloaded model was not provided.  Creating a new one')\n",
        "    #   model, _ = createModel(height, width, depth, num_classes)\n",
        "\n",
        "    if weights_file != None:\n",
        "      print('--- Loading weights file: ' + weights_file)\n",
        "      model = keras.models.load_model(weights_file)\n",
        "    else:\n",
        "      print('--- No weights file provided.  Compiling a new one.')\n",
        "      \n",
        "      model, _ = createModel(height, width, depth, num_classes)\n",
        "      model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "                    optimizer='adam', # using the Adam optimiser\n",
        "                    metrics=['accuracy']) # reporting the accuracy\n",
        "      # if preloaded_model == None:\n",
        "        \n",
        "      # else:\n",
        "      #   print('--- Model already loaded with weights.  Skipping compilation')\n",
        "\n",
        "    model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "              batch_size=batch_size, epochs=num_epochs,\n",
        "              verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "    # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "    # print('------ weights ------')\n",
        "    # for i in range(len(model.layers)):\n",
        "    #   print(len(model.layers[i].get_weights()))\n",
        "\n",
        "    modelName = '/content/drive/MyDrive/Moire/checkPoint/final-tm' + str(time.time()).split('.')[0] + '-sp' + superpoch + '-ds' + dataSetNumber[0] + '_' + dataSetNumber[1] + '-weights'\n",
        "    model.save(modelName)\n",
        "    \n",
        "    return modelName\n",
        "\n",
        "\n",
        "def evaluate(model, X_LL_test,X_LH_test,X_HL_test,X_HH_test,y_test):\n",
        "\n",
        "    model_out = model.predict([X_LL_test,X_LH_test,X_HL_test,X_HH_test])\n",
        "    passCnt = 0\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "    positive_confidence_threshold = 0.5\n",
        "    incorrect_threshold_count = 0\n",
        "    largest_fp = 0\n",
        "    smallest_tp = 2\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "            str_label='Pass'\n",
        "            passCnt = passCnt + 1\n",
        "        else:\n",
        "            str_label='Fail'\n",
        "\n",
        "        if y_test[i] ==0:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                if model_out[i, 0] < smallest_tp:\n",
        "                  smallest_tp = model_out[i, 0]\n",
        "                # print('TP' + str(model_out[i, :]))\n",
        "                TP = TP + 1;\n",
        "            else:\n",
        "                # print('FN' + str(model_out[i, :]))\n",
        "                FN = FN + 1\n",
        "        else:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                # print('TN' + str(model_out[i, :]))\n",
        "                TN = TN + 1;\n",
        "            else:\n",
        "                if model_out[i, 1] > largest_fp:\n",
        "                  largest_fp = model_out[i, 1]\n",
        "                # print('FP' + str(model_out[i, :]))\n",
        "                FP = FP + 1\n",
        "\n",
        "        if model_out[i, 0] > positive_confidence_threshold and y_test[i] == 1:\n",
        "          incorrect_threshold_count = incorrect_threshold_count + 1\n",
        "\n",
        "    start = \"\\033[1m\"\n",
        "    end = \"\\033[0;0m\"\n",
        "\n",
        "    print(start + 'incorrect positives with threshold: ' + end + str(incorrect_threshold_count))\n",
        "    print(start + 'largest false positive confidence: ' + end + str(largest_fp))\n",
        "    print(start + 'smalles true positive confidence: ' + end + str(smallest_tp))\n",
        "    print(start + 'confusion matrix (test / validation)' + end)\n",
        "    print(start + 'true positive:  '+ end + str(TP))\n",
        "    print(start + 'false positive: '+ end + str(FP))\n",
        "    print(start + 'true negative:  '+ end + str(TN))\n",
        "    print(start + 'false negative: '+ end + str(FN))\n",
        "    print('\\n')\n",
        "\n",
        "    if TP+FP+FN+TN != 0:\n",
        "      print(start + 'accuracy:  ' + end + \"{:.4f} %\".format(100*(TP+TN)/(TP+FP+FN+TN)))\n",
        "    else:\n",
        "      print(start + 'accuracy:  ' + end + \"{:.4f} %\".format(100))\n",
        "\n",
        "    if TP + FP != 0:\n",
        "      print(start + 'precision: ' + end + \"{:.4f} %\".format(100*TP/(TP + FP)))\n",
        "    else:\n",
        "      print(start + 'precision: ' + end + \"{:.4f} %\".format(100))\n",
        "\n",
        "    if TP + FN != 0:\n",
        "      print(start + 'recall:  ' + end + \"{:.4f} %\".format(100*TP/(TP + FN)))\n",
        "    else:\n",
        "      print(start + 'recall:  ' + end + \"{:.4f} %\".format(100))\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "120i4Ry-qa_N"
      },
      "source": [
        "\n",
        "# !ls /content/drive/MyDrive/Moire/checkPoint/\n",
        "# from google.colab import files\n",
        "# files.download('content/drive/MyDrive/Moire/checkPoint/Weights-028--0.06866.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWnNYpcTqa_O"
      },
      "source": [
        "## Test CNN Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV0rGdyIueOf"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "#constants\n",
        "width = 500#384 #change dimensions according to the input image in the training\n",
        "height = 375#512 #change dimensions according to the input image in the training\n",
        "depth = 1\n",
        "num_classes = 2\n",
        "\n",
        "def testMoire(weightsFile, superpoch, dataSetNumber):\n",
        "\n",
        "    print('##### TESTING - superpoch: ' + superpoch + ' - dataset: ' + dataSetNumber[0] + ', ' + dataSetNumber[1])\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(dataSetNumber[0], 'test')\n",
        "    X_LL_2, X_LH_2, X_HL_2, X_HH_2, Y_2 = mainReadDatafromDrive(dataSetNumber[1], 'test')\n",
        "\n",
        "    print('Concatenating 2 datasets.')\n",
        "    X_LL = np.concatenate((X_LL, X_LL_2), axis=0)\n",
        "    X_LH = np.concatenate((X_LH, X_LH_2), axis=0)\n",
        "    X_HL = np.concatenate((X_HL, X_HL_2), axis=0)\n",
        "    X_HH = np.concatenate((X_HH, X_HH_2), axis=0)\n",
        "    Y = np.concatenate((Y, Y_2), axis=0)\n",
        "    X_LL_2 = None\n",
        "    X_LH_2 = None\n",
        "    X_HL_2 = None\n",
        "    X_HH_2 = None\n",
        "    Y_2 = None\n",
        "    \n",
        "    CNN_model = keras.models.load_model(weightsFile)\n",
        "    evaluate(CNN_model,X_LL,X_LH,X_HL,X_HH, Y)\n",
        "    X_LL = None\n",
        "    X_LH = None\n",
        "    X_HL = None \n",
        "    X_HH = None\n",
        "    Y = None\n",
        "\n",
        "def run(model, X_LL_test,X_LH_test,X_HL_test,y_test):\n",
        "    return\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYSPiTtfqa_O"
      },
      "source": [
        "# weightsFile = \"moirePattern3CNN_.h5\"\n",
        "    \n",
        "    \n",
        "# mainTest('content/drive/MyDrive/Moire/checkPoint/moirePattern3CNN_.h5', '/content/drive/MyDrive/Moire/testDataPositive', '/content/drive/MyDrive/Moire/testDataNegative')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmyNG_XqMzIb"
      },
      "source": [
        "## Synthesize Data\n",
        "Synthesize random data wooo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELZtp0_bM3rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b3141d-40d3-4fc7-f547-18750b33b98a"
      },
      "source": [
        "\n",
        "from PIL import Image, ImageDraw\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "colors = ['orange', 'blue', 'yellow', 'red', 'green', 'purple']\n",
        "\n",
        "def randomColor():\n",
        "  return colors[random.randint(0, 5)]\n",
        "\n",
        "def getBoundingBox(minWidth, maxWidth, minHeight, maxHeight):\n",
        "  length = random.randint(minWidth, maxWidth)\n",
        "  length1 = random.randint(minHeight, maxHeight)\n",
        "  w, h = length, length1\n",
        "  x = random.randint(0, 1000 - length)\n",
        "  y = random.randint(0, 750 - length1)\n",
        "  return [(x, y), (w + x, h + y)]\n",
        "\n",
        "def getBoundingSquare(minWidth, maxWidth):\n",
        "  length = random.randint(minWidth, maxWidth)\n",
        "  w, h = length, length\n",
        "  x = random.randint(0, 1000 - length)\n",
        "  y = random.randint(0, 750 - length)\n",
        "  return [(x, y), (w + x, h + y)]\n",
        "\n",
        "def getBoxFromSize(widthSize, heightSize, square = False):\n",
        "\n",
        "  minHeight = 0\n",
        "  maxHeight = 0\n",
        "  minWidth = 0\n",
        "  maxWidth = 0\n",
        "\n",
        "  if widthSize == 'small':\n",
        "    minWidth = 25\n",
        "    maxWidth = 100\n",
        "  elif widthSize == 'medium':\n",
        "    minWidth = 120\n",
        "    maxWidth = 280\n",
        "  elif widthSize == 'large':\n",
        "    minWidth = 280\n",
        "    maxWidth = 450\n",
        "  elif widthSize == 'x-large':\n",
        "    minWidth = 450\n",
        "    maxWidth = 620\n",
        "  elif widthSize == 'xx-large':\n",
        "    minWidth = 620\n",
        "    maxWidth = 900\n",
        "  else:\n",
        "    raise ValueError('width was not the proper value')\n",
        "\n",
        "  if heightSize == 'small':\n",
        "    minHeight = 25\n",
        "    maxHeight = 100\n",
        "  elif heightSize == 'medium':\n",
        "    minHeight = 120\n",
        "    maxHeight = 280\n",
        "  elif heightSize == 'large':\n",
        "    minHeight = 280\n",
        "    maxHeight = 450\n",
        "  elif heightSize == 'x-large':\n",
        "    minHeight = 450\n",
        "    maxHeight = 620\n",
        "  else:\n",
        "    raise ValueError('height was not the proper value')\n",
        "\n",
        "  if square == True:\n",
        "    return getBoundingSquare(minWidth, maxWidth)\n",
        "  else:\n",
        "    return getBoundingBox(minWidth, maxWidth, minHeight, maxHeight)\n",
        "\n",
        "def getRandomPointInRegion(shape):\n",
        "  return (random.randint(shape[0][0], shape[1][0]), random.randint(shape[0][1], shape[1][1]))\n",
        "\n",
        "def circle(image, imageConfig):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, True)\n",
        "    draw.chord(shape, start=0, end=360, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def ellipse(image, imageConfig):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    draw.chord(shape, start=0, end=360, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def chord(image, imageConfig):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    start = random.randint(30, 145)\n",
        "    end = random.randint(225, 340)\n",
        "    draw.chord(shape, start=start, end=end, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def rectangle(image, imageConfig):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    draw.rectangle(shape, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def square(image, imageConfig):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, True)\n",
        "    draw.rectangle(shape, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def pieslice(image, imageConfig):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, True)\n",
        "    start = random.randint(30, 145)\n",
        "    end = random.randint(225, 340)\n",
        "    draw.pieslice(shape, start=start, end=end, fill=randomColor(), outline=randomColor(), width=random.randint(2,20))\n",
        "\n",
        "def polygon(image, imageConfig):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    shape = getBoxFromSize(imageConfig.widthClass, imageConfig.heightClass, False)\n",
        "    point = None\n",
        "    if imageConfig.sides == None:\n",
        "      raise ValueError('The number of sides was not specified')\n",
        "    elif imageConfig.sides < 3:\n",
        "      raise ValueError('There needs to be three or more sides')\n",
        "    elif imageConfig.sides > 10:\n",
        "      raise ValueError('There needs to be ten or less sides')\n",
        "    elif imageConfig.sides == 3:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif imageConfig.sides == 4:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif imageConfig.sides == 5:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif imageConfig.sides == 6:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif imageConfig.sides == 7:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif imageConfig.sides == 8:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif imageConfig.sides == 9:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "    elif imageConfig.sides == 10:\n",
        "      points = (getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape), getRandomPointInRegion(shape))\n",
        "\n",
        "    draw.polygon(points, fill=randomColor())\n",
        "    \n",
        "class ImageConfig(object):\n",
        "    def __init__(self, process, widthClass, heightClass, amount, sides = None):\n",
        "        self.process = process\n",
        "        self.widthClass = widthClass\n",
        "        self.heightClass = heightClass\n",
        "        self.amount = amount\n",
        "        self.sides = sides\n",
        "\n",
        "def generateFakeImages(imageConfigList):\n",
        "\n",
        "  imageData = np.full((750, 1000), 255, np.uint8)\n",
        "  image = Image.fromarray(imageData)\n",
        "\n",
        "  if image.mode != 'RGB':\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "  for config in imageConfigList:\n",
        "    if config.process == 'circle':\n",
        "      for number in range(config.amount):\n",
        "        circle(image, config)\n",
        "    if config.process == 'chord':\n",
        "      for number in range(config.amount):\n",
        "        chord(image, config)\n",
        "    if config.process == 'pieslice':\n",
        "      for number in range(config.amount):\n",
        "        pieslice(image, config)\n",
        "    if config.process == 'square':\n",
        "      for number in range(config.amount):\n",
        "        square(image, config)\n",
        "    if config.process == 'ellipse':\n",
        "      for number in range(config.amount):\n",
        "        ellipse(image, config)\n",
        "    if config.process == 'rectangle':\n",
        "      for number in range(config.amount):\n",
        "        rectangle(image, config)\n",
        "    if config.process == 'polygon':\n",
        "      for number in range(config.amount):\n",
        "        polygon(image, config)\n",
        "\n",
        "  image.save('/content/drive/MyDrive/Moire/unnormalized/negative/018/' + str(1) + '.jpeg')\n",
        "      \n",
        "      \n",
        "\n",
        "# 018\n",
        "imageConfigList18 = []\n",
        "# imageConfigList18.append(ImageConfig('circle', 'large', 'x-large', 3))\n",
        "# imageConfigList18.append(ImageConfig('circle', 'xx-large', 'x-large', 3))\n",
        "# imageConfigList18.append(ImageConfig('circle', 'small', 'x-large', 5))\n",
        "\n",
        "# imageConfigList18.append(ImageConfig('chord', 'large', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('chord', 'x-large', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('chord', 'small', 'x-large', 5))\n",
        "\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'large', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'medium', 'x-large', 5))\n",
        "# imageConfigList18.append(ImageConfig('pieslice', 'large', 'large', 5))\n",
        "\n",
        "# imageConfigList18.append(ImageConfig('square', 'medium', 'medium', 5))\n",
        "\n",
        "# imageConfigList18.append(ImageConfig('ellipse', 'small', 'small', 5))\n",
        "\n",
        "# imageConfigList18.append(ImageConfig('rectangle', 'small', 'small', 5))\n",
        "\n",
        "imageConfigList18.append(ImageConfig('polygon', 'medium', 'medium', 5, 10))\n",
        "\n",
        "# getRandomPointInRegion(shape)\n",
        "\n",
        "# shape = getBoxFromSize('medium', 'medium', True)\n",
        "# print(shape)\n",
        "# print(getRandomPointInRegion(shape))\n",
        "# print(getRandomPointInRegion(shape))\n",
        "# print(getRandomPointInRegion(shape))\n",
        "# print(getRandomPointInRegion(shape))\n",
        "# print(getRandomPointInRegion(shape))\n",
        "\n",
        "# generateFakeImages(imageConfigList18)\n",
        "# getBoxFromSize('small', 'small')[0]\n",
        "\n",
        "print(((100, 100), (200, 50), (125, 25)))\n",
        "  \n",
        "\n",
        "# print(getBoxFromSize('xx-large', 'x-large'))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((100, 100), (200, 50), (125, 25))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTxUTR6Yv2LG"
      },
      "source": [
        "## Extended Training\n",
        "Take the trained model and continue training with additional data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_fb9-mhtcBbo",
        "outputId": "a270436e-38b0-4db3-f3a0-b26667d72a7a"
      },
      "source": [
        "# normalizeRawImages(\"001\", \"001\")\n",
        "# augmentNormalizedData(\"001\", \"001\")\n",
        "# normalizeRawImages(\"001\", \"002\")\n",
        "# augmentNormalizedData(\"001\", \"002\")\n",
        "# normalizeRawImages(\"001\", \"003\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"003\")\n",
        "# normalizeRawImages(\"001\", \"004\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"004\")\n",
        "# normalizeRawImages(\"001\", \"005\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"005\")\n",
        "# normalizeRawImages(\"001\", \"006\")                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       001\", \"003\")\n",
        "# augmentNormalizedData(\"001\", \"006\")\n",
        "\n",
        "# weights_file = '/content/drive/MyDrive/Moire/checkPoint/final-tm1626590047-sp001-ds011_008-weights'\n",
        "weights_file = None\n",
        "\n",
        "superpoch_count = 1\n",
        "epochs = 20\n",
        "datasets = ['017', '017']\n",
        "\n",
        "for sp in range(superpoch_count):\n",
        "  superpoch = '00' + str(sp + 1)\n",
        "  print('---------------------------------------------------------')\n",
        "  print('BEGINNING TRAINING OF SUPERPOCH: ' + superpoch)\n",
        "  print('---------------------------------------------------------')\n",
        "  for ds in range(len(datasets)):\n",
        "    dsIndex = ds\n",
        "    otherDsIndex = ((ds + 1) % len(datasets))\n",
        "    # datasets = ['00' + str(dsNumber), '00' + str(otherDsNumber)]\n",
        "    print([datasets[dsIndex], datasets[otherDsIndex]])\n",
        "\n",
        "    # print(ds)\n",
        "    # print(i)\n",
        "\n",
        "    # print(datasets)\n",
        "    # normalizeRawImages(superpoch, dataset)\n",
        "    # augmentNormalizedData(superpoch, dataset)\n",
        "\n",
        "    weights_file = trainMoire(superpoch, [datasets[dsIndex], datasets[otherDsIndex]], epochs, weights_file)\n",
        "    testMoire(weights_file, superpoch, [datasets[dsIndex], datasets[otherDsIndex]])\n",
        "    print('---------------------------------------------------------')\n",
        "\n",
        "# testMoire(weights_file, '001', ['004', '005'])\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/001/IMG_2866.HEIC\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/001/IMG_2875.HEIC\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/001/IMG_2893.HEIC\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/002/IMG_2900.HEIC\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/002/IMG_2904.HEIC\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/002/IMG_2915.HEIC\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/002/IMG_2921.HEIC\n",
        "# /content/drive/MyDrive/Moire/preaugmented/positive/002/IMG_2929.HEIC\n",
        "\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------\n",
            "BEGINNING TRAINING OF SUPERPOCH: 001\n",
            "---------------------------------------------------------\n",
            "['017', '017']\n",
            "##### TRAINING - superpoch: 001 - dataset: 017,  017\n",
            "/content/drive/MyDrive/Moire/train/positive/017/\n",
            "/content/drive/MyDrive/Moire/train/negative/017/\n",
            "positive samples: 288\n",
            "negative samples: 288\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  864\n",
            "Dataset length: 576\n",
            "num_train_samples 576\n",
            "/content/drive/MyDrive/Moire/train/positive/017/\n",
            "/content/drive/MyDrive/Moire/train/negative/017/\n",
            "positive samples: 288\n",
            "negative samples: 288\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  864\n",
            "Dataset length: 576\n",
            "num_train_samples 576\n",
            "Concatenating 2 datasets.\n",
            "(576, 375, 500, 1)\n",
            "(576, 375, 500, 1)\n",
            "SHAPE\n",
            "(1152, 375, 500, 1)\n",
            "--- No weights file provided.  Compiling a new one.\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 187, 250, 32), dtype=tf.float32, name=None), name='multiply/mul:0', description=\"created by layer 'multiply'\")\n",
            "Epoch 1/20\n",
            "33/33 [==============================] - 40s 258ms/step - loss: 0.6482 - accuracy: 0.6323 - val_loss: 0.4119 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.41193, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep001-ls0.41193-ac0.91-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep001-ls0.41193-ac0.91-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "33/33 [==============================] - 7s 214ms/step - loss: 0.3564 - accuracy: 0.8624 - val_loss: 0.1480 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.41193 to 0.14798, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep002-ls0.14798-ac0.93-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep002-ls0.14798-ac0.93-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/20\n",
            "33/33 [==============================] - 7s 214ms/step - loss: 0.1300 - accuracy: 0.9579 - val_loss: 0.0975 - val_accuracy: 0.9655\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.14798 to 0.09746, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep003-ls0.09746-ac0.97-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep003-ls0.09746-ac0.97-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/20\n",
            "33/33 [==============================] - 7s 214ms/step - loss: 0.1021 - accuracy: 0.9653 - val_loss: 0.0550 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.09746 to 0.05502, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep004-ls0.05502-ac0.97-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep004-ls0.05502-ac0.97-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/20\n",
            "33/33 [==============================] - 7s 214ms/step - loss: 0.1137 - accuracy: 0.9693 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.05502 to 0.01393, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep005-ls0.01393-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep005-ls0.01393-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0612 - accuracy: 0.9912 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01393 to 0.00131, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep006-ls0.00131-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep006-ls0.00131-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.7634e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00131 to 0.00018, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep007-ls0.00018-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep007-ls0.00018-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0608 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00018\n",
            "Epoch 9/20\n",
            "33/33 [==============================] - 7s 214ms/step - loss: 0.1347 - accuracy: 0.9755 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00018\n",
            "Epoch 10/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0444 - accuracy: 0.9835 - val_loss: 0.0213 - val_accuracy: 0.9914\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00018\n",
            "Epoch 11/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0401 - accuracy: 0.9923 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00018\n",
            "Epoch 12/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0278 - accuracy: 0.9866 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00018\n",
            "Epoch 13/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.1260 - accuracy: 0.9716 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00018\n",
            "Epoch 14/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0572 - accuracy: 0.9707 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00018\n",
            "Epoch 15/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0850 - accuracy: 0.9447 - val_loss: 0.0930 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00018\n",
            "Epoch 16/20\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.0658 - accuracy: 0.9594 - val_loss: 3.7298e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00018 to 0.00004, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep016-ls0.00004-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep016-ls0.00004-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0161 - accuracy: 0.9910 - val_loss: 1.1999e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00004\n",
            "Epoch 18/20\n",
            "33/33 [==============================] - 7s 211ms/step - loss: 0.0565 - accuracy: 0.9842 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00004\n",
            "Epoch 19/20\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.0442 - accuracy: 0.9583 - val_loss: 0.0070 - val_accuracy: 0.9914\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00004\n",
            "Epoch 20/20\n",
            "33/33 [==============================] - 7s 211ms/step - loss: 0.0599 - accuracy: 0.9268 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00004\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/final-tm1626846634-sp001-ds017_017-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "##### TESTING - superpoch: 001 - dataset: 017, 017\n",
            "/content/drive/MyDrive/Moire/test/positive/017/\n",
            "/content/drive/MyDrive/Moire/test/negative/017/\n",
            "positive samples: 72\n",
            "negative samples: 72\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  216\n",
            "Dataset length: 144\n",
            "num_train_samples 144\n",
            "/content/drive/MyDrive/Moire/test/positive/017/\n",
            "/content/drive/MyDrive/Moire/test/negative/017/\n",
            "positive samples: 72\n",
            "negative samples: 72\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  216\n",
            "Dataset length: 144\n",
            "num_train_samples 144\n",
            "Concatenating 2 datasets.\n",
            "\u001b[1mincorrect positives with threshold: \u001b[0;0m0\n",
            "\u001b[1mlargest false positive confidence: \u001b[0;0m0\n",
            "\u001b[1msmalles true positive confidence: \u001b[0;0m0.9533887\n",
            "\u001b[1mconfusion matrix (test / validation)\u001b[0;0m\n",
            "\u001b[1mtrue positive:  \u001b[0;0m144\n",
            "\u001b[1mfalse positive: \u001b[0;0m0\n",
            "\u001b[1mtrue negative:  \u001b[0;0m144\n",
            "\u001b[1mfalse negative: \u001b[0;0m0\n",
            "\n",
            "\n",
            "\u001b[1maccuracy:  \u001b[0;0m100.0000 %\n",
            "\u001b[1mprecision: \u001b[0;0m100.0000 %\n",
            "\u001b[1mrecall:  \u001b[0;0m100.0000 %\n",
            "---------------------------------------------------------\n",
            "['017', '017']\n",
            "##### TRAINING - superpoch: 001 - dataset: 017,  017\n",
            "/content/drive/MyDrive/Moire/train/positive/017/\n",
            "/content/drive/MyDrive/Moire/train/negative/017/\n",
            "positive samples: 288\n",
            "negative samples: 288\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  864\n",
            "Dataset length: 576\n",
            "num_train_samples 576\n",
            "/content/drive/MyDrive/Moire/train/positive/017/\n",
            "/content/drive/MyDrive/Moire/train/negative/017/\n",
            "positive samples: 288\n",
            "negative samples: 288\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  864\n",
            "Dataset length: 576\n",
            "num_train_samples 576\n",
            "Concatenating 2 datasets.\n",
            "(576, 375, 500, 1)\n",
            "(576, 375, 500, 1)\n",
            "SHAPE\n",
            "(1152, 375, 500, 1)\n",
            "--- Loading weights file: /content/drive/MyDrive/Moire/checkPoint/final-tm1626846634-sp001-ds017_017-weights\n",
            "Epoch 1/20\n",
            "33/33 [==============================] - 8s 224ms/step - loss: 0.0507 - accuracy: 0.9826 - val_loss: 5.2652e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00001, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep001-ls0.00001-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep001-ls0.00001-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.0135 - accuracy: 0.9932 - val_loss: 4.0813e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00001 to 0.00000, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep002-ls0.00000-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep002-ls0.00000-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0619 - accuracy: 0.9836 - val_loss: 7.4608e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep003-ls0.00000-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep003-ls0.00000-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/20\n",
            "33/33 [==============================] - 7s 214ms/step - loss: 0.0279 - accuracy: 0.9884 - val_loss: 0.0205 - val_accuracy: 0.9914\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00000\n",
            "Epoch 5/20\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.0130 - accuracy: 0.9913 - val_loss: 1.1742e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00000\n",
            "Epoch 6/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0051 - accuracy: 0.9961 - val_loss: 2.4619e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00000\n",
            "Epoch 7/20\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.0081 - accuracy: 0.9952 - val_loss: 5.8193e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00000\n",
            "Epoch 8/20\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.0062 - accuracy: 0.9961 - val_loss: 2.0368e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00000\n",
            "Epoch 9/20\n",
            "33/33 [==============================] - 7s 213ms/step - loss: 0.0092 - accuracy: 0.9923 - val_loss: 1.2075e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00000\n",
            "Epoch 10/20\n",
            "33/33 [==============================] - 7s 211ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 1.3493e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00000\n",
            "Epoch 11/20\n",
            "33/33 [==============================] - 7s 211ms/step - loss: 0.0159 - accuracy: 0.9932 - val_loss: 1.1196e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00000\n",
            "Epoch 12/20\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.0086 - accuracy: 0.9923 - val_loss: 2.8158e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep012-ls0.00000-ac1.00-weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Moire/checkPoint/mid-sp001-ds017_017-ep012-ls0.00000-ac1.00-weights/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/20\n",
            "10/33 [========>.....................] - ETA: 4s - loss: 0.0132 - accuracy: 0.9875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-03b2da648e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# augmentNormalizedData(superpoch, dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainMoire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motherDsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mtestMoire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuperpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motherDsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-141-bb2b3004dcfc>\u001b[0m in \u001b[0;36mtrainMoire\u001b[0;34m(superpoch, dataSetNumber, numEpochs, weights_file)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mY_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmodelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainCNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataSetNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumEpochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mX_LL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-141-bb2b3004dcfc>\u001b[0m in \u001b[0;36mtrainCNNModel\u001b[0;34m(superpoch, dataSetNumber, X_LL_train, X_LH_train, X_HL_train, X_HH_train, y_train, num_epochs, weights_file)\u001b[0m\n\u001b[1;32m     97\u001b[0m     model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n\u001b[1;32m     98\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m               verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;31m# score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyiISSNr2ZAr"
      },
      "source": [
        "# X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train = mainReadDatafromDrive('/content/drive/MyDrive/Moire/trainDataPositive', '/content/drive/MyDrive/Moire/trainDataNegative')\n",
        "# !ls /content/drive/MyDrive/Moire/preaugmented/positive/003\n",
        "print('negative unnormalized 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/negative/001')])))\n",
        "print('positive unnormalized 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/positive/001')])))\n",
        "print('negative unnormalized 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/negative/002')])))\n",
        "print('positive unnormalized 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/positive/002')])))\n",
        "print('negative unnormalized 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/negative/003')])))\n",
        "print('positive unnormalized 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/unnormalized/positive/003')])))\n",
        "# print('negative train 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/negative/001')])))\n",
        "# print('negative train 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/negative/002')])))\n",
        "# print('negative train 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/negative/003')])))\n",
        "# print('positive train 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/positive/001')])))\n",
        "# print('positive train 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/positive/002')])))\n",
        "# print('positive train 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/train/positive/003')])))\n",
        "# print('negative test 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/negative/001')])))\n",
        "# print('negative test 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/negative/002')])))\n",
        "# print('negative test 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/negative/003')])))\n",
        "# print('positive test 001: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/positive/001')])))\n",
        "# print('positive test 002: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/positive/002')])))\n",
        "# print('positive test 003: ' + str(len([name for name in os.listdir('/content/drive/MyDrive/Moire/test/positive/003')])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9RFVMxIroLI"
      },
      "source": [
        "# testMoire('/content/drive/MyDrive/Moire/checkPoint/mid-sp005-ds002-ep016-ls0.00455-ac1.00-weights.h5', \"001\", \"001\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDO0lSriFOJt"
      },
      "source": [
        "def intermediateMoire(dataSetNumber, weights_file = None):\n",
        "\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(dataSetNumber, 'test')\n",
        "    return createIntermediateModel(dataSetNumber, X_LL, X_LH, X_HL, X_HH, Y, weights_file)\n",
        "    \n",
        "\n",
        "def createIntermediateModel(dataSetNumber, X_LL_train, X_LH_train, X_HL_train, X_HH_train, y_train, weights_file):\n",
        "\n",
        "    batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "    print(\"SHAPE\")\n",
        "    print(X_LL_train.shape);\n",
        "    num_train, height, width, depth = X_LL_train.shape\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "    # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "    \n",
        "    # if not os.path.exists(checkPointFolder):\n",
        "    #     os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "    model, intermediate_model = createModel(height, width, depth, num_classes)\n",
        "\n",
        "    if weights_file != None:\n",
        "      print('--- Loading weights file: ' + weights_file)\n",
        "      model.load_weights(weights_file)\n",
        "    else:\n",
        "      print('--- No weights file provided.  Creating new model.')\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "                  optimizer='adam', # using the Adam optimiser\n",
        "                  metrics=['accuracy']) # reporting the accuracy\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # weights_list = model.get_weights()\n",
        "    # for i in range(len(model.layers)):\n",
        "    #   print(model.layers[i].get_weights())\n",
        "      # print(model.layers[i].get_weights()[1])\n",
        "    \n",
        "    model_index = 0;\n",
        "    print('----------------')\n",
        "    for layer in intermediate_model.layers:\n",
        "      for weights in layer.get_weights():\n",
        "        weights = model.get_weights()[model_index]\n",
        "        model_index = model_index + 1\n",
        "\n",
        "    # print('----------------')\n",
        "\n",
        "    # for layer in model.layers:\n",
        "    #   for weights in layer.get_weights():\n",
        "    #     print(len(weights))\n",
        "    # print('----------------')\n",
        "    \n",
        "    # intermediate_model.layers[5].set_weights(weights_list[0])\n",
        "    # print(len(model.layers))\n",
        "    # intermediate_model.layers[i].set_weights(weights)\n",
        "\n",
        "    # intermediate_model.summary()\n",
        "\n",
        "    # model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "    #           batch_size=batch_size, epochs=num_epochs,\n",
        "    #           verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "    # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "    # modelName = '/content/drive/MyDrive/Moire/checkPoint/final-tm' + str(time.time()).split('.')[0] + '-sp' + superpoch + '-ds' + dataSetNumber + '-weights.h5'\n",
        "    # model.save(modelName)\n",
        "    \n",
        "    return intermediate_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27zETVwPEMCf"
      },
      "source": [
        "# from keras.models import Model\n",
        "\n",
        "# model = intermediateMoire(\"001\", '/content/drive/MyDrive/Moire/checkPoint/mid-sp005-ds002-ep016-ls0.00455-ac1.00-weights.h5')\n",
        "\n",
        "# model.summary()\n",
        "# X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(\"001\", 'test')\n",
        "# model_out = model.predict([X_LL, X_LH, X_HL, X_HH])\n",
        "\n",
        "\n",
        "# print(model_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ESg5hvZl3u_"
      },
      "source": [
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "# model_shape = model_out.shape\n",
        "\n",
        "# reshaped_output = np.reshape(model_out, (model_shape[0], model_shape[3], model_shape[1], model_shape[2]))\n",
        "\n",
        "# print(reshaped_output.shape)\n",
        "# index = 0\n",
        "# # for image_batch in reshaped_output:\n",
        "# for image in reshaped_output[0]:\n",
        "#   # image_batch = np.reshape(reshaped_output, (model_shape[0], model_shape[3], model_shape[1], model_shape[2]))\n",
        "#   print(image.shape)\n",
        "\n",
        "#   largest = 0\n",
        "#   smallest = 100000\n",
        "\n",
        "#   for row in image:\n",
        "#     for i in row:\n",
        "#       if i > largest:\n",
        "#         largest = i\n",
        "#       if i < smallest:\n",
        "#         smallest = i\n",
        "\n",
        "#   value_range = largest - smallest\n",
        "#   scale_value = 255 / value_range\n",
        "\n",
        "#   for i in range(len(image)):\n",
        "#     for j in range(len(image[i])):\n",
        "#       image[i][j] = scale_value * image[i][j]\n",
        "#   print('largest: ' + str(largest))\n",
        "#   print('smallest: ' + str(smallest))\n",
        "#   im = Image.fromarray(image)\n",
        "#   index = index + 1\n",
        "\n",
        "#   if im.mode != 'RGB':\n",
        "#     im = im.convert('RGB')\n",
        "\n",
        "#   im.save('/content/drive/MyDrive/Moire/intermediate/test/negative/001/' + str(index) + \".jpg\")\n",
        "\n",
        "# print(index)\n",
        "# print(np.reshape(model_out, (model_shape[0], model_shape[3], model_shape[1], model_shape[2])).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnwQH5eYqa_O"
      },
      "source": [
        "# #constants\n",
        "# # width = 500#384 #change dimensions according to the input image in the training\n",
        "# # height = 375#512 #change dimensions according to the input image in the training\n",
        "# # depth = 1\n",
        "# # num_classes = 2\n",
        "\n",
        "# def continueTraining(weightsFile, X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, num_epochs):\n",
        "#     weights_file = (weightsFile)\n",
        "\n",
        "#     # X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(positiveImagePath, negativeImagePath)\n",
        "    \n",
        "    \n",
        "\n",
        "#     batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "#     print(\"SHAPE\")\n",
        "#     print(X_LL_train.shape);\n",
        "#     num_train, height, width, depth = X_LL_train.shape\n",
        "#     num_classes = len(np.unique(Y_train))\n",
        "#     Y_train = np_utils.to_categorical(Y_train, num_classes) # One-hot encode the labels\n",
        "#     print(Y_train);\n",
        "#     # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "\n",
        "#     CNN_model = createModel(height, width, depth, num_classes)\n",
        "#     CNN_model.load_weights(weights_file)\n",
        "\n",
        "#     checkPointFolder = 'content/drive/MyDrive/Moire/checkPoint'\n",
        "#     checkpoint_name = checkPointFolder + '/Weights-retrained-002--{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "#     checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "#     callbacks_list = [checkpoint]\n",
        "    \n",
        "#     if not os.path.exists(checkPointFolder):\n",
        "#         os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "#     # model = createModel(height, width, depth, num_classes)\n",
        "    \n",
        "#     CNN_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "#                   optimizer='adam', # using the Adam optimiser\n",
        "#                   metrics=['accuracy']) # reporting the accuracy\n",
        "\n",
        "#     CNN_model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "#               batch_size=batch_size, epochs=num_epochs,\n",
        "#               verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "#     # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "#     CNN_model.save('content/drive/MyDrive/Moire/checkPoint/retrained-002-moirePattern3CNN_.h5')\n",
        "    \n",
        "#     return model\n",
        "#     # evaluate(CNN_model,X_LL,X_LH,X_HL,X_HH, Y)\n",
        "# import time\n",
        "# str(time.time()).split('.')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fyxBfYY4i7U"
      },
      "source": [
        "# continueTraining('content/drive/MyDrive/Moire/checkPoint/Weights-028--0.06866.hdf5', X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlSUPMxf6tFa"
      },
      "source": [
        "# !ls content/drive/MyDrive/Moire/checkPoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYl1Npdb623a"
      },
      "source": [
        "# mainTest('content/drive/MyDrive/Moire/checkPoint/retrained-002-moirePattern3CNN_.h5', '/content/drive/MyDrive/Moire/testDataPositive', '/content/drive/MyDrive/Moire/testDataNegative')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}