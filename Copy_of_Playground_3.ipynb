{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of Playground.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianhumphreys/Moire-Detector/blob/main/Copy_of_Playground_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDFp5O-Bqa_H"
      },
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To3GCs0JndZT",
        "outputId": "7f7c1727-797e-4d7a-90d7-497fa0e2d8cb"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 12 21:27:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5iT4R4PnYT6",
        "outputId": "71eae684-bf08-4ca7-c03f-e7e31691081b"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "muinrEgNqa_J"
      },
      "source": [
        "## Test 2D Wavelet Decomposition function\n",
        "This function(fwdHaarDWT2D) computes the 2D Wavelet Transform in the image. All the input images are passed through a Haar Wavelet Decomposition module, to get the LL, LH, HL and HHH component of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWlOXh6fq3xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e923e591-4014-4f8f-ddde-9a96ab5547f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r96WGlWEqjL1",
        "outputId": "f30eae76-0b02-40be-937a-19a77f4f79bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /content/drive/MyDrive/Moire/train/negative/001/"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00830912ac5c4610a8873a2c589d344f_180_FLIP_HH.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_180_FLIP_HL.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_180_FLIP_LH.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_180_FLIP_LL.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_180_HH.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_180_HL.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_180_LH.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_180_LL.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_HH.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_HL.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_LH.tiff\n",
            "00830912ac5c4610a8873a2c589d344f_LL.tiff\n",
            "07_ordinary_extraordinary_180_HH.tiff\n",
            "07_ordinary_extraordinary_180_HL.tiff\n",
            "07_ordinary_extraordinary_180_LH.tiff\n",
            "07_ordinary_extraordinary_180_LL.tiff\n",
            "07_ordinary_extraordinary_HH.tiff\n",
            "07_ordinary_extraordinary_HL.tiff\n",
            "07_ordinary_extraordinary_LH.tiff\n",
            "07_ordinary_extraordinary_LL.tiff\n",
            "14_letterbox1024_180_FLIP_HH.tiff\n",
            "14_letterbox1024_180_FLIP_HL.tiff\n",
            "14_letterbox1024_180_FLIP_LH.tiff\n",
            "14_letterbox1024_180_FLIP_LL.tiff\n",
            "14_letterbox1024_180_HH.tiff\n",
            "14_letterbox1024_180_HL.tiff\n",
            "14_letterbox1024_180_LH.tiff\n",
            "14_letterbox1024_180_LL.tiff\n",
            "14_letterbox1024_HH.tiff\n",
            "14_letterbox1024_HL.tiff\n",
            "14_letterbox1024_LH.tiff\n",
            "14_letterbox1024_LL.tiff\n",
            "191005-224-mer-55a66859be0c8_180_FLIP_HH.tiff\n",
            "191005-224-mer-55a66859be0c8_180_FLIP_HL.tiff\n",
            "191005-224-mer-55a66859be0c8_180_FLIP_LH.tiff\n",
            "191005-224-mer-55a66859be0c8_180_FLIP_LL.tiff\n",
            "191005-224-mer-55a66859be0c8_180_HH.tiff\n",
            "191005-224-mer-55a66859be0c8_180_HL.tiff\n",
            "191005-224-mer-55a66859be0c8_180_LH.tiff\n",
            "191005-224-mer-55a66859be0c8_180_LL.tiff\n",
            "191005-224-mer-55a66859be0c8_HH.tiff\n",
            "191005-224-mer-55a66859be0c8_HL.tiff\n",
            "191005-224-mer-55a66859be0c8_LH.tiff\n",
            "191005-224-mer-55a66859be0c8_LL.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_FLIP_HH.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_FLIP_HL.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_FLIP_LH.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_FLIP_LL.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_HH.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_HL.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_LH.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_180_LL.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_HH.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_HL.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_LH.tiff\n",
            "2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5_LL.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_FLIP_HH.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_FLIP_HL.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_FLIP_LH.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_FLIP_LL.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_HH.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_HL.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_LH.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_180_LL.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_HH.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_HL.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_LH.tiff\n",
            "2014-mercedes-benz-e350-4matic-wagon_LL.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_FLIP_HH.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_FLIP_HL.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_FLIP_LH.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_FLIP_LL.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_HH.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_HL.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_LH.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_180_LL.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_HH.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_HL.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_LH.tiff\n",
            "2018-BMW-i3-front-three-quarter-01_LL.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_FLIP_HH.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_FLIP_HL.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_FLIP_LH.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_FLIP_LL.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_HH.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_HL.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_LH.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_180_LL.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_HH.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_HL.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_LH.tiff\n",
            "2018-ford-taurus-sho-release-date-640x480_LL.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_FLIP_HH.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_FLIP_HL.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_FLIP_LH.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_FLIP_LL.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_HH.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_HL.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_LH.tiff\n",
            "2018-kia-stinger-gt-first-drive_180_LL.tiff\n",
            "2018-kia-stinger-gt-first-drive_HH.tiff\n",
            "2018-kia-stinger-gt-first-drive_HL.tiff\n",
            "2018-kia-stinger-gt-first-drive_LH.tiff\n",
            "2018-kia-stinger-gt-first-drive_LL.tiff\n",
            "22_letterbox1024_180_FLIP_HH.tiff\n",
            "22_letterbox1024_180_FLIP_HL.tiff\n",
            "22_letterbox1024_180_FLIP_LH.tiff\n",
            "22_letterbox1024_180_FLIP_LL.tiff\n",
            "22_letterbox1024_180_HH.tiff\n",
            "22_letterbox1024_180_HL.tiff\n",
            "22_letterbox1024_180_LH.tiff\n",
            "22_letterbox1024_180_LL.tiff\n",
            "22_letterbox1024_HH.tiff\n",
            "22_letterbox1024_HL.tiff\n",
            "22_letterbox1024_LH.tiff\n",
            "22_letterbox1024_LL.tiff\n",
            "3500_180_FLIP_HH.tiff\n",
            "3500_180_FLIP_HL.tiff\n",
            "3500_180_FLIP_LH.tiff\n",
            "3500_180_FLIP_LL.tiff\n",
            "3500_180_HH.tiff\n",
            "3500_180_HL.tiff\n",
            "3500_180_LH.tiff\n",
            "3500_180_LL.tiff\n",
            "3500_HH.tiff\n",
            "3500_HL.tiff\n",
            "3500_LH.tiff\n",
            "3500_LL.tiff\n",
            "37_letterbox1024_180_FLIP_HH.tiff\n",
            "37_letterbox1024_180_FLIP_HL.tiff\n",
            "37_letterbox1024_180_FLIP_LH.tiff\n",
            "37_letterbox1024_180_FLIP_LL.tiff\n",
            "37_letterbox1024_180_HH.tiff\n",
            "37_letterbox1024_180_HL.tiff\n",
            "37_letterbox1024_180_LH.tiff\n",
            "37_letterbox1024_180_LL.tiff\n",
            "37_letterbox1024_HH.tiff\n",
            "37_letterbox1024_HL.tiff\n",
            "37_letterbox1024_LH.tiff\n",
            "37_letterbox1024_LL.tiff\n",
            "40001257471_f0bcf1abf0_c_180_FLIP_HH.tiff\n",
            "40001257471_f0bcf1abf0_c_180_FLIP_HL.tiff\n",
            "40001257471_f0bcf1abf0_c_180_FLIP_LH.tiff\n",
            "40001257471_f0bcf1abf0_c_180_FLIP_LL.tiff\n",
            "40001257471_f0bcf1abf0_c_180_HH.tiff\n",
            "40001257471_f0bcf1abf0_c_180_HL.tiff\n",
            "40001257471_f0bcf1abf0_c_180_LH.tiff\n",
            "40001257471_f0bcf1abf0_c_180_LL.tiff\n",
            "40001257471_f0bcf1abf0_c_HH.tiff\n",
            "40001257471_f0bcf1abf0_c_HL.tiff\n",
            "40001257471_f0bcf1abf0_c_LH.tiff\n",
            "40001257471_f0bcf1abf0_c_LL.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_FLIP_HH.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_FLIP_HL.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_FLIP_LH.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_FLIP_LL.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_HH.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_HL.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_LH.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_180_LL.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_HH.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_HL.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_LH.tiff\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773_LL.tiff\n",
            "50368478887_cae688182a_k_180_FLIP_HH.tiff\n",
            "50368478887_cae688182a_k_180_FLIP_HL.tiff\n",
            "50368478887_cae688182a_k_180_FLIP_LH.tiff\n",
            "50368478887_cae688182a_k_180_FLIP_LL.tiff\n",
            "50368478887_cae688182a_k_180_HH.tiff\n",
            "50368478887_cae688182a_k_180_HL.tiff\n",
            "50368478887_cae688182a_k_180_LH.tiff\n",
            "50368478887_cae688182a_k_180_LL.tiff\n",
            "50368478887_cae688182a_k_HH.tiff\n",
            "50368478887_cae688182a_k_HL.tiff\n",
            "50368478887_cae688182a_k_LH.tiff\n",
            "50368478887_cae688182a_k_LL.tiff\n",
            "A1913104_large-3482x2322_180_FLIP_HH.tiff\n",
            "A1913104_large-3482x2322_180_FLIP_HL.tiff\n",
            "A1913104_large-3482x2322_180_FLIP_LH.tiff\n",
            "A1913104_large-3482x2322_180_FLIP_LL.tiff\n",
            "A1913104_large-3482x2322_180_HH.tiff\n",
            "A1913104_large-3482x2322_180_HL.tiff\n",
            "A1913104_large-3482x2322_180_LH.tiff\n",
            "A1913104_large-3482x2322_180_LL.tiff\n",
            "A1913104_large-3482x2322_HH.tiff\n",
            "A1913104_large-3482x2322_HL.tiff\n",
            "A1913104_large-3482x2322_LH.tiff\n",
            "A1913104_large-3482x2322_LL.tiff\n",
            "AAKYIDz_180_FLIP_HH.tiff\n",
            "AAKYIDz_180_FLIP_HL.tiff\n",
            "AAKYIDz_180_FLIP_LH.tiff\n",
            "AAKYIDz_180_FLIP_LL.tiff\n",
            "AAKYIDz_180_HH.tiff\n",
            "AAKYIDz_180_HL.tiff\n",
            "AAKYIDz_180_LH.tiff\n",
            "AAKYIDz_180_LL.tiff\n",
            "AAKYIDz_HH.tiff\n",
            "AAKYIDz_HL.tiff\n",
            "AAKYIDz_LH.tiff\n",
            "AAKYIDz_LL.tiff\n",
            "abarth-124-14-1024x576_180_FLIP_HH.tiff\n",
            "abarth-124-14-1024x576_180_FLIP_HL.tiff\n",
            "abarth-124-14-1024x576_180_FLIP_LH.tiff\n",
            "abarth-124-14-1024x576_180_FLIP_LL.tiff\n",
            "abarth-124-14-1024x576_180_HH.tiff\n",
            "abarth-124-14-1024x576_180_HL.tiff\n",
            "abarth-124-14-1024x576_180_LH.tiff\n",
            "abarth-124-14-1024x576_180_LL.tiff\n",
            "abarth-124-14-1024x576_HH.tiff\n",
            "abarth-124-14-1024x576_HL.tiff\n",
            "abarth-124-14-1024x576_LH.tiff\n",
            "abarth-124-14-1024x576_LL.tiff\n",
            "blue-bmw-moving_180_FLIP_HH.tiff\n",
            "blue-bmw-moving_180_FLIP_HL.tiff\n",
            "blue-bmw-moving_180_FLIP_LH.tiff\n",
            "blue-bmw-moving_180_FLIP_LL.tiff\n",
            "blue-bmw-moving_180_HH.tiff\n",
            "blue-bmw-moving_180_HL.tiff\n",
            "blue-bmw-moving_180_LH.tiff\n",
            "blue-bmw-moving_180_LL.tiff\n",
            "blue-bmw-moving_HH.tiff\n",
            "blue-bmw-moving_HL.tiff\n",
            "blue-bmw-moving_LH.tiff\n",
            "blue-bmw-moving_LL.tiff\n",
            "bmw-noice_180_FLIP_HH.tiff\n",
            "bmw-noice_180_FLIP_HL.tiff\n",
            "bmw-noice_180_FLIP_LH.tiff\n",
            "bmw-noice_180_FLIP_LL.tiff\n",
            "bmw-noice_180_HH.tiff\n",
            "bmw-noice_180_HL.tiff\n",
            "bmw-noice_180_LH.tiff\n",
            "bmw-noice_180_LL.tiff\n",
            "bmw-noice_HH.tiff\n",
            "bmw-noice_HL.tiff\n",
            "bmw-noice_LH.tiff\n",
            "bmw-noice_LL.tiff\n",
            "brown-old-car_180_FLIP_HH.tiff\n",
            "brown-old-car_180_FLIP_HL.tiff\n",
            "brown-old-car_180_FLIP_LH.tiff\n",
            "brown-old-car_180_FLIP_LL.tiff\n",
            "brown-old-car_180_HH.tiff\n",
            "brown-old-car_180_HL.tiff\n",
            "brown-old-car_180_LH.tiff\n",
            "brown-old-car_180_LL.tiff\n",
            "brown-old-car_HH.tiff\n",
            "brown-old-car_HL.tiff\n",
            "brown-old-car_LH.tiff\n",
            "brown-old-car_LL.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_FLIP_HH.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_FLIP_HL.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_FLIP_LH.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_FLIP_LL.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_HH.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_HL.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_LH.tiff\n",
            "classic-renault-safety-advances-in-motoring_180_LL.tiff\n",
            "classic-renault-safety-advances-in-motoring_HH.tiff\n",
            "classic-renault-safety-advances-in-motoring_HL.tiff\n",
            "classic-renault-safety-advances-in-motoring_LH.tiff\n",
            "classic-renault-safety-advances-in-motoring_LL.tiff\n",
            "dims_180_FLIP_HH.tiff\n",
            "dims_180_FLIP_HL.tiff\n",
            "dims_180_FLIP_LH.tiff\n",
            "dims_180_FLIP_LL.tiff\n",
            "dims_180_HH.tiff\n",
            "dims_180_HL.tiff\n",
            "dims_180_LH.tiff\n",
            "dims_180_LL.tiff\n",
            "dims_HH.tiff\n",
            "dims_HL.tiff\n",
            "dims_LH.tiff\n",
            "dims_LL.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_FLIP_HH.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_FLIP_HL.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_FLIP_LH.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_FLIP_LL.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_HH.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_HL.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_LH.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_180_LL.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_HH.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_HL.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_LH.tiff\n",
            "DiqOb9AuQ-mw9fJ3TULvQQ_LL.tiff\n",
            "g63-amg-1024x453_180_FLIP_HH.tiff\n",
            "g63-amg-1024x453_180_FLIP_HL.tiff\n",
            "g63-amg-1024x453_180_FLIP_LH.tiff\n",
            "g63-amg-1024x453_180_FLIP_LL.tiff\n",
            "g63-amg-1024x453_180_HH.tiff\n",
            "g63-amg-1024x453_180_HL.tiff\n",
            "g63-amg-1024x453_180_LH.tiff\n",
            "g63-amg-1024x453_180_LL.tiff\n",
            "g63-amg-1024x453_HH.tiff\n",
            "g63-amg-1024x453_HL.tiff\n",
            "g63-amg-1024x453_LH.tiff\n",
            "g63-amg-1024x453_LL.tiff\n",
            "green-car_180_FLIP_HH.tiff\n",
            "green-car_180_FLIP_HL.tiff\n",
            "green-car_180_FLIP_LH.tiff\n",
            "green-car_180_FLIP_LL.tiff\n",
            "green-car_180_HH.tiff\n",
            "green-car_180_HL.tiff\n",
            "green-car_180_LH.tiff\n",
            "green-car_180_LL.tiff\n",
            "green-car_HH.tiff\n",
            "green-car_HL.tiff\n",
            "green-car_LH.tiff\n",
            "green-car_LL.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_FLIP_HH.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_FLIP_HL.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_FLIP_LH.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_FLIP_LL.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_HH.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_HL.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_LH.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_180_LL.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_HH.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_HL.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_LH.tiff\n",
            "HBcXPzpDSxCIWPRMWey2rg_LL.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_FLIP_HH.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_FLIP_HL.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_FLIP_LH.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_FLIP_LL.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_HH.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_HL.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_LH.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_180_LL.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_HH.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_HL.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_LH.tiff\n",
            "hyundai-sonata-hybrid-2020-01-exterior--grey--profile_LL.tiff\n",
            "image-red-car-small_180_FLIP_HH.tiff\n",
            "image-red-car-small_180_FLIP_HL.tiff\n",
            "image-red-car-small_180_FLIP_LH.tiff\n",
            "image-red-car-small_180_FLIP_LL.tiff\n",
            "image-red-car-small_180_HH.tiff\n",
            "image-red-car-small_180_HL.tiff\n",
            "image-red-car-small_180_LH.tiff\n",
            "image-red-car-small_180_LL.tiff\n",
            "image-red-car-small_HH.tiff\n",
            "image-red-car-small_HL.tiff\n",
            "image-red-car-small_LH.tiff\n",
            "image-red-car-small_LL.tiff\n",
            "images_180_FLIP_HH.tiff\n",
            "images_180_FLIP_HL.tiff\n",
            "images_180_FLIP_LH.tiff\n",
            "images_180_FLIP_LL.tiff\n",
            "images_180_HH.tiff\n",
            "images_180_HL.tiff\n",
            "images_180_LH.tiff\n",
            "images_180_LL.tiff\n",
            "images_58459_180_FLIP_HH.tiff\n",
            "images_58459_180_FLIP_HL.tiff\n",
            "images_58459_180_FLIP_LH.tiff\n",
            "images_58459_180_FLIP_LL.tiff\n",
            "images_58459_180_HH.tiff\n",
            "images_58459_180_HL.tiff\n",
            "images_58459_180_LH.tiff\n",
            "images_58459_180_LL.tiff\n",
            "images_58459_HH.tiff\n",
            "images_58459_HL.tiff\n",
            "images_58459_LH.tiff\n",
            "images_58459_LL.tiff\n",
            "images_HH.tiff\n",
            "images_HL.tiff\n",
            "images_LH.tiff\n",
            "images_LL.tiff\n",
            "images-red-beater_180_FLIP_HH.tiff\n",
            "images-red-beater_180_FLIP_HL.tiff\n",
            "images-red-beater_180_FLIP_LH.tiff\n",
            "images-red-beater_180_FLIP_LL.tiff\n",
            "images-red-beater_180_HH.tiff\n",
            "images-red-beater_180_HL.tiff\n",
            "images-red-beater_180_LH.tiff\n",
            "images-red-beater_180_LL.tiff\n",
            "images-red-beater_HH.tiff\n",
            "images-red-beater_HL.tiff\n",
            "images-red-beater_LH.tiff\n",
            "images-red-beater_LL.tiff\n",
            "ImpalaSS_111_180_FLIP_HH.tiff\n",
            "ImpalaSS_111_180_FLIP_HL.tiff\n",
            "ImpalaSS_111_180_FLIP_LH.tiff\n",
            "ImpalaSS_111_180_FLIP_LL.tiff\n",
            "ImpalaSS_111_180_HH.tiff\n",
            "ImpalaSS_111_180_HL.tiff\n",
            "ImpalaSS_111_180_LH.tiff\n",
            "ImpalaSS_111_180_LL.tiff\n",
            "ImpalaSS_111_HH.tiff\n",
            "ImpalaSS_111_HL.tiff\n",
            "ImpalaSS_111_LH.tiff\n",
            "ImpalaSS_111_LL.tiff\n",
            "jaguar-xj-30-awd_180_FLIP_HH.tiff\n",
            "jaguar-xj-30-awd_180_FLIP_HL.tiff\n",
            "jaguar-xj-30-awd_180_FLIP_LH.tiff\n",
            "jaguar-xj-30-awd_180_FLIP_LL.tiff\n",
            "jaguar-xj-30-awd_180_HH.tiff\n",
            "jaguar-xj-30-awd_180_HL.tiff\n",
            "jaguar-xj-30-awd_180_LH.tiff\n",
            "jaguar-xj-30-awd_180_LL.tiff\n",
            "jaguar-xj-30-awd_HH.tiff\n",
            "jaguar-xj-30-awd_HL.tiff\n",
            "jaguar-xj-30-awd_LH.tiff\n",
            "jaguar-xj-30-awd_LL.tiff\n",
            "kfchxatevaemoonwqaru_180_FLIP_HH.tiff\n",
            "kfchxatevaemoonwqaru_180_FLIP_HL.tiff\n",
            "kfchxatevaemoonwqaru_180_FLIP_LH.tiff\n",
            "kfchxatevaemoonwqaru_180_FLIP_LL.tiff\n",
            "kfchxatevaemoonwqaru_180_HH.tiff\n",
            "kfchxatevaemoonwqaru_180_HL.tiff\n",
            "kfchxatevaemoonwqaru_180_LH.tiff\n",
            "kfchxatevaemoonwqaru_180_LL.tiff\n",
            "kfchxatevaemoonwqaru_HH.tiff\n",
            "kfchxatevaemoonwqaru_HL.tiff\n",
            "kfchxatevaemoonwqaru_LH.tiff\n",
            "kfchxatevaemoonwqaru_LL.tiff\n",
            "KME0DiZv_180_FLIP_HH.tiff\n",
            "KME0DiZv_180_FLIP_HL.tiff\n",
            "KME0DiZv_180_FLIP_LH.tiff\n",
            "KME0DiZv_180_FLIP_LL.tiff\n",
            "KME0DiZv_180_HH.tiff\n",
            "KME0DiZv_180_HL.tiff\n",
            "KME0DiZv_180_LH.tiff\n",
            "KME0DiZv_180_LL.tiff\n",
            "KME0DiZv_HH.tiff\n",
            "KME0DiZv_HL.tiff\n",
            "KME0DiZv_LH.tiff\n",
            "KME0DiZv_LL.tiff\n",
            "lots-of-road_180_FLIP_HH.tiff\n",
            "lots-of-road_180_FLIP_HL.tiff\n",
            "lots-of-road_180_FLIP_LH.tiff\n",
            "lots-of-road_180_FLIP_LL.tiff\n",
            "lots-of-road_180_HH.tiff\n",
            "lots-of-road_180_HL.tiff\n",
            "lots-of-road_180_LH.tiff\n",
            "lots-of-road_180_LL.tiff\n",
            "lots-of-road_HH.tiff\n",
            "lots-of-road_HL.tiff\n",
            "lots-of-road_LH.tiff\n",
            "lots-of-road_LL.tiff\n",
            "lotus-carlton_180_FLIP_HH.tiff\n",
            "lotus-carlton_180_FLIP_HL.tiff\n",
            "lotus-carlton_180_FLIP_LH.tiff\n",
            "lotus-carlton_180_FLIP_LL.tiff\n",
            "lotus-carlton_180_HH.tiff\n",
            "lotus-carlton_180_HL.tiff\n",
            "lotus-carlton_180_LH.tiff\n",
            "lotus-carlton_180_LL.tiff\n",
            "lotus-carlton_HH.tiff\n",
            "lotus-carlton_HL.tiff\n",
            "lotus-carlton_LH.tiff\n",
            "lotus-carlton_LL.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_FLIP_HH.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_FLIP_HL.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_FLIP_LH.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_FLIP_LL.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_HH.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_HL.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_LH.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_180_LL.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_HH.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_HL.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_LH.tiff\n",
            "main-qimg-6e734378c6521d3d55333ec2b969bcc7_LL.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_FLIP_HH.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_FLIP_HL.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_FLIP_LH.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_FLIP_LL.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_HH.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_HL.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_LH.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_180_LL.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_HH.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_HL.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_LH.tiff\n",
            "main-qimg-a69067c77a6f3dc52f2e1360e5196ddd_LL.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_FLIP_HH.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_FLIP_HL.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_FLIP_LH.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_FLIP_LL.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_HH.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_HL.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_LH.tiff\n",
            "Mazda-6_MPS-2006-1600-01_180_LL.tiff\n",
            "Mazda-6_MPS-2006-1600-01_HH.tiff\n",
            "Mazda-6_MPS-2006-1600-01_HL.tiff\n",
            "Mazda-6_MPS-2006-1600-01_LH.tiff\n",
            "Mazda-6_MPS-2006-1600-01_LL.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_FLIP_HH.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_FLIP_HL.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_FLIP_LH.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_FLIP_LL.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_HH.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_HL.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_LH.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_180_LL.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_HH.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_HL.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_LH.tiff\n",
            "nissan_stagea_autech_260rs-56bc946faf390_LL.tiff\n",
            "Ob7t24y_180_FLIP_HH.tiff\n",
            "Ob7t24y_180_FLIP_HL.tiff\n",
            "Ob7t24y_180_FLIP_LH.tiff\n",
            "Ob7t24y_180_FLIP_LL.tiff\n",
            "Ob7t24y_180_HH.tiff\n",
            "Ob7t24y_180_HL.tiff\n",
            "Ob7t24y_180_LH.tiff\n",
            "Ob7t24y_180_LL.tiff\n",
            "Ob7t24y_HH.tiff\n",
            "Ob7t24y_HL.tiff\n",
            "Ob7t24y_LH.tiff\n",
            "Ob7t24y_LL.tiff\n",
            "Ordinary_Lead_180_FLIP_HH.tiff\n",
            "Ordinary_Lead_180_FLIP_HL.tiff\n",
            "Ordinary_Lead_180_FLIP_LH.tiff\n",
            "Ordinary_Lead_180_FLIP_LL.tiff\n",
            "Ordinary_Lead_180_HH.tiff\n",
            "Ordinary_Lead_180_HL.tiff\n",
            "Ordinary_Lead_180_LH.tiff\n",
            "Ordinary_Lead_180_LL.tiff\n",
            "Ordinary_Lead_HH.tiff\n",
            "Ordinary_Lead_HL.tiff\n",
            "Ordinary_Lead_LH.tiff\n",
            "Ordinary_Lead_LL.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_FLIP_HH.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_FLIP_HL.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_FLIP_LH.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_FLIP_LL.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_HH.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_HL.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_LH.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_180_LL.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_HH.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_HL.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_LH.tiff\n",
            "P90404818_highRes_bmw-440i-coupe-3481x2322_LL.tiff\n",
            "SEI_85642568-640x360_180_FLIP_HH.tiff\n",
            "SEI_85642568-640x360_180_FLIP_HL.tiff\n",
            "SEI_85642568-640x360_180_FLIP_LH.tiff\n",
            "SEI_85642568-640x360_180_FLIP_LL.tiff\n",
            "SEI_85642568-640x360_180_HH.tiff\n",
            "SEI_85642568-640x360_180_HL.tiff\n",
            "SEI_85642568-640x360_180_LH.tiff\n",
            "SEI_85642568-640x360_180_LL.tiff\n",
            "SEI_85642568-640x360_HH.tiff\n",
            "SEI_85642568-640x360_HL.tiff\n",
            "SEI_85642568-640x360_LH.tiff\n",
            "SEI_85642568-640x360_LL.tiff\n",
            "vwgolfsccolumn_180_FLIP_HH.tiff\n",
            "vwgolfsccolumn_180_FLIP_HL.tiff\n",
            "vwgolfsccolumn_180_FLIP_LH.tiff\n",
            "vwgolfsccolumn_180_FLIP_LL.tiff\n",
            "vwgolfsccolumn_180_HH.tiff\n",
            "vwgolfsccolumn_180_HL.tiff\n",
            "vwgolfsccolumn_180_LH.tiff\n",
            "vwgolfsccolumn_180_LL.tiff\n",
            "vwgolfsccolumn_HH.tiff\n",
            "vwgolfsccolumn_HL.tiff\n",
            "vwgolfsccolumn_LH.tiff\n",
            "vwgolfsccolumn_LL.tiff\n",
            "vw-standard-puetre_180_FLIP_HH.tiff\n",
            "vw-standard-puetre_180_FLIP_HL.tiff\n",
            "vw-standard-puetre_180_FLIP_LH.tiff\n",
            "vw-standard-puetre_180_FLIP_LL.tiff\n",
            "vw-standard-puetre_180_HH.tiff\n",
            "vw-standard-puetre_180_HL.tiff\n",
            "vw-standard-puetre_180_LH.tiff\n",
            "vw-standard-puetre_180_LL.tiff\n",
            "vw-standard-puetre_HH.tiff\n",
            "vw-standard-puetre_HL.tiff\n",
            "vw-standard-puetre_LH.tiff\n",
            "vw-standard-puetre_LL.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_FLIP_HH.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_FLIP_HL.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_FLIP_LH.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_FLIP_LL.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_HH.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_HL.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_LH.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_180_LL.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_HH.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_HL.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_LH.tiff\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41_LL.tiff\n",
            "yellow-ew_180_FLIP_HH.tiff\n",
            "yellow-ew_180_FLIP_HL.tiff\n",
            "yellow-ew_180_FLIP_LH.tiff\n",
            "yellow-ew_180_FLIP_LL.tiff\n",
            "yellow-ew_180_HH.tiff\n",
            "yellow-ew_180_HL.tiff\n",
            "yellow-ew_180_LH.tiff\n",
            "yellow-ew_180_LL.tiff\n",
            "yellow-ew_HH.tiff\n",
            "yellow-ew_HL.tiff\n",
            "yellow-ew_LH.tiff\n",
            "yellow-ew_LL.tiff\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDw39lK9kAe0"
      },
      "source": [
        "# !ls /content/drive/MyDrive/Moire/trainDataNegative\n",
        "# !ls /content/drive/MyDrive/Moire/train/negative/001\n",
        "# !mv -v /content/drive/MyDrive/Moire/trainDataNegative/ '/content/drive/MyDrive/Moire/train/negative/001'\n",
        "# !ls '/content/drive/MyDrive/Moire/train/negative/001/trainDataNegative'\n",
        "# !mv -v '/content/drive/MyDrive/Moire/train/negative/001/trainDataNegative/*.tiff' '/content/drive/MyDrive/Moire/train/negative/001'\n",
        "# import os\n",
        "\n",
        "# fromDir = '/content/drive/MyDrive/Moire/notNormalizedPositiveImages/'\n",
        "# toDir = \"/content/drive/MyDrive/Moire/unnormalized/positive/002/\"\n",
        "\n",
        "# # !ls /content/drive/MyDrive/Moire/testDataNegative/\n",
        "\n",
        "# for filename in os.listdir(fromDir):\n",
        "#   os.rename(fromDir + filename, toDir + filename)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA7CMKEhro9d",
        "outputId": "9e1490a7-fa0d-4c4c-da67-8ad86ff0a31a"
      },
      "source": [
        "# import os\n",
        "# os.chdir(\"/content/drive/\")\n",
        "# !ls\n",
        "\n",
        "# os.chdir(\"../..\")\n",
        "# !ls\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyDrive\n",
            "bin\t datalab  home\t lib64\topt   run   sys\t\t       tools\n",
            "boot\t dev\t  lib\t media\tproc  sbin  tensorflow-1.15.2  usr\n",
            "content  etc\t  lib32  mnt\troot  srv   tmp\t\t       var\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsTZ_TLIv3TK",
        "outputId": "8f63f642-9285-45da-fa4d-230481eaeff2"
      },
      "source": [
        "!ls /content/drive/MyDrive/Moire\n",
        "!pip install pyheif whatimage\n",
        "# !pip show wand"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "augmentedTrainedNegative     notNormalizedPositiveImages  testDataNegative\n",
            "augmentedTrainedPositive     preaugmented\t\t  testDataPositive\n",
            "checkPoint\t\t     preaugmentedNegativeImages   trainDataNegative\n",
            "notNormalizedNegativeImages  preaugmentedPositiveImages   trainDataPositive\n",
            "Collecting pyheif\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/fc/8d4714687b351f098426832dedf8fee73a87d44bfdb15168cdbd68973e4d/pyheif-0.5.1-cp37-cp37m-manylinux2014_x86_64.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 5.3MB/s \n",
            "\u001b[?25hCollecting whatimage\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/84/66f1cbaa0ea04cd4d5284bbbb64724d2cd17fb7f743e75ee46e98a953318/whatimage-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pyheif) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->pyheif) (2.20)\n",
            "Installing collected packages: pyheif, whatimage\n",
            "Successfully installed pyheif-0.5.1 whatimage-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmgaiBmhtDHX",
        "outputId": "99e09a3f-8bec-4f1a-bc07-7037979735b3"
      },
      "source": [
        "# !ls /content/drive/MyDrive/Moire/notNormalizedPositiveImages/\n",
        "# !ls /content/drive/MyDrive/Moire/notNormalizedNegativeImages/\n",
        "# !uname -m"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2005-Subaru-Forester-left-front.jpeg\n",
            "2013-mercedes-benz-c63-amg-edition-507-photo-499741-s-986x603.jpeg\n",
            "2014-mercedes-benz-e350-4matic-wagon.jpeg\n",
            "2018-ford-taurus-sho-release-date-640x480.jpeg\n",
            "44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773.jpeg\n",
            "50368478887_cae688182a_k.jpeg\n",
            "99_photos_toyota_hilux_2001_2.jpeg\n",
            "AAKYIDz.jpeg\n",
            "abarth-124-14-1024x576.jpeg\n",
            "classic-renault-safety-advances-in-motoring.jpeg\n",
            "dims.jpeg\n",
            "F.75.jpg\n",
            "g63-amg-1024x453.jpeg\n",
            "green-car.jpeg\n",
            "HBcXPzpDSxCIWPRMWey2rg.jpeg\n",
            "images_58459.jpeg\n",
            "jaguar-xj-30-awd.jpeg\n",
            "lots-of-road.jpeg\n",
            "lotus-carlton.jpeg\n",
            "Ob7t24y.jpeg\n",
            "vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41.jpeg\n",
            "x86_64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO9ckef9Wrs3"
      },
      "source": [
        "## Normalized Raw data to 1000x750 pixel images\n",
        "Images are cropped to fit a 3:4 aspect ratio and then resized to match a 1000x750 size. Moves photos **unnormalized** -> **preaugmented**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xaN5wepXCy3"
      },
      "source": [
        "# importing the module\n",
        "\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "\n",
        "import whatimage\n",
        "import pyheif\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def decodeImage(bytesIo):\n",
        "    with open(bytesIo, 'rb') as f:\n",
        "      data = f.read()\n",
        "      fmt = whatimage.identify_image(data)\n",
        "      if fmt in ['heic', 'avif']:\n",
        "        i = pyheif.read_heif(data)\n",
        "        pi = Image.frombytes(mode=i.mode, size=i.size, data=i.data)\n",
        "        pi.save(\"heic.jpg\", format=\"jpeg\")\n",
        "\n",
        "def read_heic(path: str):\n",
        "    img = Wimage(path)\n",
        "    img.format = 'jpg'\n",
        "    img.save(filename=\"heic.jpg\")\n",
        "    img.close()\n",
        "\n",
        "def openImage(fileName):\n",
        "  decodeImage(fileName)\n",
        "  return Image.open(\"heic.jpg\")\n",
        "\n",
        "def cropAndSave(image, fileName):\n",
        "    width = image.size[0]\n",
        "    height = image.size[1]\n",
        "\n",
        "    aspect = width / float(height)\n",
        "\n",
        "    if (height > width):\n",
        "        image = image.rotate(90, Image.NEAREST, expand=1)\n",
        "        width = image.size[0]\n",
        "        height = image.size[1]\n",
        "\n",
        "    ideal_width = 1000\n",
        "    ideal_height = 750\n",
        "\n",
        "    ideal_aspect = ideal_width / float(ideal_height)\n",
        "\n",
        "    if aspect > ideal_aspect:\n",
        "        # Then crop the left and right edges:\n",
        "        new_width = int(ideal_aspect * height)\n",
        "        offset = (width - new_width) / 2\n",
        "        resize = (offset, 0, width - offset, height)\n",
        "    else:\n",
        "        # ... crop the top and bottom:\n",
        "        new_height = int(width / ideal_aspect)\n",
        "        offset = (height - new_height) / 2\n",
        "        resize = (0, offset, width, height - offset)\n",
        "\n",
        "    thumb = image.crop(resize).resize((ideal_width, ideal_height), Image.ANTIALIAS)\n",
        "    thumb.save(fileName)\n",
        "\n",
        "\n",
        "def normalizeRawImages(dataSetNumber):\n",
        "\n",
        "  negativeFromDir = '/content/drive/MyDrive/Moire/unnormalized/negative/' + dataSetNumber + '/'\n",
        "  positiveFromDir = '/content/drive/MyDrive/Moire/unnormalized/positive/' + dataSetNumber + '/'\n",
        "  negativeToDir = '/content/drive/MyDrive/Moire/preaugmented/negative/' + dataSetNumber + '/'\n",
        "  positiveToDir = '/content/drive/MyDrive/Moire/preaugmented/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  if not os.path.exists(positiveToDir):\n",
        "      os.makedirs(positiveToDir)\n",
        "  if not os.path.exists(negativeToDir):\n",
        "      os.makedirs(negativeToDir)\n",
        "\n",
        "  positiveImageFiles = [f for f in listdir(positiveFromDir) if (isfile(join(positiveFromDir, f)))]\n",
        "  negativeImageFiles = [f for f in listdir(negativeFromDir) if (isfile(join(negativeFromDir, f)))]\n",
        "\n",
        "  # LLList = [l for l in positiveImageFiles if 'LLL' in l]\n",
        "  # print(LLList)\n",
        "\n",
        "  for f in positiveImageFiles:\n",
        "      print(join(positiveFromDir, f))\n",
        "      img = openImage(join(positiveFromDir, f))\n",
        "\n",
        "      rgb_im = img.convert(\"RGB\")\n",
        "      components = f.split('.')\n",
        "      newComponents = components[:len(components) - 1]\n",
        "      newComponents.append('jpg')\n",
        "      newFileName = '.'.join(newComponents)\n",
        "\n",
        "      print(newFileName)\n",
        "\n",
        "      cropAndSave(rgb_im, join(positiveToDir, newFileName))\n",
        "\n",
        "  for f in negativeImageFiles:\n",
        "      print(join(negativeFromDir, f))\n",
        "      img = Image.open(join(negativeFromDir, f))\n",
        "\n",
        "      rgb_im = img.convert(\"RGB\")\n",
        "      components = f.split('.')\n",
        "      newComponents = components[:len(components) - 1]\n",
        "      newComponents.append('jpg')\n",
        "      newFileName = '.'.join(newComponents)\n",
        "\n",
        "      print(newFileName)\n",
        "\n",
        "      cropAndSave(rgb_im, join(negativeToDir, newFileName))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9o2VLHoqyOo"
      },
      "source": [
        "#This function(fwdHaarDWT2D) computes the 2D Wavelet Transform in the image. All the input images are passed through a Haar Wavelet Decomposition module, to get the LL, LH, HL and HHH component of the image\n",
        "\n",
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "def splitFreqBands(img, levRows, levCols):\n",
        "    halfRow = int(levRows/2)\n",
        "    halfCol = int(levCols/2)\n",
        "    LL = img[0:halfRow, 0:halfCol]\n",
        "    LH = img[0:halfRow, halfCol:levCols]\n",
        "    HL = img[halfRow:levRows, 0:halfCol]\n",
        "    HH = img[halfRow:levRows, halfCol:levCols]\n",
        "    \n",
        "    return LL, LH, HL, HH\n",
        "    \n",
        "def haarDWT1D(data, length):\n",
        "    avg0 = 0.5;\n",
        "    avg1 = 0.5;\n",
        "    dif0 = 0.5;\n",
        "    dif1 = -0.5;\n",
        "    temp = np.empty_like(data)\n",
        "    temp = temp.astype(float)\n",
        "    h = int(length/2)\n",
        "    for i in range(h):\n",
        "        k = i*2\n",
        "        temp[i] = data[k] * avg0 + data[k + 1] * avg1;\n",
        "        temp[i + h] = data[k] * dif0 + data[k + 1] * dif1;\n",
        "    \n",
        "    data[:] = temp\n",
        "\n",
        "# computes the homography coefficients for PIL.Image.transform using point correspondences\n",
        "def fwdHaarDWT2D(img):\n",
        "    img = np.array(img)\n",
        "    levRows = img.shape[0];\n",
        "    levCols = img.shape[1];\n",
        "    img = img.astype(float)\n",
        "    for i in range(levRows):\n",
        "        row = img[i,:]\n",
        "        haarDWT1D(row, levCols)\n",
        "        img[i,:] = row\n",
        "    for j in range(levCols):\n",
        "        col = img[:,j]\n",
        "        haarDWT1D(col, levRows)\n",
        "        img[:,j] = col\n",
        "        \n",
        "    return splitFreqBands(img, levRows, levCols)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a63KHmZYqa_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "0ef15419-6d20-4b59-df72-30bff3a0b545"
      },
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "!ls /content/drive/MyDrive/Moire/\n",
        "img = Image.open('/content/drive/MyDrive/Moire/preaugmented/positive/001/IMG_2906.jpg').convert('L')\n",
        "img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "img.save('chl.jpg')\n",
        "LL, LH, HL, HH = fwdHaarDWT2D(img)\n",
        "fig, axes = plt.subplots(2, 2)\n",
        "fig.tight_layout()\n",
        "axes[0, 0].imshow(LL)\n",
        "axes[0, 1].imshow(LH)\n",
        "axes[1, 0].imshow(HL)\n",
        "axes[1, 1].imshow(HH)\n",
        "axes[0, 0].set_title(\"LL\")\n",
        "axes[0, 1].set_title(\"LH\")\n",
        "axes[1, 0].set_title(\"HL\")\n",
        "axes[1, 1].set_title(\"HH\")\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "augmented  checkPoint  preaugmented  test  train  unnormalized\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4611221ac85b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLIP_LEFT_RIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chl.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mLL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfwdHaarDWT2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fwdHaarDWT2D' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNnfNmoEqa_M"
      },
      "source": [
        "## Augment normalized data\n",
        "The training images need to be put in two folders. positiveImages and negativeImages. positiveImages are the images which are captured from the display devices and has the presence of stron or weak Moiré patterms in it.\n",
        "negativeImages are the ones without Moiré Patterns (i.e. the images which are not captured from the display devices).  Moves photos **preaugmented** -> **train/test** based on a split ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO8AKkFsqm5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d89e663-d922-4977-9722-03e1094d7fdc"
      },
      "source": [
        "import sys\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "\n",
        "#The training images need to be put in two folders. positiveImages and negativeImages. positiveImages are the images which are captured from the display devices and has the presence of stron or weak Moiré patterms in it. negativeImages are the ones without Moiré Patterns (i.e. the images which are not captured from the display devices)\n",
        "\n",
        "\n",
        "def augmentNormalizedData(dataSetNumber):\n",
        "\n",
        "  negativeFromDir = '/content/drive/MyDrive/Moire/preaugmented/negative/' + dataSetNumber + '/'\n",
        "  positiveFromDir = '/content/drive/MyDrive/Moire/preaugmented/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  negativeToTrainDir = '/content/drive/MyDrive/Moire/train/negative/' + dataSetNumber + '/'\n",
        "  positiveToTrainDir = '/content/drive/MyDrive/Moire/train/positive/' + dataSetNumber + '/'\n",
        "  negativeToTestDir = '/content/drive/MyDrive/Moire/negative/negative/' + dataSetNumber + '/'\n",
        "  positiveToTestDir = '/content/drive/MyDrive/Moire/negative/positive/' + dataSetNumber + '/'\n",
        "\n",
        "  if not os.path.exists(negativeToTrainDir):\n",
        "      os.makedirs(negativeToTrainDir)\n",
        "  if not os.path.exists(positiveToTrainDir):\n",
        "      os.makedirs(positiveToTrainDir)\n",
        "  if not os.path.exists(negativeToTestDir):\n",
        "      os.makedirs(negativeToTestDir)\n",
        "  if not os.path.exists(positiveToTestDir):\n",
        "      os.makedirs(positiveToTestDir)\n",
        "        \n",
        "  createTrainingData(positiveFromDir, negativeFromDir, positiveToTrainDir, negativeToTrainDir, positiveToTestDir, negativeToTestDir)\n",
        "\n",
        "    \n",
        "#The wavelet decomposed images are the transformed images representing the spatial and the frequency information of the image. These images are stored as 'tiff' in the disk, to preserve that information. Each image is transformed with 180 degrees rotation and as well flipped, as part of data augmentation.\n",
        "\n",
        "def transformImageAndSave(image, f, customStr, path):\n",
        "    cA, cH, cV, cD  = fwdHaarDWT2D(image);\n",
        "    \n",
        "    fileName = (os.path.splitext(f)[0])\n",
        "    fLL = (f.replace(fileName, fileName+'_' + customStr + 'LL')).replace('.jpg','.tiff')\n",
        "    fLH = (f.replace(fileName, fileName+'_' + customStr + 'LH')).replace('.jpg','.tiff')\n",
        "    fHL = (f.replace(fileName, fileName+'_' + customStr + 'HL')).replace('.jpg','.tiff')\n",
        "    fHH = (f.replace(fileName, fileName+'_' + customStr + 'HH')).replace('.jpg','.tiff')\n",
        "\n",
        "    cA = Image.fromarray(cA)\n",
        "    cH = Image.fromarray(cH)\n",
        "    cV = Image.fromarray(cV)\n",
        "    cD = Image.fromarray(cD)\n",
        "\n",
        "    cA.save(join(path, fLL))\n",
        "    cH.save(join(path, fLH))\n",
        "    cV.save(join(path, fHL))\n",
        "    cD.save(join(path, fHH))\n",
        "    \n",
        "    \n",
        "def augmentAndTrasformImage(f, mainFolder, trainFolder):\n",
        "    try:\n",
        "        print(join(mainFolder, f))\n",
        "        img = Image.open(join(mainFolder, f)) \n",
        "    except:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(f))\n",
        "        return None\n",
        "\n",
        "    imgGray = img.convert('L')\n",
        "    wdChk, htChk = imgGray.size\n",
        "    if htChk > wdChk:\n",
        "        imgGray = imgGray.rotate(-90, expand=1)\n",
        "        print('training image rotated')\n",
        "    transformImageAndSave(imgGray, f, '', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.ROTATE_180)\n",
        "    transformImageAndSave(imgGray, f, '180_', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    transformImageAndSave(imgGray, f, '180_FLIP_', trainFolder)\n",
        "    \n",
        "    return True\n",
        "    \n",
        "    \n",
        "def createTrainingData(positiveFromDir, negativeFromDir, positiveToTrainDir, negativeToTrainDir, positiveToTestDir, negativeToTestDir):\n",
        "\n",
        "    print('positive image path: ' + positiveFromDir)\n",
        "    print('negative image path: ' + negativeFromDir)\n",
        "    splitRatio = 0.9\n",
        "\n",
        "    # get image files by classes\n",
        "    positiveImageFiles = [f for f in listdir(positiveFromDir) if (isfile(join(positiveFromDir, f)))]\n",
        "    negativeImageFiles = [f for f in listdir(negativeFromDir) if (isfile(join(negativeFromDir, f)))]\n",
        "\n",
        "    positiveDataBorder = round(len(positiveImageFiles) * splitRatio)\n",
        "    negativeDataBorder = round(len(negativeImageFiles) * splitRatio)\n",
        "\n",
        "    positiveTrainFiles = positiveImageFiles[:positiveDataBorder]\n",
        "    positiveTestFiles = positiveImageFiles[positiveDataBorder:]\n",
        "    negativeTrainFiles = negativeImageFiles[:negativeDataBorder]\n",
        "    negativeTestFiles = negativeImageFiles[negativeDataBorder:]\n",
        "\n",
        "    print('positive train samples: ' + str(len(positiveTrainFiles)))\n",
        "    print('negative train samples: ' + str(len(positiveTestFiles)))\n",
        "    print('positive test samples: ' + str(len(negativeTrainFiles)))\n",
        "    print('negative test samples: ' + str(len(negativeTestFiles)))\n",
        "\n",
        "    Knegative = 0\n",
        "    Kpositive = 0\n",
        "\n",
        "    # create positive training images\n",
        "    for f in positiveTrainFiles:\n",
        "        ret = augmentAndTrasformImage(f, positiveFromDir, positiveToTrainDir)\n",
        "        if ret == None:\n",
        "            continue\n",
        "        Kpositive += 3\n",
        "\n",
        "    # create positive test images\n",
        "    for f in positiveTestFiles:\n",
        "        ret = augmentAndTrasformImage(f, positiveFromDir, negativeToTrainDir)\n",
        "        if ret == None:\n",
        "            continue\n",
        "        Kpositive += 3\n",
        "\n",
        "    # create negative training images\n",
        "    for f in negativeTrainFiles:\n",
        "        ret = augmentAndTrasformImage(f, negativeFromDir, positiveToTestDir)\n",
        "        if ret == None:\n",
        "            continue\n",
        "        Knegative += 3;\n",
        "\n",
        "    # create negative training images\n",
        "    for f in negativeTestFiles:\n",
        "        ret = augmentAndTrasformImage(f, negativeFromDir, negativeToTestDir)\n",
        "        if ret == None:\n",
        "            continue\n",
        "        Knegative += 3;\n",
        "    #\n",
        "    # print('Total positive files after augmentation: ', Kpositive)\n",
        "    # print('Total negative files after augmentation: ', Knegative)\n",
        "    \n",
        "\n",
        "\n",
        "# mainAugment('/content/drive/MyDrive/Moire/preaugmentedPositiveImages', '/content/drive/MyDrive/Moire/preaugmentedNegativeImages')\n",
        "\n",
        "          \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive image path: /content/drive/MyDrive/Moire/preaugmentedPositiveImages\n",
            "negative image path: /content/drive/MyDrive/Moire/preaugmentedNegativeImages\n",
            "positive train samples: 48\n",
            "negative train samples: 5\n",
            "positive test samples: 53\n",
            "negative test samples: 6\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/350_letterbox1024.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/355_letterbox1024.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/284_letterbox1024.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/chl.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2855.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2859.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2856.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2860.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2866.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2864.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2877.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2863.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2869.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2868.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2871.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2865.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2873.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2872.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2875.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2874.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2870.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2876.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2857.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2862.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2895.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2906.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2902.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2880.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2882.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2905.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2891.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2888.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2887.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2889.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2892.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2897.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2904.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2890.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2898.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2894.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2879.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2901.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2896.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2883.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2881.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2903.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2893.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2900.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2885.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2899.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2884.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2886.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedPositiveImages/IMG_2849.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/14_letterbox1024.jpg\n",
            "training image rotated\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/37_letterbox1024.jpg\n",
            "training image rotated\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/0_letterbox1024.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/22_letterbox1024.jpg\n",
            "training image rotated\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/01_ordinary_extraordinary-1.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/2002_lexus_gs_300_-jzs160r_my0-56bce48d85ed5.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/yellow-ew.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/bmw-noice.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/vw-standard-puetre.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/blue-bmw-moving.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/Mazda-6_MPS-2006-1600-01.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/191005-224-mer-55a66859be0c8.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/2018-kia-stinger-gt-first-drive.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/brown-old-car.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/07_ordinary_extraordinary.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/vwgolfsccolumn.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/kfchxatevaemoonwqaru.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/1-audi-a3.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/images.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/hyundai-sonata-hybrid-2020-01-exterior--grey--profile.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/main-qimg-a69067c77a6f3dc52f2e1360e5196ddd.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/SEI_85642568-640x360.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/2018-BMW-i3-front-three-quarter-01.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/nissan_stagea_autech_260rs-56bc946faf390.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/image-red-car-small.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/Ordinary_Lead.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/00830912ac5c4610a8873a2c589d344f.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/main-qimg-6e734378c6521d3d55333ec2b969bcc7.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/A1913104_large-3482x2322.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/P90404818_highRes_bmw-440i-coupe-3481x2322.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/ImpalaSS_111.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/3500.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/KME0DiZv.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/40001257471_f0bcf1abf0_c.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/images-red-beater.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/DiqOb9AuQ-mw9fJ3TULvQQ.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/vw_touareg_v10_tdi_facelift_-s-56bcbdf96ac41.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/Ob7t24y.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/lotus-carlton.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/lots-of-road.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/jaguar-xj-30-awd.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/images_58459.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/HBcXPzpDSxCIWPRMWey2rg.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/green-car.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/dims.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/g63-amg-1024x453.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/classic-renault-safety-advances-in-motoring.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/abarth-124-14-1024x576.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/AAKYIDz.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/50368478887_cae688182a_k.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/44061639-9671581-The_biggest_riser_among_these_rather_unexceptional_old_motors_is-a-3_1623422340773.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/2018-ford-taurus-sho-release-date-640x480.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/2014-mercedes-benz-e350-4matic-wagon.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/2013-mercedes-benz-c63-amg-edition-507-photo-499741-s-986x603.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/2005-Subaru-Forester-left-front.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/99_photos_toyota_hilux_2001_2.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/F_75.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/images-ugly-carr.jpg\n",
            "/content/drive/MyDrive/Moire/preaugmentedNegativeImages/lancia-thema-8-32-owned-by-rowan-atkinson.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzpWIkVNqa_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "a6d95459-8d59-478e-e81d-4fff0c0c919c"
      },
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "# positiveImagePath = '/content/drive/MyDrive/Moire/preaugmentedPositiveImages'\n",
        "# negativeImagePath = '/content/drive/MyDrive/Moire/preaugmentedNegativeImages'\n",
        "\n",
        "# mainAugment(positiveImagePath, negativeImagePath, 0)\n",
        "   "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive samples: 53\n",
            "negative samples: 59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRAWMODE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'F'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6dbadd1e7bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnegativeImagePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Moire/preaugmentedNegativeImages'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmainAugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositiveImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegativeImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-ad92ba1fc565>\u001b[0m in \u001b[0;36mmainAugment\u001b[0;34m(positiveImages, negativeImages, train)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnegativeTrainImagePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./testDataNegative'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcreateTrainingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositiveImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegativeImagePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-ad92ba1fc565>\u001b[0m in \u001b[0;36mcreateTrainingData\u001b[0;34m(positiveImagePath, negativeImagePath)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# create positive training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositiveImageFiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentAndTrasformImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositiveImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositiveTrainImagePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-ad92ba1fc565>\u001b[0m in \u001b[0;36maugmentAndTrasformImage\u001b[0;34m(f, mainFolder, trainFolder)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mimgGray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgGray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training image rotated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mtransformImageAndSave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mimgGray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgGray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROTATE_180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-ad92ba1fc565>\u001b[0m in \u001b[0;36mtransformImageAndSave\u001b[0;34m(image, f, customStr, path)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mcV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mcD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mcA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mcH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfLH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mcV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfHL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRAWMODE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot write mode %s as JPEG\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoderinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: cannot write mode F as JPEG"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNTveLG9tEf6",
        "outputId": "e00971a5-9ecf-4afa-bcd0-b93b215abfc1"
      },
      "source": [
        "# !cd ../\n",
        "# !ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INPlfs7QQXYJ"
      },
      "source": [
        "## Load Data into Memory\n",
        "Get your big boy pants on because it's going to be a lot of data.  Increase runtime memory.  This section will load data from an **augmented** directory and loads it into a tensor for training or evaluation.  Recommended to make sure that there is no accelerator used so that it can be used when training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOTnUFotxJJJ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#constants\n",
        "WIDTH = 500#384\n",
        "HEIGHT = 375#512\n",
        "\n",
        "#Here, we perform index based splitting and use those indices to split the our multi-input datasets. This is done because the CNN model is multi-input network\n",
        "def splitTrainTestDataForBands(inputData, X_train_ind, X_test_ind):\n",
        "    X_train = np.zeros((len(X_train_ind), WIDTH*HEIGHT))\n",
        "    for i in range(len(X_train_ind)):\n",
        "        X_train[i,:] = inputData[int(X_train_ind[i,0]),:]\n",
        "        \n",
        "    X_test = np.zeros((len(X_test_ind), WIDTH*HEIGHT))\n",
        "    for i in range(len(X_test_ind)):\n",
        "        X_test[i,:] = inputData[int(X_test_ind[i,0]),:]\n",
        "        \n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def countPositiveSamplesAfterSplit(trainData):\n",
        "    count = 0;\n",
        "    for i in range(len(trainData)):\n",
        "        if(trainData[i,0] == 0):\n",
        "            count = count + 1\n",
        "    return count\n",
        "\n",
        "def scaleData(inp, minimum, maximum):\n",
        "    minMaxScaler = preprocessing.MinMaxScaler(copy=True, feature_range=(minimum,maximum))\n",
        "    inp = inp.reshape(-1, 1)\n",
        "    inp = minMaxScaler.fit_transform(inp)\n",
        "    \n",
        "    return inp\n",
        "\n",
        "def readAndScaleImage(f, customStr, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, sampleVal):\n",
        "    fileName = (os.path.splitext(f)[0])\n",
        "    # print(fileName)\n",
        "    # print(customStr)\n",
        "\n",
        "    fLL = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fLH = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fHL = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    fHH = (f.replace(fileName, fileName + customStr)).replace('.jpg','.tiff')\n",
        "    \n",
        "    try:\n",
        "        imgLL = Image.open(join(trainImagePath, fLL))\n",
        "        imgLH = Image.open(join(trainImagePath, fLH))\n",
        "        imgHL = Image.open(join(trainImagePath, fHL))\n",
        "        imgHH = Image.open(join(trainImagePath, fHH))\n",
        "    except Exception as e:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(fileName))\n",
        "        print('Exception:', e)\n",
        "        return None\n",
        "        \n",
        "    imgLL = np.array(imgLL)\n",
        "    imgLH = np.array(imgLH)\n",
        "    imgHL = np.array(imgHL)\n",
        "    imgHH = np.array(imgHH)\n",
        "    imgLL = scaleData(imgLL, 0, 1)\n",
        "    imgLH = scaleData(imgLH, -1, 1)\n",
        "    imgHL = scaleData(imgHL, -1, 1)\n",
        "    imgHH = scaleData(imgHH, -1, 1)\n",
        "    \n",
        "    imgVector = imgLL.reshape(1, WIDTH*HEIGHT)\n",
        "    X_LL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgLH.reshape(1, WIDTH*HEIGHT)\n",
        "    X_LH[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHL.reshape(1, WIDTH*HEIGHT)\n",
        "    X_HL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHH.reshape(1, WIDTH*HEIGHT)\n",
        "    X_HH[sampleIndex, :] = imgVector\n",
        "    \n",
        "    Y[sampleIndex, 0] = sampleVal;\n",
        "    X_index[sampleIndex, 0] = sampleIndex;\n",
        "    \n",
        "    return True\n",
        "\n",
        "def trainTestSplit(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount):\n",
        "    testCountPercent = 0.1\n",
        "\n",
        "    # evaluate the model by splitting into train and test sets\n",
        "    # X_train_ind, X_test_ind, y_train, y_test = train_test_split(X_index, Y, test_size=testCountPercent, random_state=1, stratify=Y)\n",
        "\n",
        "    # X_LL_train, X_LL_test = splitTrainTestDataForBands(X_LL, X_train_ind, X_test_ind)\n",
        "    # X_LH_train, X_LH_test = splitTrainTestDataForBands(X_LH, X_train_ind, X_test_ind)\n",
        "    # X_HL_train, X_HL_test = splitTrainTestDataForBands(X_HL, X_train_ind, X_test_ind)\n",
        "    # X_HH_train, X_HH_test = splitTrainTestDataForBands(X_HH, X_train_ind, X_test_ind)\n",
        "    X_LL_train = X_LL\n",
        "    X_LH_train = X_LH\n",
        "    X_HL_train = X_HL\n",
        "    X_HH_train = X_HH\n",
        "\n",
        "    imageHeight = HEIGHT\n",
        "    imageWidth = WIDTH\n",
        "\n",
        "\n",
        "    # print(countPositiveSamplesAfterSplit(y_train))\n",
        "    print(len(X_LL_train))\n",
        "    # print(len(y_train))\n",
        "    # print(len(X_LL_test))\n",
        "    # print(len(y_test))\n",
        "\n",
        "    # num_train_samples = len(y_train)\n",
        "    print('num_train_samples', len(X_LL))\n",
        "    X_LL_train = np.array(X_LL_train)\n",
        "    X_LL_train = X_LL_train.reshape((len(X_LL), imageHeight, imageWidth, 1))\n",
        "    # X_LL_test = np.array(X_LL_test)\n",
        "    # X_LL_test = X_LL_test.reshape((imageCount - num_train_samples, imageHeight, imageWidth, 1))\n",
        "\n",
        "    X_LH_train = np.array(X_LH_train)\n",
        "    X_LH_train = X_LH_train.reshape((len(X_LH), imageHeight, imageWidth, 1))\n",
        "    # X_LH_test = np.array(X_LH_test)\n",
        "    # X_LH_test = X_LH_test.reshape((imageCount - num_train_samples, imageHeight, imageWidth, 1))\n",
        "\n",
        "    X_HL_train = np.array(X_HL_train)\n",
        "    X_HL_train = X_HL_train.reshape((len(X_HL), imageHeight, imageWidth, 1))\n",
        "    # X_HL_test = np.array(X_HL_test)\n",
        "    # X_HL_test = X_HL_test.reshape((imageCount - num_train_samples, imageHeight, imageWidth, 1))\n",
        "    \n",
        "    X_HH_train = np.array(X_HH_train)\n",
        "    X_HH_train = X_HH_train.reshape((len(X_HH), imageHeight, imageWidth, 1))\n",
        "    # X_HH_test = np.array(X_HH_test)\n",
        "    # X_HH_test = X_HH_test.reshape((imageCount - num_train_samples, imageHeight, imageWidth, 1))\n",
        "\n",
        "    y_train = np.array(Y)\n",
        "    # y_test = np.array(y_test)\n",
        "\n",
        "    # num_train, height, width, depth = X_LL_train.shape\n",
        "    # num_test = X_LL_test.shape[0]\n",
        "    # num_classes = len(np.unique(y_train))\n",
        "    \n",
        "    return X_LL_train, X_LH_train, X_HL_train, X_HH_train, y_train\n",
        "\n",
        "def readImageSet(imageFiles, trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass):\n",
        "\n",
        "    for f in imageFiles:\n",
        "        ret = readAndScaleImage(f, '', trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass)\n",
        "        if ret == True:\n",
        "            sampleIndex = sampleIndex + 1\n",
        "\n",
        "        # #read 180deg rotated data\n",
        "        # ret = readAndScaleImage(f, '_180', trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex,bClass)\n",
        "        # if ret == True:\n",
        "        #     sampleIndex = sampleIndex + 1\n",
        "        #\n",
        "        # #read 180deg FLIP data\n",
        "        # ret = readAndScaleImage(f, '_180_FLIP', trainImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, bClass)\n",
        "        # if ret == True:\n",
        "        #     sampleIndex = sampleIndex + 1\n",
        "     \n",
        "    return sampleIndex\n",
        "\n",
        "def readWaveletData(positiveImagePath, negativeImagePath):\n",
        "    \n",
        "    # get augmented, balanced training data image files by class\n",
        "    positiveImageFiles = [f for f in listdir(positiveImagePath) if (isfile(join(positiveImagePath, f)))]\n",
        "    negativeImageFiles = [f for f in listdir(negativeImagePath) if (isfile(join(negativeImagePath, f)))]\n",
        "\n",
        "    positiveCount = len(positiveImageFiles)\n",
        "    negativeCount = len(negativeImageFiles)\n",
        "\n",
        "    print('positive samples: ' + str(positiveCount))\n",
        "    print('negative samples: ' + str(negativeCount))\n",
        "    imageCount = positiveCount + negativeCount\n",
        "    #intialization\n",
        "    X_LL = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_LH = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_HL = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_HH = np.zeros((positiveCount + negativeCount, WIDTH*HEIGHT))\n",
        "    X_index = np.zeros((positiveCount + negativeCount, 1))\n",
        "    Y = np.zeros((positiveCount + negativeCount, 1))\n",
        "    \n",
        "    sampleIndex = 0\n",
        "    # read all images, convert to float, divide by 255 (leads to gray range 0..1), reshape into a row vector\n",
        "    # write class 0 for positive and 1 for negative samples    \n",
        "    # print('SHAPES 1')\n",
        "    # print(X_LL.shape)\n",
        "    # print(X_LH.shape)\n",
        "    # print(X_HL.shape)\n",
        "    # print(X_HH.shape)\n",
        "\n",
        "    sampleIndex = readImageSet(positiveImageFiles, positiveImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, 0)\n",
        "    print('positive data loaded.')\n",
        "    \n",
        "    sampleIndex += readImageSet(negativeImageFiles, negativeImagePath, X_LL, X_LH, X_HL, X_HH, X_index, Y, sampleIndex, 1)\n",
        "    print('negative data loaded.')\n",
        "\n",
        "    print('Total Samples Loaded: ', sampleIndex)\n",
        "    # print(X_LL)\n",
        "    # print(X_LH)\n",
        "    # print(Y)\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = shuffle(X_LL, X_LH, X_HL, X_HH, Y, random_state=0)\n",
        "    \n",
        "    return X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount\n",
        "\n",
        "def mainReadDatafromDrive(trainingDataPositive, trainingDataNegative):\n",
        "    # positiveImagePath = (args.positiveImages)\n",
        "    # negativeImagePath = (args.negativeImages)\n",
        "    positiveTrainImagePath = trainingDataPositive\n",
        "    negativeTrainImagePath = trainingDataNegative\n",
        "    # positiveTestImagePath = args.testingDataPositive\n",
        "    # negativeTestImagePath = args.testingDataNegative\n",
        "\n",
        "    X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount = readWaveletData(positiveTrainImagePath, negativeTrainImagePath)\n",
        "\n",
        "    # print('SHAPES')\n",
        "    # print(X_LL.shape)\n",
        "    # print(X_LH.shape)\n",
        "    # print(X_HL.shape)\n",
        "    # print(X_HH.shape)\n",
        "\n",
        "    X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train = trainTestSplit(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount)\n",
        "    return X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train;\n",
        "\n",
        "# X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train = mainReadDatafromDrive('/content/drive/MyDrive/Moire/trainDataPositive', '/content/drive/MyDrive/Moire/trainDataNegative')\n",
        "# print(X_LL_train)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azf3IN-SRudm"
      },
      "source": [
        "## Train CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ASB86jIRxvK"
      },
      "source": [
        "import os\n",
        "\n",
        "from keras.models import Model # basic class for specifying and training a neural network\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Add, Multiply, Maximum\n",
        "\n",
        "def createModel(height, width, depth, num_classes):\n",
        "#     num_epochs = 20 # 50 26 200 # we iterate 200 times over the entire training set\n",
        "    kernel_size_1 = 7 # we will use 7x7 kernels \n",
        "    kernel_size_2 = 3 # we will use 3x3 kernels \n",
        "    pool_size = 2 # we will use 2x2 pooling throughout\n",
        "    conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
        "    conv_depth_2 = 16 # ...switching to 16 after the first pooling layer\n",
        "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
        "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
        "    hidden_size = 32 # 128 512 the FC layer will have 512 neurons\n",
        "\n",
        "\n",
        "    inpLL = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpLH = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHL = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHH = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end (first in Theano)\n",
        "\n",
        "    conv_1_LL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLL)\n",
        "    conv_1_LH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLH)\n",
        "    conv_1_HL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHL)\n",
        "    conv_1_HH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHH)\n",
        "    pool_1_LL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LL)\n",
        "    pool_1_LH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LH)\n",
        "    pool_1_HL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HL)\n",
        "    pool_1_HH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HH)\n",
        "\n",
        "    avg_LH_HL_HH = Maximum()([pool_1_LH, pool_1_HL, pool_1_HH])\n",
        "    inp_merged = Multiply()([pool_1_LL, avg_LH_HL_HH])\n",
        "    C4 = Convolution2D(conv_depth_2, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(inp_merged)\n",
        "    S2 = MaxPooling2D(pool_size=(4, 4))(C4)\n",
        "    drop_1 = Dropout(drop_prob_1)(S2)\n",
        "    C5 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(drop_1)\n",
        "    S3 = MaxPooling2D(pool_size=(pool_size, pool_size))(C5)\n",
        "    C6 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(S3)\n",
        "    S4 = MaxPooling2D(pool_size=(pool_size, pool_size))(C6)\n",
        "    drop_2 = Dropout(drop_prob_1)(S4)\n",
        "    # Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
        "    flat = Flatten()(drop_2)\n",
        "    hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "    drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "    out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "    \n",
        "    model = Model(inputs=[inpLL, inpLH, inpHL, inpHH], outputs=out) # To define a model, just specify its input and output layers\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTX2vudptIaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b7493a-fdf7-4b6b-f02a-45dc1361635a"
      },
      "source": [
        "#To detect Moire ́ patternzs, images are first decomposed using Wavelet decomposition (refer to file '') and trained using multi-input Convolutional neural network. The strength of the proposed CNN model is, it uses the LL intensity image (from the Wavelet decomposition) as a weight parameter for the Moire ́ pattern, thereby approximating the spatial spread of the Moire ́ pattern in the image. Usage of CNN model performs better than frequency thresholding approach as the model is trained considering diverse scenarios and it is able to distinguish between the high frequency of background texture and the Moire ́ pattern.\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# - read positive and negative training data\n",
        "# - create X and Y from training data\n",
        "\n",
        "\n",
        "def mainTrain(X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, numEpochs):\n",
        "    # positiveImagePath = (args.positiveImages)\n",
        "    # negativeImagePath = (args.negativeImages)\n",
        "    # numEpochs = epochs\n",
        "    # positiveTrainImagePath = trainingDataPositive\n",
        "    # negativeTrainImagePath = trainingDataNegative\n",
        "    # positiveTestImagePath = args.testingDataPositive\n",
        "    # negativeTestImagePath = args.testingDataNegative\n",
        "\n",
        "    # X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount = readWaveletData(positiveTrainImagePath, negativeTrainImagePath)\n",
        "\n",
        "    \n",
        "    # X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train = trainTestSplit(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount)\n",
        "    # X_LL_train,X_LH_train,X_HL_train,X_HH_train,Y_train,X_LL_test,X_LH_test,X_HL_test,X_HH_test,Y_test = trainTestSplit(X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount)\n",
        "\n",
        "    model = trainCNNModel(X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, numEpochs)\n",
        "    \n",
        "    # evaluate(model, X_LL_test,X_LH_test,X_HL_test,X_HH_test,Y_test)\n",
        "    \n",
        "\n",
        "def trainCNNModel(X_LL_train,X_LH_train,X_HL_train,X_HH_train,y_train,num_epochs):\n",
        "\n",
        "    batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "    print(\"SHAPE\")\n",
        "    print(X_LL_train.shape);\n",
        "    num_train, height, width, depth = X_LL_train.shape\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "    print(y_train);\n",
        "    # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "\n",
        "    checkPointFolder = 'content/drive/MyDrive/Moire/checkPoint'\n",
        "    checkpoint_name = checkPointFolder + '/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "    checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "    callbacks_list = [checkpoint]\n",
        "    \n",
        "    if not os.path.exists(checkPointFolder):\n",
        "        os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "    model = createModel(height, width, depth, num_classes)\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "                  optimizer='adam', # using the Adam optimiser\n",
        "                  metrics=['accuracy']) # reporting the accuracy\n",
        "\n",
        "    model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "              batch_size=batch_size, epochs=num_epochs,\n",
        "              verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "    # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "    model.save('content/drive/MyDrive/Moire/checkPoint/moirePattern3CNN_.h5')\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate(model, X_LL_test,X_LH_test,X_HL_test,X_HH_test,y_test):\n",
        "\n",
        "    model_out = model.predict([X_LL_test,X_LH_test,X_HL_test,X_HH_test])\n",
        "    passCnt = 0\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "            str_label='Pass'\n",
        "            passCnt = passCnt + 1\n",
        "        else:\n",
        "            str_label='Fail'\n",
        "\n",
        "        if y_test[i] ==0:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                TP = TP + 1;\n",
        "            else:\n",
        "                FN = FN + 1\n",
        "        else:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                TN = TN + 1;\n",
        "            else:\n",
        "                FP = FP + 1\n",
        "\n",
        "    start = \"\\033[1m\"\n",
        "    end = \"\\033[0;0m\"\n",
        "    print(start + 'confusion matrix (test / validation)' + end)\n",
        "    print(start + 'true positive:  '+ end + str(TP))\n",
        "    print(start + 'false positive: '+ end + str(FP))\n",
        "    print(start + 'true negative:  '+ end + str(TN))\n",
        "    print(start + 'false negative: '+ end + str(FN))\n",
        "    print('\\n')\n",
        "    print(start + 'accuracy:  ' + end + \"{:.4f} %\".format(100*(TP+TN)/(TP+FP+FN+TN)))\n",
        "    print(start + 'precision: ' + end + \"{:.4f} %\".format(100*TP/(TP + FP)))\n",
        "    print(start + 'recall:  ' + end + \"{:.4f} %\".format(100*TP/(TP + FN)))\n",
        "\n",
        "\n",
        "def parse_arguments(argv):\n",
        "    parser = argparse.ArgumentParser()\n",
        "    \n",
        "    # parser.add_argument('positiveImages', type=str, help='Directory with original positive (Moiré pattern) images.')\n",
        "    # parser.add_argument('negativeImages', type=str, help='Directory with original negative (Normal) images.')\n",
        "    \n",
        "    parser.add_argument('trainingDataPositive', type=str, help='Directory with transformed positive (Moiré pattern) images for training.')\n",
        "    parser.add_argument('trainingDataNegative', type=str, help='Directory with transformed negative (Normal) images for training.')\n",
        "\n",
        "    # parser.add_argument('testingDataPositive', type=str, help='Directory with transformed positive (Moiré pattern) images for testing.')\n",
        "    # parser.add_argument('testingDataNegative', type=str, help='Directory with transformed negative (Normal) images for testing.')\n",
        "    \n",
        "    parser.add_argument('epochs', type=int, help='Number of epochs for training')\n",
        "    \n",
        "    return parser.parse_args(argv)\n",
        "\n",
        "\n",
        "\n",
        "print(X_LL_train)\n",
        "mainTrain(X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, 30)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[0.53679651]\n",
            "   [0.48484847]\n",
            "   [0.44155842]\n",
            "   ...\n",
            "   [0.44155842]\n",
            "   [0.44588745]\n",
            "   [0.45454544]]\n",
            "\n",
            "  [[0.47619048]\n",
            "   [0.48051947]\n",
            "   [0.47186145]\n",
            "   ...\n",
            "   [0.40692639]\n",
            "   [0.43290043]\n",
            "   [0.46753246]]\n",
            "\n",
            "  [[0.49350649]\n",
            "   [0.47619048]\n",
            "   [0.42857143]\n",
            "   ...\n",
            "   [0.42424241]\n",
            "   [0.43290043]\n",
            "   [0.46320346]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.45021644]\n",
            "   [0.45021644]\n",
            "   [0.45021644]\n",
            "   ...\n",
            "   [0.44588745]\n",
            "   [0.42857143]\n",
            "   [0.41125542]]\n",
            "\n",
            "  [[0.45021644]\n",
            "   [0.45021644]\n",
            "   [0.45021644]\n",
            "   ...\n",
            "   [0.48051947]\n",
            "   [0.46320346]\n",
            "   [0.45021644]]\n",
            "\n",
            "  [[0.45021644]\n",
            "   [0.45021644]\n",
            "   [0.45021644]\n",
            "   ...\n",
            "   [0.44155842]\n",
            "   [0.43290043]\n",
            "   [0.46320346]]]\n",
            "\n",
            "\n",
            " [[[0.56026793]\n",
            "   [0.51339293]\n",
            "   [0.4620536 ]\n",
            "   ...\n",
            "   [0.42410719]\n",
            "   [0.54464293]\n",
            "   [0.56919646]]\n",
            "\n",
            "  [[0.5714286 ]\n",
            "   [0.43750003]\n",
            "   [0.4508929 ]\n",
            "   ...\n",
            "   [0.4464286 ]\n",
            "   [0.52901793]\n",
            "   [0.52901793]]\n",
            "\n",
            "  [[0.54464293]\n",
            "   [0.53125006]\n",
            "   [0.45535719]\n",
            "   ...\n",
            "   [0.50446433]\n",
            "   [0.51785719]\n",
            "   [0.48660719]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.4620536 ]\n",
            "   [0.44866076]\n",
            "   [0.64955366]\n",
            "   ...\n",
            "   [0.52232146]\n",
            "   [0.50000006]\n",
            "   [0.56696433]]\n",
            "\n",
            "  [[0.37723219]\n",
            "   [0.57812506]\n",
            "   [0.60044646]\n",
            "   ...\n",
            "   [0.53571433]\n",
            "   [0.49553576]\n",
            "   [0.54910719]]\n",
            "\n",
            "  [[0.59598219]\n",
            "   [0.5089286 ]\n",
            "   [0.56473219]\n",
            "   ...\n",
            "   [0.5558036 ]\n",
            "   [0.52008933]\n",
            "   [0.48883933]]]\n",
            "\n",
            "\n",
            " [[[0.4755435 ]\n",
            "   [0.47010869]\n",
            "   [0.47282609]\n",
            "   ...\n",
            "   [0.47282609]\n",
            "   [0.47282609]\n",
            "   [0.47282609]]\n",
            "\n",
            "  [[0.47282609]\n",
            "   [0.47282609]\n",
            "   [0.4755435 ]\n",
            "   ...\n",
            "   [0.47282609]\n",
            "   [0.47282609]\n",
            "   [0.47282609]]\n",
            "\n",
            "  [[0.47282609]\n",
            "   [0.47282609]\n",
            "   [0.47010869]\n",
            "   ...\n",
            "   [0.47282609]\n",
            "   [0.47282609]\n",
            "   [0.47282609]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.47282609]\n",
            "   [0.47010869]\n",
            "   [0.47282609]\n",
            "   ...\n",
            "   [0.47282609]\n",
            "   [0.47010869]\n",
            "   [0.47282609]]\n",
            "\n",
            "  [[0.47282609]\n",
            "   [0.47282609]\n",
            "   [0.47282609]\n",
            "   ...\n",
            "   [0.4755435 ]\n",
            "   [0.47282609]\n",
            "   [0.47282609]]\n",
            "\n",
            "  [[0.47282609]\n",
            "   [0.47010869]\n",
            "   [0.47282609]\n",
            "   ...\n",
            "   [0.4755435 ]\n",
            "   [0.47282609]\n",
            "   [0.4755435 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.52112675]\n",
            "   [0.50704223]\n",
            "   [0.46478871]\n",
            "   ...\n",
            "   [0.46478871]\n",
            "   [0.47887322]\n",
            "   [0.47887322]]\n",
            "\n",
            "  [[0.49295774]\n",
            "   [0.47887322]\n",
            "   [0.46478871]\n",
            "   ...\n",
            "   [0.46478871]\n",
            "   [0.47887322]\n",
            "   [0.47887322]]\n",
            "\n",
            "  [[0.4366197 ]\n",
            "   [0.42253518]\n",
            "   [0.47887322]\n",
            "   ...\n",
            "   [0.46478871]\n",
            "   [0.46478871]\n",
            "   [0.47887322]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.47887322]\n",
            "   [0.46478871]\n",
            "   [0.46478871]\n",
            "   ...\n",
            "   [0.47887322]\n",
            "   [0.47887322]\n",
            "   [0.47887322]]\n",
            "\n",
            "  [[0.47887322]\n",
            "   [0.47887322]\n",
            "   [0.47887322]\n",
            "   ...\n",
            "   [0.47887322]\n",
            "   [0.47887322]\n",
            "   [0.47887322]]\n",
            "\n",
            "  [[0.49295774]\n",
            "   [0.47887322]\n",
            "   [0.47887322]\n",
            "   ...\n",
            "   [0.47887322]\n",
            "   [0.47887322]\n",
            "   [0.47887322]]]\n",
            "\n",
            "\n",
            " [[[0.60536397]\n",
            "   [0.61302686]\n",
            "   [0.60919541]\n",
            "   ...\n",
            "   [0.60536397]\n",
            "   [0.60536397]\n",
            "   [0.60536397]]\n",
            "\n",
            "  [[0.60536397]\n",
            "   [0.61302686]\n",
            "   [0.61302686]\n",
            "   ...\n",
            "   [0.61302686]\n",
            "   [0.60919541]\n",
            "   [0.60919541]]\n",
            "\n",
            "  [[0.60919541]\n",
            "   [0.60919541]\n",
            "   [0.60919541]\n",
            "   ...\n",
            "   [0.61302686]\n",
            "   [0.60536397]\n",
            "   [0.60919541]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.61302686]\n",
            "   [0.60919541]\n",
            "   [0.60919541]\n",
            "   ...\n",
            "   [0.60919541]\n",
            "   [0.60919541]\n",
            "   [0.61302686]]\n",
            "\n",
            "  [[0.60919541]\n",
            "   [0.60919541]\n",
            "   [0.60919541]\n",
            "   ...\n",
            "   [0.60919541]\n",
            "   [0.60919541]\n",
            "   [0.61302686]]\n",
            "\n",
            "  [[0.61302686]\n",
            "   [0.60919541]\n",
            "   [0.60536397]\n",
            "   ...\n",
            "   [0.60919541]\n",
            "   [0.60919541]\n",
            "   [0.61302686]]]\n",
            "\n",
            "\n",
            " [[[0.73622048]\n",
            "   [0.73622048]\n",
            "   [0.73622048]\n",
            "   ...\n",
            "   [0.51082677]\n",
            "   [0.50688976]\n",
            "   [0.50295275]]\n",
            "\n",
            "  [[0.72637796]\n",
            "   [0.72637796]\n",
            "   [0.72637796]\n",
            "   ...\n",
            "   [0.50787401]\n",
            "   [0.5       ]\n",
            "   [0.49507874]]\n",
            "\n",
            "  [[0.71456695]\n",
            "   [0.71456695]\n",
            "   [0.71456695]\n",
            "   ...\n",
            "   [0.50885826]\n",
            "   [0.50885826]\n",
            "   [0.50984251]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.59940946]\n",
            "   [0.61122048]\n",
            "   [0.61220473]\n",
            "   ...\n",
            "   [0.5925197 ]\n",
            "   [0.60137796]\n",
            "   [0.61023623]]\n",
            "\n",
            "  [[0.62795275]\n",
            "   [0.62992126]\n",
            "   [0.62893701]\n",
            "   ...\n",
            "   [0.58759844]\n",
            "   [0.60433072]\n",
            "   [0.62204725]]\n",
            "\n",
            "  [[0.65059054]\n",
            "   [0.6555118 ]\n",
            "   [0.65255904]\n",
            "   ...\n",
            "   [0.58661419]\n",
            "   [0.60728347]\n",
            "   [0.625     ]]]]\n",
            "SHAPE\n",
            "(1212, 375, 500, 1)\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " ...\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n",
            "Epoch 1/30\n",
            "35/35 [==============================] - 140s 4s/step - loss: 0.6931 - accuracy: 0.5455 - val_loss: 0.6927 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69269, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-001--0.69269.hdf5\n",
            "Epoch 2/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 120s 3s/step - loss: 0.6927 - accuracy: 0.5099 - val_loss: 0.6853 - val_accuracy: 0.5656\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69269 to 0.68528, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-002--0.68528.hdf5\n",
            "Epoch 3/30\n",
            "35/35 [==============================] - 119s 3s/step - loss: 0.6739 - accuracy: 0.5969 - val_loss: 0.5513 - val_accuracy: 0.7295\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68528 to 0.55132, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-003--0.55132.hdf5\n",
            "Epoch 4/30\n",
            "35/35 [==============================] - 118s 3s/step - loss: 0.5768 - accuracy: 0.6866 - val_loss: 0.4926 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.55132 to 0.49261, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-004--0.49261.hdf5\n",
            "Epoch 5/30\n",
            "35/35 [==============================] - 120s 3s/step - loss: 0.4770 - accuracy: 0.7518 - val_loss: 0.3267 - val_accuracy: 0.8525\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.49261 to 0.32671, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-005--0.32671.hdf5\n",
            "Epoch 6/30\n",
            "35/35 [==============================] - 119s 3s/step - loss: 0.3355 - accuracy: 0.8469 - val_loss: 0.3088 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.32671 to 0.30881, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-006--0.30881.hdf5\n",
            "Epoch 7/30\n",
            "35/35 [==============================] - 120s 3s/step - loss: 0.2817 - accuracy: 0.8836 - val_loss: 0.2590 - val_accuracy: 0.8770\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.30881 to 0.25903, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-007--0.25903.hdf5\n",
            "Epoch 8/30\n",
            "35/35 [==============================] - 119s 3s/step - loss: 0.2182 - accuracy: 0.8975 - val_loss: 0.1798 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.25903 to 0.17978, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-008--0.17978.hdf5\n",
            "Epoch 9/30\n",
            "35/35 [==============================] - 121s 3s/step - loss: 0.2418 - accuracy: 0.9023 - val_loss: 0.1704 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.17978 to 0.17036, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-009--0.17036.hdf5\n",
            "Epoch 10/30\n",
            "35/35 [==============================] - 118s 3s/step - loss: 0.1553 - accuracy: 0.9418 - val_loss: 0.3192 - val_accuracy: 0.8689\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.17036\n",
            "Epoch 11/30\n",
            "35/35 [==============================] - 122s 3s/step - loss: 0.1643 - accuracy: 0.9323 - val_loss: 0.1934 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.17036\n",
            "Epoch 12/30\n",
            "35/35 [==============================] - 120s 3s/step - loss: 0.1145 - accuracy: 0.9621 - val_loss: 0.1642 - val_accuracy: 0.9098\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.17036 to 0.16418, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-012--0.16418.hdf5\n",
            "Epoch 13/30\n",
            "35/35 [==============================] - 119s 3s/step - loss: 0.1351 - accuracy: 0.9438 - val_loss: 0.1876 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.16418\n",
            "Epoch 14/30\n",
            "35/35 [==============================] - 124s 4s/step - loss: 0.1051 - accuracy: 0.9588 - val_loss: 0.1564 - val_accuracy: 0.9098\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.16418 to 0.15639, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-014--0.15639.hdf5\n",
            "Epoch 15/30\n",
            "35/35 [==============================] - 121s 3s/step - loss: 0.1762 - accuracy: 0.9336 - val_loss: 0.1816 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.15639\n",
            "Epoch 16/30\n",
            "35/35 [==============================] - 123s 4s/step - loss: 0.1227 - accuracy: 0.9464 - val_loss: 0.1486 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.15639 to 0.14864, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-016--0.14864.hdf5\n",
            "Epoch 17/30\n",
            "35/35 [==============================] - 117s 3s/step - loss: 0.0917 - accuracy: 0.9671 - val_loss: 0.1308 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.14864 to 0.13076, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-017--0.13076.hdf5\n",
            "Epoch 18/30\n",
            "35/35 [==============================] - 115s 3s/step - loss: 0.0864 - accuracy: 0.9752 - val_loss: 0.0990 - val_accuracy: 0.9508\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.13076 to 0.09903, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-018--0.09903.hdf5\n",
            "Epoch 19/30\n",
            "35/35 [==============================] - 116s 3s/step - loss: 0.0755 - accuracy: 0.9728 - val_loss: 0.1160 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.09903\n",
            "Epoch 20/30\n",
            "35/35 [==============================] - 116s 3s/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 0.1635 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.09903\n",
            "Epoch 21/30\n",
            "35/35 [==============================] - 115s 3s/step - loss: 0.0512 - accuracy: 0.9815 - val_loss: 0.0992 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.09903\n",
            "Epoch 22/30\n",
            "35/35 [==============================] - 116s 3s/step - loss: 0.1053 - accuracy: 0.9690 - val_loss: 0.1611 - val_accuracy: 0.9426\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.09903\n",
            "Epoch 23/30\n",
            "35/35 [==============================] - 117s 3s/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 0.1686 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.09903\n",
            "Epoch 24/30\n",
            "35/35 [==============================] - 117s 3s/step - loss: 0.0570 - accuracy: 0.9771 - val_loss: 0.1130 - val_accuracy: 0.9508\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.09903\n",
            "Epoch 25/30\n",
            "35/35 [==============================] - 118s 3s/step - loss: 0.0602 - accuracy: 0.9764 - val_loss: 0.1012 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.09903\n",
            "Epoch 26/30\n",
            "35/35 [==============================] - 118s 3s/step - loss: 0.0403 - accuracy: 0.9904 - val_loss: 0.1173 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.09903\n",
            "Epoch 27/30\n",
            "35/35 [==============================] - 116s 3s/step - loss: 0.0627 - accuracy: 0.9810 - val_loss: 0.1307 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.09903\n",
            "Epoch 28/30\n",
            "35/35 [==============================] - 116s 3s/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0687 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.09903 to 0.06866, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-028--0.06866.hdf5\n",
            "Epoch 29/30\n",
            "35/35 [==============================] - 119s 3s/step - loss: 0.0350 - accuracy: 0.9851 - val_loss: 0.0961 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.06866\n",
            "Epoch 30/30\n",
            "35/35 [==============================] - 117s 3s/step - loss: 0.0282 - accuracy: 0.9864 - val_loss: 0.0825 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.06866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "120i4Ry-qa_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "09d2a53d-cebb-4426-e3ff-f9102fb612f8"
      },
      "source": [
        "# positiveTrainImagePath = './trainDataPositive'\n",
        "# negativeTrainImagePath = './trainDataNegative'\n",
        "# epochs = 10\n",
        "    \n",
        "# mainTrain(positiveImagePath, negativeImagePath, positiveTrainImagePath, negativeTrainImagePath, epochs)\n",
        "!ls content/drive/MyDrive/Moire/checkPoint/\n",
        "from google.colab import files\n",
        "files.download('content/drive/MyDrive/Moire/checkPoint/Weights-028--0.06866.hdf5')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moirePattern3CNN_.h5\t   Weights-006--0.30881.hdf5  Weights-016--0.14864.hdf5\n",
            "Weights-001--0.69269.hdf5  Weights-007--0.25903.hdf5  Weights-017--0.13076.hdf5\n",
            "Weights-002--0.68528.hdf5  Weights-008--0.17978.hdf5  Weights-018--0.09903.hdf5\n",
            "Weights-003--0.55132.hdf5  Weights-009--0.17036.hdf5  Weights-028--0.06866.hdf5\n",
            "Weights-004--0.49261.hdf5  Weights-012--0.16418.hdf5\n",
            "Weights-005--0.32671.hdf5  Weights-014--0.15639.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ed4a12a7-44a6-4424-8508-4e3fb67950fc\", \"Weights-028--0.06866.hdf5\", 2433344)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWnNYpcTqa_O"
      },
      "source": [
        "## Test CNN Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV0rGdyIueOf"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#constants\n",
        "width = 500#384 #change dimensions according to the input image in the training\n",
        "height = 375#512 #change dimensions according to the input image in the training\n",
        "depth = 1\n",
        "num_classes = 2\n",
        "\n",
        "# positiveTestImagePath = './testDataPositive'\n",
        "# negativeTestImagePath = './testDataNegative'\n",
        "    \n",
        "def mainTest(weightsFile, positiveTestImages, negativeTestImages):\n",
        "    weights_file = (weightsFile)\n",
        "    positiveImagePath = (positiveTestImages)\n",
        "    negativeImagePath = (negativeTestImages)\n",
        "\n",
        "    print(positiveImagePath)\n",
        "    print(negativeImagePath)\n",
        "    # print(positiveTestImagePath)\n",
        "    # print(positiveTestImagePath)\n",
        "    \n",
        "    # mainAugment(positiveImagePath, negativeImagePath, 1)\n",
        "    # X_LL, X_LH, X_HL, X_HH, X_index, Y, imageCount = readWaveletData(positiveImagePath, negativeImagePath)\n",
        "    X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(positiveImagePath, negativeImagePath)\n",
        "    \n",
        "    # X_LL = np.array(X_LL)\n",
        "    # X_LL = X_LL.reshape((imageCount, height, width, depth))\n",
        "    # X_LH = np.array(X_LH)\n",
        "    # X_LH = X_LH.reshape((imageCount, height, width, depth))\n",
        "    # X_HL = np.array(X_HL)\n",
        "    # X_HL = X_HL.reshape((imageCount, height, width, depth))\n",
        "    # X_HH = np.array(X_HH)\n",
        "    # X_HH = X_HH.reshape((imageCount, height, width, depth))\n",
        "    \n",
        "    CNN_model = createModel(height, width, depth, num_classes)\n",
        "    CNN_model.load_weights(weights_file)\n",
        "    evaluate(CNN_model,X_LL,X_LH,X_HL,X_HH, Y)\n",
        "\n",
        "\n",
        "\n",
        "def run(model, X_LL_test,X_LH_test,X_HL_test,y_test):\n",
        "    return\n",
        "\n",
        "\n",
        "def parse_arguments(argv):\n",
        "    parser = argparse.ArgumentParser()\n",
        "    \n",
        "    parser.add_argument('weightsFile', type=str, help='saved CNN model file')\n",
        "    \n",
        "    parser.add_argument('positiveTestImages', type=str, help='Directory with positive (Moiré pattern) images.')\n",
        "    parser.add_argument('negativeTestImages', type=str, help='Directory with negative (Normal) images.')\n",
        "    \n",
        "    \n",
        "    return parser.parse_args(argv)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYSPiTtfqa_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47150240-54ae-4f14-8e50-d42c020ac5d0"
      },
      "source": [
        "weightsFile = \"moirePattern3CNN_.h5\"\n",
        "    \n",
        "    \n",
        "mainTest('content/drive/MyDrive/Moire/checkPoint/moirePattern3CNN_.h5', '/content/drive/MyDrive/Moire/testDataPositive', '/content/drive/MyDrive/Moire/testDataNegative')\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Moire/testDataPositive\n",
            "/content/drive/MyDrive/Moire/testDataNegative\n",
            "positive samples: 48\n",
            "negative samples: 72\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  168\n",
            "120\n",
            "num_train_samples 120\n",
            "\u001b[1mconfusion matrix (test / validation)\u001b[0;0m\n",
            "\u001b[1mtrue positive:  \u001b[0;0m16\n",
            "\u001b[1mfalse positive: \u001b[0;0m0\n",
            "\u001b[1mtrue negative:  \u001b[0;0m72\n",
            "\u001b[1mfalse negative: \u001b[0;0m32\n",
            "\n",
            "\n",
            "\u001b[1maccuracy:  \u001b[0;0m73.3333 %\n",
            "\u001b[1mprecision: \u001b[0;0m100.0000 %\n",
            "\u001b[1mrecall:  \u001b[0;0m33.3333 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTxUTR6Yv2LG"
      },
      "source": [
        "## Extended Training\n",
        "Take the trained model and continue training with additional data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fb9-mhtcBbo",
        "outputId": "836a00ef-6d10-4285-88fa-b1c37a82ce6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "positiveTrainImagePath = '/content/drive/MyDrive/Moire/preaugmented/positive/002'\n",
        "negativeTrainImagePath = '/content/drive/MyDrive/Moire/preaugmented/negative/002'\n",
        "normalizeRawImages(positiveTrainImagePath, negativeTrainImagePath)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2907.HEIC\n",
            "IMG_2907.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2911.HEIC\n",
            "IMG_2911.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2940.HEIC\n",
            "IMG_2940.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2912.HEIC\n",
            "IMG_2912.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2935.HEIC\n",
            "IMG_2935.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2936.HEIC\n",
            "IMG_2936.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2918.HEIC\n",
            "IMG_2918.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2937.HEIC\n",
            "IMG_2937.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2941.HEIC\n",
            "IMG_2941.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2915.HEIC\n",
            "IMG_2915.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2930.HEIC\n",
            "IMG_2930.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2917.HEIC\n",
            "IMG_2917.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2916.HEIC\n",
            "IMG_2916.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2919.HEIC\n",
            "IMG_2919.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2934.HEIC\n",
            "IMG_2934.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2933.HEIC\n",
            "IMG_2933.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2929.HEIC\n",
            "IMG_2929.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2922.HEIC\n",
            "IMG_2922.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2921.HEIC\n",
            "IMG_2921.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2939.HEIC\n",
            "IMG_2939.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2914.HEIC\n",
            "IMG_2914.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2931.HEIC\n",
            "IMG_2931.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2924.HEIC\n",
            "IMG_2924.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2927.HEIC\n",
            "IMG_2927.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2923.HEIC\n",
            "IMG_2923.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2913.HEIC\n",
            "IMG_2913.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2908.HEIC\n",
            "IMG_2908.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2920.HEIC\n",
            "IMG_2920.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2928.HEIC\n",
            "IMG_2928.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2910.HEIC\n",
            "IMG_2910.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2909.HEIC\n",
            "IMG_2909.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2938.HEIC\n",
            "IMG_2938.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedPositiveImages/IMG_2932.HEIC\n",
            "IMG_2932.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/vehicle-detailing-new-bedford-1-300x200.jpeg\n",
            "vehicle-detailing-new-bedford-1-300x200.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/white-van-parking-lot.jpeg\n",
            "white-van-parking-lot.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/Vancouver-vehicle-storage.jpeg\n",
            "Vancouver-vehicle-storage.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/steelermobile-fahrzeugfest.jpeg\n",
            "steelermobile-fahrzeugfest.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/transmission-fluid-exchange-1200x900-min.png\n",
            "transmission-fluid-exchange-1200x900-min.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/schedule-pick-up-and-delivery-hero-mobile.jpeg\n",
            "schedule-pick-up-and-delivery-hero-mobile.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/Planning-a-Car-Museum-Tour.jpeg\n",
            "Planning-a-Car-Museum-Tour.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/pco-car-hire.jpeg\n",
            "pco-car-hire.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/on-site-car-repair-santa-clarita-1024x576.jpeg\n",
            "on-site-car-repair-santa-clarita-1024x576.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/new-car-two-dudes.jpeg\n",
            "new-car-two-dudes.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/jeep2-400w.png\n",
            "jeep2-400w.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/hood-open.jpeg\n",
            "hood-open.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/fp-article-2.png\n",
            "fp-article-2.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/d906ee31efe845af9e192ce9c01343e7.jpeg\n",
            "d906ee31efe845af9e192ce9c01343e7.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL3BsdWctaW4taHlicmlkcy1iZXR0ZXItdGhhbi1yZWd1bGFyLWh5YnJpZHMtMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjI5MH19fQ==.jpeg\n",
            "eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL3BsdWctaW4taHlicmlkcy1iZXR0ZXItdGhhbi1yZWd1bGFyLWh5YnJpZHMtMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjI5MH19fQ==.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/cq5dam_web_2440_1600.jpg\n",
            "cq5dam_web_2440_1600.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/car-moving.jpeg\n",
            "car-moving.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/210607134025-2022-gmc-hummer-ev-super-tease.jpeg\n",
            "210607134025-2022-gmc-hummer-ev-super-tease.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/28421016158.jpeg\n",
            "28421016158.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/6926542183_df5327f7e3_b.jpeg\n",
            "6926542183_df5327f7e3_b.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/2021-hyundai-veloster-mmp-1-1594743978.jpeg\n",
            "2021-hyundai-veloster-mmp-1-1594743978.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/2140033-L2hvbWUvZGVhbGVycy9hc3NldHMvMTkvaW1hZ2VzLzIxNDAwMzMtMjAyMC1jaGV2eS1zaWx2ZXJhZG8tMTUwMC1yZWQuanBn.jpeg\n",
            "2140033-L2hvbWUvZGVhbGVycy9hc3NldHMvMTkvaW1hZ2VzLzIxNDAwMzMtMjAyMC1jaGV2eS1zaWx2ZXJhZG8tMTUwMC1yZWQuanBn.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/2020-Toyota-Prius-Rain_o-1038x400.png\n",
            "2020-Toyota-Prius-Rain_o-1038x400.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/1200px-97-01_Jeep_Cherokee.jpeg\n",
            "1200px-97-01_Jeep_Cherokee.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/587b529c22e346a592a3908e01a324fa.jpeg\n",
            "587b529c22e346a592a3908e01a324fa.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/27890018890.jpeg\n",
            "27890018890.jpg\n",
            "/content/drive/MyDrive/Moire/notNormalizedNegativeImages/1-bentley-bentayga-2020-uk-fd-hero-front_1.jpeg\n",
            "1-bentley-bentayga-2020-uk-fd-hero-front_1.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyiISSNr2ZAr",
        "outputId": "c654690a-b1db-464b-f17b-2fff60f1e2b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train = mainReadDatafromDrive('/content/drive/MyDrive/Moire/trainDataPositive', '/content/drive/MyDrive/Moire/trainDataNegative')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive samples: 576\n",
            "negative samples: 636\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  1788\n",
            "1212\n",
            "num_train_samples 1212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnwQH5eYqa_O"
      },
      "source": [
        "#constants\n",
        "# width = 500#384 #change dimensions according to the input image in the training\n",
        "# height = 375#512 #change dimensions according to the input image in the training\n",
        "# depth = 1\n",
        "# num_classes = 2\n",
        "\n",
        "def continueTraining(weightsFile, X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, num_epochs):\n",
        "    weights_file = (weightsFile)\n",
        "\n",
        "    # X_LL, X_LH, X_HL, X_HH, Y = mainReadDatafromDrive(positiveImagePath, negativeImagePath)\n",
        "    \n",
        "    \n",
        "\n",
        "    batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "    print(\"SHAPE\")\n",
        "    print(X_LL_train.shape);\n",
        "    num_train, height, width, depth = X_LL_train.shape\n",
        "    num_classes = len(np.unique(Y_train))\n",
        "    Y_train = np_utils.to_categorical(Y_train, num_classes) # One-hot encode the labels\n",
        "    print(Y_train);\n",
        "    # Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "\n",
        "    CNN_model = createModel(height, width, depth, num_classes)\n",
        "    CNN_model.load_weights(weights_file)\n",
        "\n",
        "    checkPointFolder = 'content/drive/MyDrive/Moire/checkPoint'\n",
        "    checkpoint_name = checkPointFolder + '/Weights-retrained-002--{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "    checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "    callbacks_list = [checkpoint]\n",
        "    \n",
        "    if not os.path.exists(checkPointFolder):\n",
        "        os.makedirs(checkPointFolder)\n",
        "        \n",
        "        \n",
        "    # model = createModel(height, width, depth, num_classes)\n",
        "    \n",
        "    CNN_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "                  optimizer='adam', # using the Adam optimiser\n",
        "                  metrics=['accuracy']) # reporting the accuracy\n",
        "\n",
        "    CNN_model.fit([X_LL_train,X_LH_train,X_HL_train,X_HH_train], Y_train,                # Train the model using the training set...\n",
        "              batch_size=batch_size, epochs=num_epochs,\n",
        "              verbose=1, validation_split=0.1, callbacks=callbacks_list) # ...holding out 10% of the data for validation\n",
        "    # score, acc = model.evaluate([X_LL_test,X_LH_test,X_HL_test,X_HH_test], Y_test, verbose=1)  # Evaluate the trained model on the test set!\n",
        "\n",
        "    CNN_model.save('content/drive/MyDrive/Moire/checkPoint/retrained-002-moirePattern3CNN_.h5')\n",
        "    \n",
        "    return model\n",
        "    # evaluate(CNN_model,X_LL,X_LH,X_HL,X_HH, Y)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fyxBfYY4i7U",
        "outputId": "79918e44-c326-4016-a1e8-1e19bd78813e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "continueTraining('content/drive/MyDrive/Moire/checkPoint/Weights-028--0.06866.hdf5', X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, 1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SHAPE\n",
            "(1212, 375, 500, 1)\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n",
            "35/35 [==============================] - 123s 3s/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.1405 - val_accuracy: 0.9426\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.14051, saving model to content/drive/MyDrive/Moire/checkPoint/Weights-retrained-002--001--0.14051.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-15cde0690968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontinueTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content/drive/MyDrive/Moire/checkPoint/Weights-028--0.06866.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LL_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_LH_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HL_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_HH_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-3a8746765611>\u001b[0m in \u001b[0;36mcontinueTraining\u001b[0;34m(weightsFile, X_LL_train, X_LH_train, X_HL_train, X_HH_train, Y_train, num_epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mCNN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content/drive/MyDrive/Moire/checkPoint/retrained-002-moirePattern3CNN_.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# evaluate(CNN_model,X_LL,X_LH,X_HL,X_HH, Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlSUPMxf6tFa",
        "outputId": "39336915-f670-49e5-8a92-b77c6ee53aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls content/drive/MyDrive/Moire/checkPoint"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moirePattern3CNN_.h5\t\t    Weights-008--0.17978.hdf5\n",
            "retrained-002-moirePattern3CNN_.h5  Weights-009--0.17036.hdf5\n",
            "Weights-001--0.69269.hdf5\t    Weights-012--0.16418.hdf5\n",
            "Weights-002--0.68528.hdf5\t    Weights-014--0.15639.hdf5\n",
            "Weights-003--0.55132.hdf5\t    Weights-016--0.14864.hdf5\n",
            "Weights-004--0.49261.hdf5\t    Weights-017--0.13076.hdf5\n",
            "Weights-005--0.32671.hdf5\t    Weights-018--0.09903.hdf5\n",
            "Weights-006--0.30881.hdf5\t    Weights-028--0.06866.hdf5\n",
            "Weights-007--0.25903.hdf5\t    Weights-retrained-002--001--0.14051.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYl1Npdb623a",
        "outputId": "3fb4f917-fdb1-45d8-ea58-c72707d2e56a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mainTest('content/drive/MyDrive/Moire/checkPoint/retrained-002-moirePattern3CNN_.h5', '/content/drive/MyDrive/Moire/testDataPositive', '/content/drive/MyDrive/Moire/testDataNegative')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Moire/testDataPositive\n",
            "/content/drive/MyDrive/Moire/testDataNegative\n",
            "positive samples: 48\n",
            "negative samples: 72\n",
            "positive data loaded.\n",
            "negative data loaded.\n",
            "Total Samples Loaded:  168\n",
            "120\n",
            "num_train_samples 120\n",
            "\u001b[1mconfusion matrix (test / validation)\u001b[0;0m\n",
            "\u001b[1mtrue positive:  \u001b[0;0m29\n",
            "\u001b[1mfalse positive: \u001b[0;0m4\n",
            "\u001b[1mtrue negative:  \u001b[0;0m68\n",
            "\u001b[1mfalse negative: \u001b[0;0m19\n",
            "\n",
            "\n",
            "\u001b[1maccuracy:  \u001b[0;0m80.8333 %\n",
            "\u001b[1mprecision: \u001b[0;0m87.8788 %\n",
            "\u001b[1mrecall:  \u001b[0;0m60.4167 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}